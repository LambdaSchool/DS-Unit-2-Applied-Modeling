{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 1*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Wrangle ML datasets\n",
    "\n",
    "- [ ] Continue to clean and explore your data. \n",
    "- [ ] For the evaluation metric you chose, what score would you get just by guessing?\n",
    "- [ ] Can you make a fast, first model that beats guessing?\n",
    "\n",
    "**We recommend that you use your portfolio project dataset for all assignments this sprint.**\n",
    "\n",
    "**But if you aren't ready yet, or you want more practice, then use the New York City property sales dataset for today's assignment.** Follow the instructions below, to just keep a subset for the Tribeca neighborhood, and remove outliers or dirty data. [Here's a video walkthrough](https://youtu.be/pPWFw8UtBVg?t=584) you can refer to if you get stuck or want hints!\n",
    "\n",
    "- Data Source: [NYC OpenData: NYC Citywide Rolling Calendar Sales](https://data.cityofnewyork.us/dataset/NYC-Citywide-Rolling-Calendar-Sales/usep-8jbt)\n",
    "- Glossary: [NYC Department of Finance: Rolling Sales Data](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is some free form exploration.  Just trying to figure out whats going on here and poke \n",
    "#around some before I get to my actual strategy.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#the dots represent how many folders up we have to go before looking for the file\n",
    "folder = '../../DS-Unit-2-Build/bosch-production-line-performance/'\n",
    "\n",
    "#we are going to read in chunks of 1k for right now to keep from overloading my ram\n",
    "cat_iter = pd.read_csv(folder + 'train_categorical.csv', iterator = True, chunksize = 1000)\n",
    "\n",
    "num_iter = pd.read_csv(folder + 'train_numeric.csv', iterator = True, chunksize = 1000)\n",
    "\n",
    "date_iter = pd.read_csv(folder + 'train_date.csv', iterator = True, chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/anaconda3/envs/anaconda_env/lib/python3.8/site-packages/IPython/core/async_helpers.py:68: DtypeWarning: Columns (96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,335,407,410,413,416,419,422,425,428,431,434,437,440,443,446,449,452,455,458,461,464,467,470,473,476,479,482,485,488,491,494,497,500,503,506,509,512,515,518,611,614,617,620,623,626,629,632,635,638,641,644,647,650,653,656,659,662,665,668,671,674,677,680,683,686,689,692,695,698,701,704,707,710,713,716,719,722,1005,1007,1008,1010,1011,1013,1014,1016,1017,1019,1020,1022,1023,1025,1026,1028,1029,1031,1032,1034,1035,1037,1038,1040,1041,1043,1044,1046,1047,1049,1050,1052,1126,1129,1132,1135,1138,1141,1144,1147,1183,1185,1188,1191,1194,1197,1200,1203,1206,1209,1212,1215,1218,1221,1224,1227,1230,1233,1236,1239,1242,1245,1248,1251,1254,1257,1260,1263,1266,1269,1272,1275,1278,1288,1298,1300,1303,1306,1309,1312,1315,1318,1321,1324,1327,1330,1333,1336,1339,1342,1345,1348,1351,1354,1357,1360,1363,1366,1369,1372,1375,1378,1381,1384,1387,1390,1393,1419,1431,1434,1437,1440,1443,1446,1449,1452,1455,1458,1461,1464,1467,1470,1473,1476,1527,1530,1533,1536,1539,1542,1545,1548,1657,1659,1661,1663,1665,1667,1669,1671,1673,1675,1677,1679,1681,1683,1685,1687,1689,1691,1693,1694,1696,1698,1700,1702,1704,1706,1708,2052,2054,2055,2057,2058,2060,2061,2063,2064,2066,2067,2069,2070,2072,2073,2075,2076,2077,2078,2079,2080,2081,2082,2083) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  coro.send(None)\n"
     ]
    }
   ],
   "source": [
    "#This warning has to do with how pandas reads categorical data.  Basically pandas wants me\n",
    "#to read the whole file and infer the data type from there.  Or I can pass in the datatype.\n",
    "#But since I haven't fully explored yet we'll just note this warning for what its and move\n",
    "#on\n",
    "cat = cat_iter.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4229</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>998.613000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>586.907348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>491.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>973.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1511.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2055.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id  L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  \\\n",
       "count  1000.000000        0.0        0.0        0.0        0.0        0.0   \n",
       "mean    998.613000        NaN        NaN        NaN        NaN        NaN   \n",
       "std     586.907348        NaN        NaN        NaN        NaN        NaN   \n",
       "min       4.000000        NaN        NaN        NaN        NaN        NaN   \n",
       "25%     491.750000        NaN        NaN        NaN        NaN        NaN   \n",
       "50%     973.500000        NaN        NaN        NaN        NaN        NaN   \n",
       "75%    1511.500000        NaN        NaN        NaN        NaN        NaN   \n",
       "max    2055.000000        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "       L0_S2_F35  L0_S2_F37  L0_S2_F39  L0_S2_F41  ...  L3_S49_F4225  \\\n",
       "count        0.0        0.0        0.0        0.0  ...           0.0   \n",
       "mean         NaN        NaN        NaN        NaN  ...           NaN   \n",
       "std          NaN        NaN        NaN        NaN  ...           NaN   \n",
       "min          NaN        NaN        NaN        NaN  ...           NaN   \n",
       "25%          NaN        NaN        NaN        NaN  ...           NaN   \n",
       "50%          NaN        NaN        NaN        NaN  ...           NaN   \n",
       "75%          NaN        NaN        NaN        NaN  ...           NaN   \n",
       "max          NaN        NaN        NaN        NaN  ...           NaN   \n",
       "\n",
       "       L3_S49_F4227  L3_S49_F4229  L3_S49_F4230  L3_S49_F4232  L3_S49_F4234  \\\n",
       "count           0.0           0.0           0.0           0.0           0.0   \n",
       "mean            NaN           NaN           NaN           NaN           NaN   \n",
       "std             NaN           NaN           NaN           NaN           NaN   \n",
       "min             NaN           NaN           NaN           NaN           NaN   \n",
       "25%             NaN           NaN           NaN           NaN           NaN   \n",
       "50%             NaN           NaN           NaN           NaN           NaN   \n",
       "75%             NaN           NaN           NaN           NaN           NaN   \n",
       "max             NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "       L3_S49_F4235  L3_S49_F4237  L3_S49_F4239  L3_S49_F4240  \n",
       "count           0.0           0.0           0.0           0.0  \n",
       "mean            NaN           NaN           NaN           NaN  \n",
       "std             NaN           NaN           NaN           NaN  \n",
       "min             NaN           NaN           NaN           NaN  \n",
       "25%             NaN           NaN           NaN           NaN  \n",
       "50%             NaN           NaN           NaN           NaN  \n",
       "75%             NaN           NaN           NaN           NaN  \n",
       "max             NaN           NaN           NaN           NaN  \n",
       "\n",
       "[8 rows x 1525 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eh not super useful\n",
    "cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2141)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Okay baseline what our chunk size is\n",
    "cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1524\n",
       "1       156\n",
       "693      60\n",
       "5        45\n",
       "3        40\n",
       "161      27\n",
       "86       27\n",
       "15       25\n",
       "9        21\n",
       "12       21\n",
       "6        20\n",
       "49       19\n",
       "45       19\n",
       "13       19\n",
       "8        18\n",
       "14       17\n",
       "21       16\n",
       "2        16\n",
       "25       13\n",
       "94       12\n",
       "39       11\n",
       "4         8\n",
       "669       3\n",
       "34        1\n",
       "35        1\n",
       "93        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#okay checking to see if there are any values in this chunk.  There definitely are\n",
    "cat.drop(columns = 'Id').notna().sum().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(802, 2140)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets try a drop na on only rows that are all nans. and see what we end up losing.\n",
    "cat.drop(columns = 'Id').dropna(how = 'all').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Okay so there are definitely values in there, I just have visibility problem.  I'm always\n",
    "#going to have a hard time inspecting them because the dataset is so wide.\n",
    "#I wonder if PCA may come in hand?  I should explore that as one of my models, see if I can\n",
    "#get some Insight from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore and Clean strategy\n",
    "Okay after taking that quick look above, I know that just chunking in information isn't going to be as useful as I want it to be.  Essentially I'm chunking in huge, mostly empty dataframes.  So I think I will run my numerical and categorical data through two different models, and use a stacking/voting techinque.  So basically if a uniqe part had no categorical data, then my categorical model will not have a vote so to speak.\n",
    "### Step 1 verify id\n",
    "I need to verify that in each data set, that a unique part ID is never duplicated.  I'd assume not, but I can read in that column and find out.\n",
    "### Step 2 Inspect\n",
    "Check the resulting data frame, and get an idea of what is actually in there.\n",
    "### Step 3 Throw out nans\n",
    "Get rid of rows with all nans.  For right now I don't care about those\n",
    "### Step 4 Impute\n",
    "I can't just leave those nans in there.  So I'm going to try some imputing.\n",
    "### Step 5 basic model\n",
    "I just want to get a simple mvp model to try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183747,)\n"
     ]
    }
   ],
   "source": [
    "#step 1\n",
    "check_id = pd.read_csv(folder + 'train_numeric.csv', usecols = ['Id'], squeeze = True)\n",
    "print(check_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183747,)\n"
     ]
    }
   ],
   "source": [
    "#okay definitely unique.  Lets verify we have the same IDs in the categorical and the date\n",
    "#data sets\n",
    "cat_id = pd.read_csv(folder + 'train_categorical.csv', usecols = ['Id'], squeeze = True)\n",
    "print(cat_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same shape, that is a good sign\n",
    "cat_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183747"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we have exactly 1:1 IDs in the data sets then this should equal the size of our id shape\n",
    "pd.concat([check_id, cat_id]).duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 970)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>998.613000</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.002838</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>586.907348</td>\n",
       "      <td>0.079192</td>\n",
       "      <td>0.093521</td>\n",
       "      <td>0.214535</td>\n",
       "      <td>0.214192</td>\n",
       "      <td>0.094356</td>\n",
       "      <td>0.163048</td>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.105601</td>\n",
       "      <td>0.119745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254489</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.251000</td>\n",
       "      <td>-0.258000</td>\n",
       "      <td>-0.397000</td>\n",
       "      <td>-0.397000</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>-0.566000</td>\n",
       "      <td>-0.044000</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>-0.327000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>491.750000</td>\n",
       "      <td>-0.049000</td>\n",
       "      <td>-0.056000</td>\n",
       "      <td>-0.179000</td>\n",
       "      <td>-0.179000</td>\n",
       "      <td>-0.056000</td>\n",
       "      <td>-0.066000</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>-0.072000</td>\n",
       "      <td>-0.082000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>973.500000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>-0.034000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1511.500000</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2055.000000</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id    L0_S0_F0    L0_S0_F2    L0_S0_F4    L0_S0_F6  \\\n",
       "count  1000.000000  600.000000  600.000000  600.000000  600.000000   \n",
       "mean    998.613000   -0.001823   -0.002838    0.009395    0.009162   \n",
       "std     586.907348    0.079192    0.093521    0.214535    0.214192   \n",
       "min       4.000000   -0.251000   -0.258000   -0.397000   -0.397000   \n",
       "25%     491.750000   -0.049000   -0.056000   -0.179000   -0.179000   \n",
       "50%     973.500000    0.003000    0.004000   -0.024000   -0.034000   \n",
       "75%    1511.500000    0.056000    0.063000    0.294000    0.294000   \n",
       "max    2055.000000    0.252000    0.250000    0.530000    0.548000   \n",
       "\n",
       "         L0_S0_F8   L0_S0_F10   L0_S0_F12   L0_S0_F14   L0_S0_F16  ...  \\\n",
       "count  600.000000  600.000000  600.000000  600.000000  600.000000  ...   \n",
       "mean    -0.000037    0.003355    0.000878    0.006267    0.000722  ...   \n",
       "std      0.094356    0.163048    0.019698    0.105601    0.119745  ...   \n",
       "min     -0.317000   -0.566000   -0.044000   -0.232000   -0.327000  ...   \n",
       "25%     -0.056000   -0.066000   -0.015000   -0.072000   -0.082000  ...   \n",
       "50%      0.031000    0.070000    0.000000    0.008000    0.000000  ...   \n",
       "75%      0.074000    0.116000    0.015000    0.088000    0.081000  ...   \n",
       "max      0.248000    0.206000    0.052000    0.328000    0.347000  ...   \n",
       "\n",
       "       L3_S50_F4245  L3_S50_F4247  L3_S50_F4249  L3_S50_F4251  L3_S50_F4253  \\\n",
       "count     24.000000          24.0          24.0          24.0     24.000000   \n",
       "mean      -0.000042           0.0           0.0           0.0      0.020833   \n",
       "std        0.000204           0.0           0.0           0.0      0.254489   \n",
       "min       -0.001000           0.0           0.0           0.0     -0.250000   \n",
       "25%        0.000000           0.0           0.0           0.0     -0.250000   \n",
       "50%        0.000000           0.0           0.0           0.0      0.250000   \n",
       "75%        0.000000           0.0           0.0           0.0      0.250000   \n",
       "max        0.000000           0.0           0.0           0.0      0.250000   \n",
       "\n",
       "       L3_S51_F4256  L3_S51_F4258  L3_S51_F4260  L3_S51_F4262     Response  \n",
       "count     39.000000          39.0     39.000000          39.0  1000.000000  \n",
       "mean      -0.000026           0.0      0.000462           0.0     0.004000  \n",
       "std        0.000160           0.0      0.002882           0.0     0.063151  \n",
       "min       -0.001000           0.0      0.000000           0.0     0.000000  \n",
       "25%        0.000000           0.0      0.000000           0.0     0.000000  \n",
       "50%        0.000000           0.0      0.000000           0.0     0.000000  \n",
       "75%        0.000000           0.0      0.000000           0.0     0.000000  \n",
       "max        0.000000           0.0      0.018000           0.0     1.000000  \n",
       "\n",
       "[8 rows x 970 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#okay lets just knock out a quick mvp, and then we can think about how to make this reproducable\n",
    "#for the full datasets.  I'm going to work with train_numeric right now, because it has our\n",
    "#target in it, so I don't have to load in a bunch of data sets.\n",
    "\n",
    "num_iter = pd.read_csv(folder + 'train_numeric.csv', iterator = True, chunksize = 1000)\n",
    "\n",
    "num = num_iter.get_chunk()\n",
    "print(num.shape)\n",
    "num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  L0_S0_F0  L0_S0_F2  L0_S0_F4  L0_S0_F6  L0_S0_F8  L0_S0_F10  L0_S0_F12  \\\n",
       "0   4     0.030    -0.034    -0.197    -0.179     0.118      0.116     -0.015   \n",
       "1   6       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "2   7     0.088     0.086     0.003    -0.052     0.161      0.025     -0.015   \n",
       "3   9    -0.036    -0.064     0.294     0.330     0.074      0.161      0.022   \n",
       "4  11    -0.055    -0.086     0.294     0.330     0.118      0.025      0.030   \n",
       "\n",
       "   L0_S0_F14  L0_S0_F16  ...  L3_S50_F4245  L3_S50_F4247  L3_S50_F4249  \\\n",
       "0     -0.032      0.020  ...           NaN           NaN           NaN   \n",
       "1        NaN        NaN  ...           NaN           NaN           NaN   \n",
       "2     -0.072     -0.225  ...           NaN           NaN           NaN   \n",
       "3      0.128     -0.026  ...           NaN           NaN           NaN   \n",
       "4      0.168     -0.169  ...           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  L3_S51_F4258  L3_S51_F4260  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_F4262  Response  \n",
       "0           NaN         0  \n",
       "1           NaN         0  \n",
       "2           NaN         0  \n",
       "3           NaN         0  \n",
       "4           NaN         0  \n",
       "\n",
       "[5 rows x 970 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#okay good this is looking like it has little more info available.\n",
    "num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 968)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.drop(columns = ['Id', 'Response']).dropna(how = 'all').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eeeeeeehhhhhh that is literally only one line of the data I chunked in.  Okay, lesson learned\n",
    "#Though the categorical data set might be missing quite a few rows, this numerical dataset seems\n",
    "#to be pretty intact. Ultimately, I'm going to skip this step and knock out a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3.5\n",
    "Create a baseline with a dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Response'\n",
    "X = num.drop(columns = ['Id', target])\n",
    "y = num['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 968), (1000,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision of a random guess baseline is:  0.00398406374501992\n",
      "The accuracy of a random guess baseline is:  0.498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#since we decided to go with a guessing basline, this is effectively \n",
    "baseline = DummyClassifier(strategy = 'uniform')\n",
    "\n",
    "baseline.fit(X, y)\n",
    "\n",
    "y_pred = baseline.predict(X)\n",
    "\n",
    "#we are using precision as our metric, but I'm curious about accuracy as well\n",
    "print('The precision of a random guess baseline is: ', precision_score(y, y_pred))\n",
    "print('The accuracy of a random guess baseline is: ', accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holy smokes a random guess has a crazy low precision.  Good to know the bar is so low.\n",
    "#lets go ahead and split out a test set\n",
    "from skelearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets do a quick one with cross validation, but no hyperparameter tweaking regression classifier\n",
    "#with so much missing data, median might be a better choice than mean for imputing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy = 'median'),\n",
    "    LogisticRegression(random_state = 42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets do a quick cross validation and see how this goes\n",
    "\n",
    "results = cross_validate(\n",
    "    pipeline,\n",
    "    X,\n",
    "    y,\n",
    "    scoring =  ['accuracy', 'precision'],\n",
    "    cv = 4,\n",
    "    n_jobs = -1,\n",
    "    return_train_score = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.05400133, 0.0525794 , 0.05420256, 0.04981446]),\n",
       " 'score_time': array([0.00499964, 0.00532413, 0.00533652, 0.00535655]),\n",
       " 'test_accuracy': array([0.996, 0.996, 0.996, 0.996]),\n",
       " 'train_accuracy': array([0.996, 0.996, 0.996, 0.996]),\n",
       " 'test_precision': array([0., 0., 0., 0.]),\n",
       " 'train_precision': array([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hmmm either I'm doing it wrong or my answer is getting rounded down.  Sure looks wrong though\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I must have some leakage going on.  That accuracy is way too high, and likely the reason I have\n",
    "#0 precision"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
