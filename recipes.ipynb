{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General setup for a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv('&todo')\n",
    "#&cell\n",
    "# take a look at the data\n",
    "df.head()\n",
    "#&cell\n",
    "\n",
    "# Going to get a list of the categorical variables an the numeric valiables and take a look at a baseline\n",
    "# model\n",
    "target = '' #&todo\n",
    "\n",
    "cat=df.select_dtypes(exclude='number')\n",
    "num=df.select_dtypes(exclude='object')\n",
    "\n",
    "# filter out unwanted features like dates\n",
    "ignore=[''] #&todo\n",
    "cat=[x for x in cat if x not in ignore]\n",
    "num=[x for x in num if x not in ignore]\n",
    "features=cat+num\n",
    "\n",
    "# validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train,test=train_test_split(df,random_state=42)\n",
    "train,val=train_test_split(train,random_state=42)\n",
    "\n",
    "# feature sets\n",
    "X_train=train[features]\n",
    "X_val=val[features]\n",
    "X_test=test[features]\n",
    "\n",
    "y_train=train[target]\n",
    "y_val=val[target]\n",
    "y_test=test[target]\n",
    "\n",
    "print(\"(train shape)(val shape)(test shape)\")\n",
    "train.shape,val.shape,test.shape\n",
    "#&cell\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score,r2_score\n",
    "\n",
    "from sklearn.linear_model import [LinearRegression,LogisticRegression]\n",
    "\n",
    "pipeline=make_pipeline(\n",
    "#&todo make a model slection and encoding selection\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "print(\"training r^2 is:\",pipeline.score(X_train,y_train))\n",
    "print(\"validation r^2 is:\",pipeline.score(X_val,y_val))\n",
    "\n",
    "#&cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdp plot single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox.pdp import pdp_isolate,pdp_plot\n",
    "# select the feature that is going to be looked at\n",
    "feature = ''#&todo\n",
    "# use a fitted model,df,a list of columns from the df, and the feature that you want to inspect to ini the pdp\n",
    "isolate=pdp_isolate(\n",
    "    model=model,\n",
    "    dataset=X_val,\n",
    "    model_features=X_val.columns,\n",
    "    feature=feature\n",
    ")\n",
    "# use the pdp plot method with the pdp object and the target feature name to plot a graph\n",
    "pdp_plot(isolate,feature_name=feature) #plot_lines=True,frac_to_plot=0.01 makes it so that it will track indeividuels instead of a proba cone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdp plot multi inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdpbox.pdp import pdp_interact,pdp_interact_plot\n",
    "# select features to use for the pdp plot\n",
    "features=['Annual Income','Credit Score']\n",
    "# diffrent object same process\n",
    "interaction=pdp_interact(\n",
    "        model=model,\n",
    "        dataset=X_val,\n",
    "        model_features=X_val.columns,\n",
    "        features=features\n",
    "\n",
    ")\n",
    "# make a bit of a difffrent plot because of some bugs in this version of pdp\n",
    "# use plot_type='grid'\n",
    "pdp_interact_plot(interaction,plot_type='grid',feature_names=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shaply plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDY/PRACTICE THIS CELL FOR THE SPRINT CHALLENGE\n",
    "import shap\n",
    "\n",
    "processor = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "# To explain the prediction for test observation with index #3094, \n",
    "# first, get all of the features for that observation\n",
    "row = X_test.iloc[[3094]]\n",
    "row\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "row_processed = processor.transform(row)\n",
    "shap_values = explainer.shap_values(row_processed)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value, \n",
    "    shap_values=shap_values, \n",
    "    features=row, \n",
    "    link='logit' # For classification, this shows predicted probabilities\n",
    "                 # otherwise it can be left omitted for regression problems\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the permutation importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# make a transformation pipeline\n",
    "autobot=make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(strategy='median') # change this as needed\n",
    ")\n",
    "\n",
    "# make the transformed feature matrixs\n",
    "X_train_encoded=autobot.fit_transform(X_train,y_train)\n",
    "X_val_encoded=autobot.transform(X_val)\n",
    "\n",
    "# fit the model with the transformed information\n",
    "model=LinearRegression(n_jobs=-1)\n",
    "model.fit(X_train_encoded,y_train)\n",
    "\n",
    "# make a permutation importance finder\n",
    "permuter=PermutationImportance(\n",
    "    model,\n",
    "    scoring=None,\n",
    "    n_iter=5,\n",
    "    random_state=42\n",
    ")\n",
    "# fit the premuter to the validation set\n",
    "permuter.fit(X_val_encoded,y_val)\n",
    "\n",
    "feature_names = X_val.columns.tolist()\n",
    "# if this breaks look at the code from 2-3 LS_DS_234_assignment\n",
    "pd.Series(permuter.feature_importances_, feature_names).sort_values().index\n",
    "\n",
    "# actually shows the graph for the permution importance\n",
    "eli5.show_weights(\n",
    "    permuter,\n",
    "    top=None,\n",
    "    feature_names=feature_names\n",
    ")"
   ]
  }
 ]
}