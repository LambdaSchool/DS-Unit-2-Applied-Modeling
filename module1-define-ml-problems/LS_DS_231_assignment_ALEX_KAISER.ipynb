{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LS_DS_231_assignment_ALEX_KAISER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lord-Kanzler/DS-Unit-2-Applied-Modeling/blob/master/module1-define-ml-problems/LS_DS_231_assignment_ALEX_KAISER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 1*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Define ML problems\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your decisions.\n",
        "\n",
        "- [x] Choose your target. Which column in your tabular dataset will you predict?\n",
        "\n",
        "\n",
        "- [x] Is your problem regression or classification?\n",
        "- [x] How is your target distributed?\n",
        "    - Classification: How many classes? Are the classes imbalanced?\n",
        "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
        "- [x] Choose your evaluation metric(s).\n",
        "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
        "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
        "- [x] Choose which observations you will use to train, validate, and test your model.\n",
        "    - Are some observations outliers? Will you exclude them?\n",
        "    - Will you do a random split or a time-based split?\n",
        "- [x] Begin to clean and explore your data.\n",
        "- [x] Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
        "\n",
        "If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.\n",
        "\n",
        "Some students worry, ***what if my model isn't “good”?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvkxNFvHMrcj",
        "colab_type": "text"
      },
      "source": [
        "Choose your target. Which column in your tabular dataset will you predict?\n",
        "\n",
        "- There would be several features to predict, first I would have to create a few features by combining column content into more descriptive features. The Columns major*, minor*, and unknown* would be combined first into a single class, for each type of incident reported (accidents involving cyclists, pedestrians, car-on-car crashes etc. Similar feature engineering would happen for information regarding accidents with fatal outcomes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC0o5Gr4OpaV",
        "colab_type": "text"
      },
      "source": [
        "Is your problem regression or classification?\n",
        "\n",
        "- It has both aspects to it, since first I would need to predict potential numbers of incidents based on prior data, but my goal would be to predict the types of incidents in relation to local areas of dc. So it would also include classifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5LzCrT-Ophk",
        "colab_type": "text"
      },
      "source": [
        "How is your target distributed?\n",
        "\n",
        "- The targets are definetly skewed towards car-on-car crashes, as those are the predominant class of incidents reported to ddot. At this point I am not completely certain of how many classes I have as this would be a multi-stage process. But for the start, there are 4 types of incidents total, and 3 types of incidents with fatal outcomes, so potentially 7. However, these would be split among classification and regression according to the perrtaining question I'm trying to answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb5ukcoyOpkq",
        "colab_type": "text"
      },
      "source": [
        "Choose your evaluation metric(s)\n",
        "\n",
        "- For the classification stage of the build, I would use prediction accuracy for both the validation set and the test set. The neat part about this dc-traffic incident set is that it's maintained regularly, which which provides another layer of validation as time progresses, and future incidents occure( keeping morbide aspects aside).\n",
        "\n",
        "- For the regression I would try to determine mean absolut error, R^2 and root mean square error probably. Mostly because it is a minor feat to calculate these once code is all set up, and it would also help me develope a better feel on how to interprete these values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asb6zpcpR36N",
        "colab_type": "text"
      },
      "source": [
        "Choose which observations you will use to train, validate, and test your model\n",
        "\n",
        "- I would do random split although I am not completely certain on the ratios yet. For future validation I would only use the same range of data that I have used for the first build project, and reserve the newest data for secondary validation of my predictions. The random split makes more sense to me in this specific case, as it avoids grouping time or year specific flaktuations of incidents that might bias my models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK0_S9WBR39I",
        "colab_type": "text"
      },
      "source": [
        " Begin to clean and explore your data.\n",
        "\n",
        "-As discussed previously, I already cleaned the data as part of the first build week project. I am currently working on creating new features, and adding data point markers for the respective areas of dc (for which i\"m still trying to determine their respective geographical coordinates)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDkagr9cTs67",
        "colab_type": "text"
      },
      "source": [
        "Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
        "\n",
        "- The good thing is, that no features would be leaking data. However, I am also taking a closer look at information from the raw data set that I have previously dropped to make sure I'm not disregarding anything that could prove useful for my predictions."
      ]
    }
  ]
}