{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCc3XZEyG3XV"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 1*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Define ML problems\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your decisions.\n",
    "\n",
    "- [ ] Choose your target. Which column in your tabular dataset will you predict?\n",
    "- [ ] Is your problem regression or classification?\n",
    "- [ ] How is your target distributed?\n",
    "    - Classification: How many classes? Are the classes imbalanced?\n",
    "    - Regression: Is the target right-skewed? If so, you may want to log transform the target.\n",
    "- [ ] Choose your evaluation metric(s).\n",
    "    - Classification: Is your majority class frequency >= 50% and < 70% ? If so, you can just use accuracy if you want. Outside that range, accuracy could be misleading. What evaluation metric will you choose, in addition to or instead of accuracy?\n",
    "    - Regression: Will you use mean absolute error, root mean squared error, R^2, or other regression metrics?\n",
    "- [ ] Choose which observations you will use to train, validate, and test your model.\n",
    "    - Are some observations outliers? Will you exclude them?\n",
    "    - Will you do a random split or a time-based split?\n",
    "- [ ] Begin to clean and explore your data.\n",
    "- [ ] Begin to choose which features, if any, to exclude. Would some features \"leak\" future information?\n",
    "\n",
    "If you haven't found a dataset yet, do that today. [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2) and choose your dataset.\n",
    "\n",
    "Some students worry, ***what if my model isn't “good”?*** Then, [produce a detailed tribute to your wrongness. That is science!](https://twitter.com/nathanwpyle/status/1176860147223867393)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first things first we gotta read this thing in.  It is massive, and literally split into\n",
    "#three datasets.  Two of which make sense to me, one which is really weird.  So I'm just going\n",
    "#to read these in.\n",
    "#Reference: https://www.kaggle.com/c/bosch-production-line-performance/data\n",
    "import pandas as pd\n",
    "\n",
    "#the dots represent how many folders up we have to go before looking for the file\n",
    "folder = '../../DS-Unit-2-Build/bosch-production-line-performance/'\n",
    "\n",
    "#we are going to read in chunks of 1k for right now to keep from overloading my ram\n",
    "cat_iter = pd.read_csv(folder + 'train_categorical.csv', iterator = True, chunksize = 1000)\n",
    "\n",
    "num_iter = pd.read_csv(folder + 'train_numeric.csv', iterator = True, chunksize = 1000)\n",
    "\n",
    "date_iter = pd.read_csv(folder + 'train_date.csv', iterator = True, chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/anaconda3/envs/anaconda_env/lib/python3.8/site-packages/IPython/core/async_helpers.py:68: DtypeWarning: Columns (96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,335,407,410,413,416,419,422,425,428,431,434,437,440,443,446,449,452,455,458,461,464,467,470,473,476,479,482,485,488,491,494,497,500,503,506,509,512,515,518,611,614,617,620,623,626,629,632,635,638,641,644,647,650,653,656,659,662,665,668,671,674,677,680,683,686,689,692,695,698,701,704,707,710,713,716,719,722,1005,1007,1008,1010,1011,1013,1014,1016,1017,1019,1020,1022,1023,1025,1026,1028,1029,1031,1032,1034,1035,1037,1038,1040,1041,1043,1044,1046,1047,1049,1050,1052,1126,1129,1132,1135,1138,1141,1144,1147,1183,1185,1188,1191,1194,1197,1200,1203,1206,1209,1212,1215,1218,1221,1224,1227,1230,1233,1236,1239,1242,1245,1248,1251,1254,1257,1260,1263,1266,1269,1272,1275,1278,1288,1298,1300,1303,1306,1309,1312,1315,1318,1321,1324,1327,1330,1333,1336,1339,1342,1345,1348,1351,1354,1357,1360,1363,1366,1369,1372,1375,1378,1381,1384,1387,1390,1393,1419,1431,1434,1437,1440,1443,1446,1449,1452,1455,1458,1461,1464,1467,1470,1473,1476,1527,1530,1533,1536,1539,1542,1545,1548,1657,1659,1661,1663,1665,1667,1669,1671,1673,1675,1677,1679,1681,1683,1685,1687,1689,1691,1693,1694,1696,1698,1700,1702,1704,1706,1708,2052,2054,2055,2057,2058,2060,2061,2063,2064,2066,2067,2069,2070,2072,2073,2075,2076,2077,2078,2079,2080,2081,2082,2083) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  coro.send(None)\n"
     ]
    }
   ],
   "source": [
    "#we got some chonky iterators.  Lets get those chonks!\n",
    "\n",
    "cat_df = cat_iter.get_chunk()\n",
    "num_df = num_iter.get_chunk()\n",
    "date_df = date_iter.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2141)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4229</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "0   4        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "1   6        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2   7        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3   9        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4  11        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   L0_S2_F37  L0_S2_F39  L0_S2_F41  ...  L3_S49_F4225  L3_S49_F4227  \\\n",
       "0        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "1        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "2        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "3        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "4        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "\n",
       "   L3_S49_F4229  L3_S49_F4230  L3_S49_F4232  L3_S49_F4234  L3_S49_F4235  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S49_F4237  L3_S49_F4239  L3_S49_F4240  \n",
       "0           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 2141 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#that warning is to be expected.  I can probably safely treat my numeric data set as floats\n",
    "#and i'm guessing my categorical dataset should be strings, but we really need to take a look\n",
    "#to find out.\n",
    "print(cat_df.shape)\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 970)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  L0_S0_F0  L0_S0_F2  L0_S0_F4  L0_S0_F6  L0_S0_F8  L0_S0_F10  L0_S0_F12  \\\n",
       "0   4     0.030    -0.034    -0.197    -0.179     0.118      0.116     -0.015   \n",
       "1   6       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "2   7     0.088     0.086     0.003    -0.052     0.161      0.025     -0.015   \n",
       "3   9    -0.036    -0.064     0.294     0.330     0.074      0.161      0.022   \n",
       "4  11    -0.055    -0.086     0.294     0.330     0.118      0.025      0.030   \n",
       "\n",
       "   L0_S0_F14  L0_S0_F16  ...  L3_S50_F4245  L3_S50_F4247  L3_S50_F4249  \\\n",
       "0     -0.032      0.020  ...           NaN           NaN           NaN   \n",
       "1        NaN        NaN  ...           NaN           NaN           NaN   \n",
       "2     -0.072     -0.225  ...           NaN           NaN           NaN   \n",
       "3      0.128     -0.026  ...           NaN           NaN           NaN   \n",
       "4      0.168     -0.169  ...           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  L3_S51_F4258  L3_S51_F4260  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_F4262  Response  \n",
       "0           NaN         0  \n",
       "1           NaN         0  \n",
       "2           NaN         0  \n",
       "3           NaN         0  \n",
       "4           NaN         0  \n",
       "\n",
       "[5 rows x 970 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oh definitely, lets just say all these are floats.  And heeeeeeyyyyyy there is our target!\n",
    "print(num_df.shape)\n",
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1157)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S0_D3</th>\n",
       "      <th>L0_S0_D5</th>\n",
       "      <th>L0_S0_D7</th>\n",
       "      <th>L0_S0_D9</th>\n",
       "      <th>L0_S0_D11</th>\n",
       "      <th>L0_S0_D13</th>\n",
       "      <th>L0_S0_D15</th>\n",
       "      <th>L0_S0_D17</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_D4246</th>\n",
       "      <th>L3_S50_D4248</th>\n",
       "      <th>L3_S50_D4250</th>\n",
       "      <th>L3_S50_D4252</th>\n",
       "      <th>L3_S50_D4254</th>\n",
       "      <th>L3_S51_D4255</th>\n",
       "      <th>L3_S51_D4257</th>\n",
       "      <th>L3_S51_D4259</th>\n",
       "      <th>L3_S51_D4261</th>\n",
       "      <th>L3_S51_D4263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  L0_S0_D1  L0_S0_D3  L0_S0_D5  L0_S0_D7  L0_S0_D9  L0_S0_D11  L0_S0_D13  \\\n",
       "0   4     82.24     82.24     82.24     82.24     82.24      82.24      82.24   \n",
       "1   6       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "2   7   1618.70   1618.70   1618.70   1618.70   1618.70    1618.70    1618.70   \n",
       "3   9   1149.20   1149.20   1149.20   1149.20   1149.20    1149.20    1149.20   \n",
       "4  11    602.64    602.64    602.64    602.64    602.64     602.64     602.64   \n",
       "\n",
       "   L0_S0_D15  L0_S0_D17  ...  L3_S50_D4246  L3_S50_D4248  L3_S50_D4250  \\\n",
       "0      82.24      82.24  ...           NaN           NaN           NaN   \n",
       "1        NaN        NaN  ...           NaN           NaN           NaN   \n",
       "2    1618.70    1618.70  ...           NaN           NaN           NaN   \n",
       "3    1149.20    1149.20  ...           NaN           NaN           NaN   \n",
       "4     602.64     602.64  ...           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S50_D4252  L3_S50_D4254  L3_S51_D4255  L3_S51_D4257  L3_S51_D4259  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_D4261  L3_S51_D4263  \n",
       "0           NaN           NaN  \n",
       "1           NaN           NaN  \n",
       "2           NaN           NaN  \n",
       "3           NaN           NaN  \n",
       "4           NaN           NaN  \n",
       "\n",
       "[5 rows x 1157 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#this one is a weirdo.  I read the reference, and it is a little strange. so L0_S0_D1 is the\n",
    "#timestamp recorded at L0_S0_F0, and L0_S0_D3 is the timestamp from L0_S0_F2.  What a weirdo\n",
    "#way to encode that. I assume there is some reason why.\n",
    "print(date_df.shape)\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose your target\n",
    "My target is ```Response``` in the numerical dataset (of all places).  It is a binary categorical of 0 and 1.<br>\n",
    "1 = Failed QC<br>\n",
    "0 = Passed QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "I'm ultimately looking to classify each unique ID in the test set to a pass or failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Distribution\n",
    "Target is binary, so only two classes<br>\n",
    "Target is pretty imbalanced, but that is to be expected for quality checks<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183747,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Okay, I feel like I can read in the entier Response column to get an idea of how my datat is\n",
    "#distributed\n",
    "\n",
    "#okay read in only the response column and squeeze it into a series.\n",
    "response = pd.read_csv(folder + 'train_numeric.csv', usecols = ['Response'], squeeze = True)\n",
    "print(response.shape)\n",
    "response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1176868\n",
       "1       6879\n",
       "Name: Response, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#okay that looks really imbalanced, but thats not crazy for the type of problem.\n",
    "#if you were failing qc in a manufacturing environment a \"balanced\" amount of time you would\n",
    "#just be bleeding money out.\n",
    "response.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metric\n",
    "So accuracy isn't going to cut it for our needs.  Lets just do a confusion matrix and figure this out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                 | Predicted Failed                                                                                                                                          | Predicted Passed                                                                                                                                     |\n",
    "|-----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Actually Failed | Sweet                                                                                                                                                     | Part goes to production, product made, possibly fails in field, loss of consumer faith, high complexity cost and monetary cost of reverse logistics. |\n",
    "| Actually Passed | Part gets binned for rework.  Best case, is identified as good during rework. Worst case classified as wastage. I'd expect lower overall cost and impact. | Sweet                                                                                                                                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay I think we figured it out.  False positive is our biggest concern here.  Not at the expense of false negatives, they do have some cost.  So I'm thinking we highly prioritize precision, but maybe lets say an 80/20 split for now.  I'll re-evaluate as time goes by."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose observations to train, validate and test\n",
    "#### Identifying Outliers\n",
    "This is likely going to take its own entire notebook, so it might be outside of the scope of this assignment tonight. The resource I got the data from indicates there may be outliers, so I will definitely have to spend a lot of time checking.\n",
    "#### What kind of split\n",
    "If I do a split (I really like cross validation), I'm likely to do a random split probably 80/20.  There are date timestamps in their own dataframe, but I don't expect a time split would be useful for my purposes.  I suspect that time doesn't play a huge predictive factor, but that is a hip shot right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
