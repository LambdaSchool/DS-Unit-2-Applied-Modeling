{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of assignment_applied_modeling_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhaSab5292/DS-Unit-2-Applied-Modeling/blob/master/Copy_of_assignment_applied_modeling_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 1*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Define ML problems\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your decisions.\n",
        "\n",
        "- [ ] Choose your target. Which column in your tabular dataset will you predict?\n",
        "- [ ] Choose which observations you will use to train, validate, and test your model. And which observations, if any, to exclude.\n",
        "- [ ] Determine whether your problem is regression or classification.\n",
        "- [ ] Choose your evaluation metric.\n",
        "- [ ] Begin to clean and explore your data.\n",
        "- [ ] Begin to choose which features, if any, to exclude. Would some features \"leak\" information from the future?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSZ12J7KPhJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flsOV6sX7VFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBfb7JwM6lhq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b6779db-7954-4a35-e1a4-0b6396558db5"
      },
      "source": [
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "# Split train into train & val. Make val the same size as test.\n",
        "train, val = train_test_split(train, test_size = len(test),  \n",
        "                              stratify = train[target], random_state = 42)\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((45042, 41), (14358, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHutdqw-AnoD",
        "colab_type": "text"
      },
      "source": [
        "# **Begin to clean and explore your data.  Begin to choose which features, if any, to exclude.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY-5FaC97ixg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # replace very small values with zeros.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', 'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "            \n",
        "    # drop duplicate columns\n",
        "    X = X.drop(columns = ['quantity_group', 'water_quality', 'extraction_type', \n",
        "                          'extraction_type_group', 'payment', 'source', 'waterpoint_type'])\n",
        "    X['quality_group'] = X['quality_group'].str.replace('good', 'soft')\n",
        "    X['payment_type'] = X['payment_type'].str.replace('on failure', 'upon failure')\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    X = X.drop(columns = ['recorded_by', 'id'])\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format = True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO4TR-rq_7KS",
        "colab_type": "text"
      },
      "source": [
        "# **Choose your target**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzWzMuvs8hb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "545feaed-913b-4a85-fc99-200e960fcf01"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Arrange data into X features matrix and y target vector\n",
        "# so we use the high-cardinality categoricals features\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns = target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns = target)\n",
        "y_val = val[target]\n",
        "X_test = test\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((45042, 33), (14358, 33), (14358, 33), (45042,), (14358,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70PHGYIBh348",
        "colab_type": "text"
      },
      "source": [
        "# **Choose your evaluation metric**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYh3PKH_-m4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3ab264cf-34e0-4441-e81b-a96231efe73e"
      },
      "source": [
        "y_train.value_counts(normalize = True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "functional                 0.543071\n",
              "non functional             0.384241\n",
              "functional needs repair    0.072688\n",
              "Name: status_group, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjJ3-ya-9Hpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bd843cfc-1e60-4e78-959e-60cfc686cc26"
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy = 'median'), \n",
        "    RandomForestClassifier(n_estimators = 100, random_state = 42, n_jobs = -1))\n",
        "\n",
        "# Fit on train\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Score on train and val\n",
        "print('Train Accuracy', pipeline.score(X_train, y_train))\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy 0.9999777984991786\n",
            "Validation Accuracy 0.8091656219529182\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}