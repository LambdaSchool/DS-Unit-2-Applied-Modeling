{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2ha9OWxf0jw"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hTictxWYih7"
   },
   "source": [
    "# Permutation & Boosting\n",
    "\n",
    "- Get **permutation importances** for model interpretation and feature selection\n",
    "- Use xgboost for **gradient boosting**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoxNYFBXYih9"
   },
   "source": [
    "### Default Feature Importances are fast, but Permutation Importances may be more accurate\n",
    "\n",
    "- Permutation Importances\n",
    "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
    "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "- (Default) Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
    "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
    "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
    "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
    "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
    "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy.\n",
    "\n",
    "#### Python libraries for Gradient Boosting\n",
    "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
    "  - Anaconda: already installed\n",
    "  - Google Colab: already installed\n",
    "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
    "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
    "  - Windows: `conda install -c anaconda py-xgboost`\n",
    "  - Google Colab: already installed\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
    "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
    "  - Google Colab: already installed\n",
    "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
    "  - Anaconda: `conda install -c conda-forge catboost`\n",
    "  - Google Colab: `pip install catboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMejJg0w8v76"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
    "\n",
    "Libraries:\n",
    "\n",
    "- category_encoders\n",
    "- [**eli5**](https://eli5.readthedocs.io/en/latest/)\n",
    "- matplotlib\n",
    "- numpy\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- [**xgboost**](https://xgboost.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFQMky3CYih-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "    !pip install eli5\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-TExplb_Slf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
    "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
    "\n",
    "\n",
    "# Split train into train & val\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "                              stratify=train['status_group'], random_state=42)\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
    "    \n",
    "    # Prevent SettingWithCopyWarning\n",
    "    X = X.copy()\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    # Also create a \"missing indicator\" column, because the fact that\n",
    "    # values are missing may be a predictive signal.\n",
    "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
    "                       'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col+'_MISSING'] = X[col].isnull()\n",
    "            \n",
    "    # Drop duplicate columns\n",
    "    duplicates = ['quantity_group', 'payment_type']\n",
    "    X = X.drop(columns=duplicates)\n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "    unusable_variance = ['recorded_by', 'id']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']\n",
    "    X['years_MISSING'] = X['years'].isnull()\n",
    "    \n",
    "    # return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhg8PQKt_jzP"
   },
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector\n",
    "target = 'status_group'\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=target)\n",
    "y_val = val[target]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8lB4z5l_eml"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8135521885521886\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HOayKBOYiit"
   },
   "source": [
    "# 3 types of feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4bRhsxENYiiu"
   },
   "source": [
    "## 1. (Default) Feature Importances\n",
    "\n",
    "Fastest, good for first estimates, but be aware:\n",
    "\n",
    "\n",
    "\n",
    ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
    "\n",
    "\n",
    " \n",
    " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNVm6f7mYiiu"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances\n",
    "rf = pipeline.named_steps['randomforestclassifier']\n",
    "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 20\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8HzLcCBYiiv"
   },
   "source": [
    "## 2. Drop-Column Importance\n",
    "\n",
    "The best in theory, but too slow in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQAOlERnYiiw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy without quantity: 0.7771043771043771\n",
      "Validation Accuracy with quantity: 0.8135521885521886\n",
      "Drop-Column Importance for quantity: 0.03644781144781151\n"
     ]
    }
   ],
   "source": [
    "column  = 'quantity'\n",
    "\n",
    "# Fit without column\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train.drop(columns=column), y_train)\n",
    "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
    "print(f'Validation Accuracy without {column}: {score_without}')\n",
    "\n",
    "# Fit with column\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "score_with = pipeline.score(X_val, y_val)\n",
    "print(f'Validation Accuracy with {column}: {score_with}')\n",
    "\n",
    "# Compare the error with & without column\n",
    "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Vu39wGkYiix"
   },
   "source": [
    "## 3. Permutation Importance\n",
    "\n",
    "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
    "\n",
    "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
    "\n",
    "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
    ">\n",
    "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
    ">\n",
    ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
    ">\n",
    ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYCiEx7zYiiy"
   },
   "source": [
    "### Do-It-Yourself way, for intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TksOf_n2Yiiy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290     insufficient\n",
       "47666    insufficient\n",
       "2538           enough\n",
       "53117          enough\n",
       "51817          enough\n",
       "Name: quantity, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEFORE: Sequence of the feature to be permuted\n",
    "feature = 'quantity'\n",
    "X_val[feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enough          6619\n",
       "insufficient    2976\n",
       "dry             1325\n",
       "seasonal         806\n",
       "unknown          154\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEFORE: Distribution of the feature to be permuted\n",
    "X_val[feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERMUTE!\n",
    "X_val_permuted = X_val.copy()\n",
    "X_val_permuted[feature] = np.random.permutation(X_val[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290           enough\n",
       "47666          enough\n",
       "2538           enough\n",
       "53117    insufficient\n",
       "51817        seasonal\n",
       "Name: quantity, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER: Sequence has changed\n",
    "X_val_permuted[feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enough          6619\n",
       "insufficient    2976\n",
       "dry             1325\n",
       "seasonal         806\n",
       "unknown          154\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER: Distribution hasn't changed!\n",
    "X_val_permuted[feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with quantity: 0.8135521885521886\n",
      "Validation accuracy with quantity permuted: 0.7135521885521886\n",
      "Permutation importance: 0.09999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Get the permutation importance\n",
    "# Notice that we don't need to refit here!\n",
    "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
    "\n",
    "print(f'Validation accuracy with {feature}: {score_with}')\n",
    "print(f'Validation accuracy with {feature} permuted: {score_permuted}')\n",
    "print(f'Permutation importance: {score_with - score_permuted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy with wpt_name: 0.8135521885521886\n",
      "Validation accuracy with wpt_name permuted: 0.8123737373737374\n",
      "Permutation importance: 0.0011784511784511675\n"
     ]
    }
   ],
   "source": [
    "# Rerun the permutation importance process, but for a different feature\n",
    "feature = 'wpt_name'\n",
    "X_val_permuted = X_val.copy()\n",
    "X_val_permuted[feature] = np.random.permutation(X_val[feature])\n",
    "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
    "\n",
    "print(f'Validation accuracy with {feature}: {score_with}')\n",
    "print(f'Validation accuracy with {feature} permuted: {score_permuted}')\n",
    "print(f'Permutation importance: {score_with - score_permuted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LYk19SNYii7"
   },
   "source": [
    "### With eli5 library\n",
    "\n",
    "For more documentation on using this library, see:\n",
    "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
    "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
    "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
    "\n",
    "eli5 doesn't work with pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpSemTkFFP8i"
   },
   "outputs": [],
   "source": [
    "transformers = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed = transformers.fit_transform(X_train)\n",
    "X_val_transformed = transformers.transform(X_val)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(cv='prefit',\n",
       "                      estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=None,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=-1,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_state=42,\n",
       "                                                       verbose=0,\n",
       "                                                       warm_start=False),\n",
       "                      n_iter=5, random_state=42, refit=True,\n",
       "                      scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# 1. Calculate permutation importances\n",
    "permuter = PermutationImportance(\n",
    "    model, \n",
    "    scoring='accuracy', \n",
    "    n_iter=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X_val_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basin                       -0.001431\n",
       "quality_group               -0.000572\n",
       "management_group            -0.000488\n",
       "installer                   -0.000051\n",
       "source_type                 -0.000017\n",
       "construction_year_MISSING    0.000051\n",
       "gps_height_MISSING           0.000051\n",
       "latitude_MISSING             0.000135\n",
       "population_MISSING           0.000202\n",
       "year_recorded                0.000269\n",
       "source_class                 0.000337\n",
       "num_private                  0.000337\n",
       "management                   0.000455\n",
       "years_MISSING                0.000471\n",
       "extraction_type              0.000539\n",
       "water_quality                0.000539\n",
       "ward                         0.000539\n",
       "scheme_management            0.000657\n",
       "lga                          0.000724\n",
       "permit                       0.000774\n",
       "scheme_name                  0.000808\n",
       "longitude_MISSING            0.000875\n",
       "region_code                  0.000892\n",
       "region                       0.000926\n",
       "wpt_name                     0.000943\n",
       "month_recorded               0.001128\n",
       "funder                       0.001128\n",
       "day_recorded                 0.001498\n",
       "source                       0.001549\n",
       "gps_height                   0.001768\n",
       "extraction_type_group        0.001785\n",
       "district_code                0.002239\n",
       "construction_year            0.002609\n",
       "public_meeting               0.002963\n",
       "years                        0.002980\n",
       "subvillage                   0.003030\n",
       "payment                      0.003064\n",
       "latitude                     0.006246\n",
       "population                   0.006414\n",
       "waterpoint_type_group        0.006751\n",
       "longitude                    0.008838\n",
       "extraction_type_class        0.010168\n",
       "waterpoint_type              0.010354\n",
       "amount_tsh                   0.010758\n",
       "quantity                     0.101633\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X_val.columns.tolist()\n",
    "pd.Series(permuter.feature_importances_, feature_names).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1016\n",
       "                \n",
       "                    &plusmn; 0.0029\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                quantity\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.85%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0108\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                amount_tsh\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0104\n",
       "                \n",
       "                    &plusmn; 0.0018\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                waterpoint_type\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0102\n",
       "                \n",
       "                    &plusmn; 0.0015\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                extraction_type_class\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0088\n",
       "                \n",
       "                    &plusmn; 0.0015\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                longitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0068\n",
       "                \n",
       "                    &plusmn; 0.0018\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                waterpoint_type_group\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.11%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0064\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                population\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0026\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                latitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0031\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                payment\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "                    &plusmn; 0.0015\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                subvillage\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "                    &plusmn; 0.0026\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                years\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                public_meeting\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0029\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                construction_year\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                district_code\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0015\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                extraction_type_group\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0018\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                gps_height\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.93%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                source\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0015\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                day_recorded\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                funder\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                month_recorded\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                wpt_name\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                region\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                region_code\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                longitude_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                scheme_name\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                permit\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lga\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                scheme_management\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ward\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                water_quality\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                extraction_type\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                years_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0021\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                management\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_private\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                source_class\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                year_recorded\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.74%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                population_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                latitude_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                gps_height_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                construction_year_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.95%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0000\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                source_type\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0001\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                installer\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0005\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                management_group\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0006\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                quality_group\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.99%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0014\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                basin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Display permutation importances\n",
    "eli5.show_weights(\n",
    "    permuter, \n",
    "    top=None, # show permutation importances for all features\n",
    "    feature_names=feature_names # must be a list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q07yW9k-Yii8"
   },
   "source": [
    "### We can use importances for feature selection\n",
    "\n",
    "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZrPFyEMYii9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing features: (47520, 45)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before removing features:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_importance = 0\n",
    "mask = permuter.feature_importances_ > minimum_importance\n",
    "features = X_train.columns[mask]\n",
    "X_train = X_train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing features: (47520, 40)\n"
     ]
    }
   ],
   "source": [
    "print('Shape after removing features:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8117003367003367\n"
     ]
    }
   ],
   "source": [
    "X_val = X_val[features]\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True, False,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True, False, False,  True,  True,  True,\n",
       "        True, False, False, False, False,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuter.feature_importances_ - permuter.feature_importances_std_ > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fl67bCR7WY6j"
   },
   "source": [
    "## Use xgboost for gradient boosting\n",
    "\n",
    "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsnJRKjfWYph"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'subvillage',\n",
       "                                      'region', 'lga', 'ward', 'public_meeting',\n",
       "                                      'scheme_management', 'scheme_name',\n",
       "                                      'permit', 'extraction_type',\n",
       "                                      'extraction_type_group',\n",
       "                                      'extraction_type_class', 'management',\n",
       "                                      'payment', 'water_quality', 'quantity',\n",
       "                                      'source', 'source_class',\n",
       "                                      'waterpoint_type',\n",
       "                                      'waterpoin...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
       "                               objective='multi:softprob', random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.7457070707070707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = pipeline.predict(X_val)\n",
    "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ubb7Ot6OZcK1"
   },
   "source": [
    "### Understand the difference between boosting & bagging\n",
    "\n",
    "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
    "\n",
    "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
    "\n",
    ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
    ">\n",
    ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
    ">\n",
    ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
    ">\n",
    ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
    ">\n",
    ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCjVSlD_XJr2"
   },
   "source": [
    "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
    "\n",
    "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
    "\n",
    "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
    "\n",
    "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
    "\n",
    "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
    "\n",
    "#### XGBoost parameters\n",
    "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
    "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNX3IKftXBFS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.250884\tvalidation_1-merror:0.261953\n",
      "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-merror:0.252294\tvalidation_1-merror:0.264057\n",
      "[2]\tvalidation_0-merror:0.251747\tvalidation_1-merror:0.264731\n",
      "[3]\tvalidation_0-merror:0.249895\tvalidation_1-merror:0.262037\n",
      "[4]\tvalidation_0-merror:0.248864\tvalidation_1-merror:0.26069\n",
      "[5]\tvalidation_0-merror:0.24678\tvalidation_1-merror:0.257239\n",
      "[6]\tvalidation_0-merror:0.243687\tvalidation_1-merror:0.255051\n",
      "[7]\tvalidation_0-merror:0.240404\tvalidation_1-merror:0.250421\n",
      "[8]\tvalidation_0-merror:0.2379\tvalidation_1-merror:0.248316\n",
      "[9]\tvalidation_0-merror:0.235816\tvalidation_1-merror:0.247054\n",
      "[10]\tvalidation_0-merror:0.234975\tvalidation_1-merror:0.24596\n",
      "[11]\tvalidation_0-merror:0.23388\tvalidation_1-merror:0.245118\n",
      "[12]\tvalidation_0-merror:0.233228\tvalidation_1-merror:0.245286\n",
      "[13]\tvalidation_0-merror:0.231776\tvalidation_1-merror:0.244529\n",
      "[14]\tvalidation_0-merror:0.232008\tvalidation_1-merror:0.244529\n",
      "[15]\tvalidation_0-merror:0.230535\tvalidation_1-merror:0.243855\n",
      "[16]\tvalidation_0-merror:0.229104\tvalidation_1-merror:0.241835\n",
      "[17]\tvalidation_0-merror:0.228325\tvalidation_1-merror:0.241919\n",
      "[18]\tvalidation_0-merror:0.227125\tvalidation_1-merror:0.239899\n",
      "[19]\tvalidation_0-merror:0.226515\tvalidation_1-merror:0.238973\n",
      "[20]\tvalidation_0-merror:0.225526\tvalidation_1-merror:0.238973\n",
      "[21]\tvalidation_0-merror:0.224495\tvalidation_1-merror:0.237626\n",
      "[22]\tvalidation_0-merror:0.22298\tvalidation_1-merror:0.23569\n",
      "[23]\tvalidation_0-merror:0.221843\tvalidation_1-merror:0.235522\n",
      "[24]\tvalidation_0-merror:0.221044\tvalidation_1-merror:0.235774\n",
      "[25]\tvalidation_0-merror:0.220244\tvalidation_1-merror:0.235269\n",
      "[26]\tvalidation_0-merror:0.218939\tvalidation_1-merror:0.234428\n",
      "[27]\tvalidation_0-merror:0.217151\tvalidation_1-merror:0.232492\n",
      "[28]\tvalidation_0-merror:0.215109\tvalidation_1-merror:0.230892\n",
      "[29]\tvalidation_0-merror:0.213636\tvalidation_1-merror:0.229882\n",
      "[30]\tvalidation_0-merror:0.212563\tvalidation_1-merror:0.228283\n",
      "[31]\tvalidation_0-merror:0.211132\tvalidation_1-merror:0.227357\n",
      "[32]\tvalidation_0-merror:0.209996\tvalidation_1-merror:0.227104\n",
      "[33]\tvalidation_0-merror:0.209049\tvalidation_1-merror:0.226683\n",
      "[34]\tvalidation_0-merror:0.207765\tvalidation_1-merror:0.226515\n",
      "[35]\tvalidation_0-merror:0.206734\tvalidation_1-merror:0.226347\n",
      "[36]\tvalidation_0-merror:0.205724\tvalidation_1-merror:0.225589\n",
      "[37]\tvalidation_0-merror:0.204882\tvalidation_1-merror:0.225168\n",
      "[38]\tvalidation_0-merror:0.203998\tvalidation_1-merror:0.224158\n",
      "[39]\tvalidation_0-merror:0.20221\tvalidation_1-merror:0.222475\n",
      "[40]\tvalidation_0-merror:0.200968\tvalidation_1-merror:0.221633\n",
      "[41]\tvalidation_0-merror:0.199474\tvalidation_1-merror:0.220539\n",
      "[42]\tvalidation_0-merror:0.198695\tvalidation_1-merror:0.220707\n",
      "[43]\tvalidation_0-merror:0.197769\tvalidation_1-merror:0.220286\n",
      "[44]\tvalidation_0-merror:0.196275\tvalidation_1-merror:0.219613\n",
      "[45]\tvalidation_0-merror:0.195707\tvalidation_1-merror:0.219108\n",
      "[46]\tvalidation_0-merror:0.194739\tvalidation_1-merror:0.218266\n",
      "[47]\tvalidation_0-merror:0.194192\tvalidation_1-merror:0.217172\n",
      "[48]\tvalidation_0-merror:0.193287\tvalidation_1-merror:0.217172\n",
      "[49]\tvalidation_0-merror:0.192466\tvalidation_1-merror:0.216667\n",
      "[50]\tvalidation_0-merror:0.19194\tvalidation_1-merror:0.216835\n",
      "[51]\tvalidation_0-merror:0.191225\tvalidation_1-merror:0.216077\n",
      "[52]\tvalidation_0-merror:0.190278\tvalidation_1-merror:0.215152\n",
      "[53]\tvalidation_0-merror:0.18971\tvalidation_1-merror:0.21431\n",
      "[54]\tvalidation_0-merror:0.189205\tvalidation_1-merror:0.214478\n",
      "[55]\tvalidation_0-merror:0.188279\tvalidation_1-merror:0.212879\n",
      "[56]\tvalidation_0-merror:0.187184\tvalidation_1-merror:0.212795\n",
      "[57]\tvalidation_0-merror:0.186385\tvalidation_1-merror:0.211953\n",
      "[58]\tvalidation_0-merror:0.185501\tvalidation_1-merror:0.211448\n",
      "[59]\tvalidation_0-merror:0.18487\tvalidation_1-merror:0.211448\n",
      "[60]\tvalidation_0-merror:0.184364\tvalidation_1-merror:0.211364\n",
      "[61]\tvalidation_0-merror:0.183586\tvalidation_1-merror:0.210859\n",
      "[62]\tvalidation_0-merror:0.183123\tvalidation_1-merror:0.21069\n",
      "[63]\tvalidation_0-merror:0.182302\tvalidation_1-merror:0.210354\n",
      "[64]\tvalidation_0-merror:0.182029\tvalidation_1-merror:0.210522\n",
      "[65]\tvalidation_0-merror:0.181839\tvalidation_1-merror:0.209512\n",
      "[66]\tvalidation_0-merror:0.181145\tvalidation_1-merror:0.209259\n",
      "[67]\tvalidation_0-merror:0.180745\tvalidation_1-merror:0.209259\n",
      "[68]\tvalidation_0-merror:0.180156\tvalidation_1-merror:0.208923\n",
      "[69]\tvalidation_0-merror:0.179735\tvalidation_1-merror:0.208923\n",
      "[70]\tvalidation_0-merror:0.179398\tvalidation_1-merror:0.208754\n",
      "[71]\tvalidation_0-merror:0.178767\tvalidation_1-merror:0.208923\n",
      "[72]\tvalidation_0-merror:0.17822\tvalidation_1-merror:0.208923\n",
      "[73]\tvalidation_0-merror:0.177946\tvalidation_1-merror:0.209091\n",
      "[74]\tvalidation_0-merror:0.176684\tvalidation_1-merror:0.208502\n",
      "[75]\tvalidation_0-merror:0.176157\tvalidation_1-merror:0.207997\n",
      "[76]\tvalidation_0-merror:0.175231\tvalidation_1-merror:0.207576\n",
      "[77]\tvalidation_0-merror:0.174958\tvalidation_1-merror:0.208165\n",
      "[78]\tvalidation_0-merror:0.174579\tvalidation_1-merror:0.206313\n",
      "[79]\tvalidation_0-merror:0.17399\tvalidation_1-merror:0.206145\n",
      "[80]\tvalidation_0-merror:0.173695\tvalidation_1-merror:0.205556\n",
      "[81]\tvalidation_0-merror:0.17338\tvalidation_1-merror:0.205135\n",
      "[82]\tvalidation_0-merror:0.173211\tvalidation_1-merror:0.205219\n",
      "[83]\tvalidation_0-merror:0.172727\tvalidation_1-merror:0.204798\n",
      "[84]\tvalidation_0-merror:0.172306\tvalidation_1-merror:0.204798\n",
      "[85]\tvalidation_0-merror:0.171928\tvalidation_1-merror:0.204714\n",
      "[86]\tvalidation_0-merror:0.171907\tvalidation_1-merror:0.204545\n",
      "[87]\tvalidation_0-merror:0.17138\tvalidation_1-merror:0.204209\n",
      "[88]\tvalidation_0-merror:0.170581\tvalidation_1-merror:0.204545\n",
      "[89]\tvalidation_0-merror:0.17037\tvalidation_1-merror:0.204293\n",
      "[90]\tvalidation_0-merror:0.169634\tvalidation_1-merror:0.204461\n",
      "[91]\tvalidation_0-merror:0.169423\tvalidation_1-merror:0.204545\n",
      "[92]\tvalidation_0-merror:0.169213\tvalidation_1-merror:0.204377\n",
      "[93]\tvalidation_0-merror:0.168624\tvalidation_1-merror:0.204545\n",
      "[94]\tvalidation_0-merror:0.168119\tvalidation_1-merror:0.204377\n",
      "[95]\tvalidation_0-merror:0.167908\tvalidation_1-merror:0.204377\n",
      "[96]\tvalidation_0-merror:0.167551\tvalidation_1-merror:0.204545\n",
      "[97]\tvalidation_0-merror:0.167424\tvalidation_1-merror:0.204461\n",
      "[98]\tvalidation_0-merror:0.167109\tvalidation_1-merror:0.204377\n",
      "[99]\tvalidation_0-merror:0.166561\tvalidation_1-merror:0.204293\n",
      "[100]\tvalidation_0-merror:0.166246\tvalidation_1-merror:0.203788\n",
      "[101]\tvalidation_0-merror:0.166077\tvalidation_1-merror:0.203367\n",
      "[102]\tvalidation_0-merror:0.16553\tvalidation_1-merror:0.203704\n",
      "[103]\tvalidation_0-merror:0.165236\tvalidation_1-merror:0.20362\n",
      "[104]\tvalidation_0-merror:0.164857\tvalidation_1-merror:0.20362\n",
      "[105]\tvalidation_0-merror:0.164583\tvalidation_1-merror:0.203704\n",
      "[106]\tvalidation_0-merror:0.164394\tvalidation_1-merror:0.203114\n",
      "[107]\tvalidation_0-merror:0.164141\tvalidation_1-merror:0.203199\n",
      "[108]\tvalidation_0-merror:0.163784\tvalidation_1-merror:0.203451\n",
      "[109]\tvalidation_0-merror:0.163237\tvalidation_1-merror:0.203367\n",
      "[110]\tvalidation_0-merror:0.163047\tvalidation_1-merror:0.203283\n",
      "[111]\tvalidation_0-merror:0.162584\tvalidation_1-merror:0.202778\n",
      "[112]\tvalidation_0-merror:0.162353\tvalidation_1-merror:0.202694\n",
      "[113]\tvalidation_0-merror:0.162163\tvalidation_1-merror:0.203114\n",
      "[114]\tvalidation_0-merror:0.161848\tvalidation_1-merror:0.202778\n",
      "[115]\tvalidation_0-merror:0.161616\tvalidation_1-merror:0.202609\n",
      "[116]\tvalidation_0-merror:0.161258\tvalidation_1-merror:0.202525\n",
      "[117]\tvalidation_0-merror:0.161027\tvalidation_1-merror:0.20303\n",
      "[118]\tvalidation_0-merror:0.160354\tvalidation_1-merror:0.203283\n",
      "[119]\tvalidation_0-merror:0.159891\tvalidation_1-merror:0.202946\n",
      "[120]\tvalidation_0-merror:0.159638\tvalidation_1-merror:0.202946\n",
      "[121]\tvalidation_0-merror:0.159322\tvalidation_1-merror:0.202778\n",
      "[122]\tvalidation_0-merror:0.159049\tvalidation_1-merror:0.202946\n",
      "[123]\tvalidation_0-merror:0.158228\tvalidation_1-merror:0.20202\n",
      "[124]\tvalidation_0-merror:0.158228\tvalidation_1-merror:0.201852\n",
      "[125]\tvalidation_0-merror:0.157639\tvalidation_1-merror:0.20202\n",
      "[126]\tvalidation_0-merror:0.157302\tvalidation_1-merror:0.20202\n",
      "[127]\tvalidation_0-merror:0.156692\tvalidation_1-merror:0.201431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128]\tvalidation_0-merror:0.156629\tvalidation_1-merror:0.201178\n",
      "[129]\tvalidation_0-merror:0.156313\tvalidation_1-merror:0.201347\n",
      "[130]\tvalidation_0-merror:0.156124\tvalidation_1-merror:0.200926\n",
      "[131]\tvalidation_0-merror:0.155997\tvalidation_1-merror:0.201263\n",
      "[132]\tvalidation_0-merror:0.155829\tvalidation_1-merror:0.201094\n",
      "[133]\tvalidation_0-merror:0.155513\tvalidation_1-merror:0.200589\n",
      "[134]\tvalidation_0-merror:0.154651\tvalidation_1-merror:0.200673\n",
      "[135]\tvalidation_0-merror:0.154461\tvalidation_1-merror:0.200673\n",
      "[136]\tvalidation_0-merror:0.154209\tvalidation_1-merror:0.200589\n",
      "[137]\tvalidation_0-merror:0.153746\tvalidation_1-merror:0.200337\n",
      "[138]\tvalidation_0-merror:0.153367\tvalidation_1-merror:0.2\n",
      "[139]\tvalidation_0-merror:0.152883\tvalidation_1-merror:0.199832\n",
      "[140]\tvalidation_0-merror:0.152462\tvalidation_1-merror:0.2\n",
      "[141]\tvalidation_0-merror:0.152189\tvalidation_1-merror:0.200168\n",
      "[142]\tvalidation_0-merror:0.151915\tvalidation_1-merror:0.200337\n",
      "[143]\tvalidation_0-merror:0.15162\tvalidation_1-merror:0.200168\n",
      "[144]\tvalidation_0-merror:0.151494\tvalidation_1-merror:0.199916\n",
      "[145]\tvalidation_0-merror:0.151115\tvalidation_1-merror:0.2\n",
      "[146]\tvalidation_0-merror:0.150758\tvalidation_1-merror:0.199663\n",
      "[147]\tvalidation_0-merror:0.15061\tvalidation_1-merror:0.199411\n",
      "[148]\tvalidation_0-merror:0.149874\tvalidation_1-merror:0.199579\n",
      "[149]\tvalidation_0-merror:0.149369\tvalidation_1-merror:0.199327\n",
      "[150]\tvalidation_0-merror:0.149158\tvalidation_1-merror:0.199158\n",
      "[151]\tvalidation_0-merror:0.148843\tvalidation_1-merror:0.199663\n",
      "[152]\tvalidation_0-merror:0.148506\tvalidation_1-merror:0.199832\n",
      "[153]\tvalidation_0-merror:0.14838\tvalidation_1-merror:0.2\n",
      "[154]\tvalidation_0-merror:0.148001\tvalidation_1-merror:0.199242\n",
      "[155]\tvalidation_0-merror:0.14779\tvalidation_1-merror:0.199327\n",
      "[156]\tvalidation_0-merror:0.147517\tvalidation_1-merror:0.199579\n",
      "[157]\tvalidation_0-merror:0.147559\tvalidation_1-merror:0.199747\n",
      "[158]\tvalidation_0-merror:0.147054\tvalidation_1-merror:0.199663\n",
      "[159]\tvalidation_0-merror:0.146949\tvalidation_1-merror:0.199832\n",
      "[160]\tvalidation_0-merror:0.146591\tvalidation_1-merror:0.199411\n",
      "[161]\tvalidation_0-merror:0.146444\tvalidation_1-merror:0.199579\n",
      "[162]\tvalidation_0-merror:0.146233\tvalidation_1-merror:0.199411\n",
      "[163]\tvalidation_0-merror:0.146065\tvalidation_1-merror:0.198906\n",
      "[164]\tvalidation_0-merror:0.145644\tvalidation_1-merror:0.198569\n",
      "[165]\tvalidation_0-merror:0.145118\tvalidation_1-merror:0.198148\n",
      "[166]\tvalidation_0-merror:0.144592\tvalidation_1-merror:0.198401\n",
      "[167]\tvalidation_0-merror:0.144129\tvalidation_1-merror:0.198316\n",
      "[168]\tvalidation_0-merror:0.143813\tvalidation_1-merror:0.198232\n",
      "[169]\tvalidation_0-merror:0.14354\tvalidation_1-merror:0.197896\n",
      "[170]\tvalidation_0-merror:0.143119\tvalidation_1-merror:0.197727\n",
      "[171]\tvalidation_0-merror:0.142761\tvalidation_1-merror:0.19798\n",
      "[172]\tvalidation_0-merror:0.142635\tvalidation_1-merror:0.198232\n",
      "[173]\tvalidation_0-merror:0.142277\tvalidation_1-merror:0.198401\n",
      "[174]\tvalidation_0-merror:0.142045\tvalidation_1-merror:0.198148\n",
      "[175]\tvalidation_0-merror:0.141582\tvalidation_1-merror:0.198148\n",
      "[176]\tvalidation_0-merror:0.141246\tvalidation_1-merror:0.198064\n",
      "[177]\tvalidation_0-merror:0.140783\tvalidation_1-merror:0.198401\n",
      "[178]\tvalidation_0-merror:0.14053\tvalidation_1-merror:0.198148\n",
      "[179]\tvalidation_0-merror:0.140109\tvalidation_1-merror:0.198064\n",
      "[180]\tvalidation_0-merror:0.139752\tvalidation_1-merror:0.198064\n",
      "[181]\tvalidation_0-merror:0.139773\tvalidation_1-merror:0.197811\n",
      "[182]\tvalidation_0-merror:0.139436\tvalidation_1-merror:0.197559\n",
      "[183]\tvalidation_0-merror:0.139247\tvalidation_1-merror:0.197475\n",
      "[184]\tvalidation_0-merror:0.138889\tvalidation_1-merror:0.197306\n",
      "[185]\tvalidation_0-merror:0.138636\tvalidation_1-merror:0.197222\n",
      "[186]\tvalidation_0-merror:0.138173\tvalidation_1-merror:0.196886\n",
      "[187]\tvalidation_0-merror:0.137921\tvalidation_1-merror:0.196886\n",
      "[188]\tvalidation_0-merror:0.137858\tvalidation_1-merror:0.19697\n",
      "[189]\tvalidation_0-merror:0.137521\tvalidation_1-merror:0.197054\n",
      "[190]\tvalidation_0-merror:0.137395\tvalidation_1-merror:0.19697\n",
      "[191]\tvalidation_0-merror:0.137205\tvalidation_1-merror:0.197138\n",
      "[192]\tvalidation_0-merror:0.136953\tvalidation_1-merror:0.197054\n",
      "[193]\tvalidation_0-merror:0.136532\tvalidation_1-merror:0.19697\n",
      "[194]\tvalidation_0-merror:0.136574\tvalidation_1-merror:0.197138\n",
      "[195]\tvalidation_0-merror:0.136322\tvalidation_1-merror:0.197138\n",
      "[196]\tvalidation_0-merror:0.136153\tvalidation_1-merror:0.19697\n",
      "[197]\tvalidation_0-merror:0.135795\tvalidation_1-merror:0.196717\n",
      "[198]\tvalidation_0-merror:0.135396\tvalidation_1-merror:0.196465\n",
      "[199]\tvalidation_0-merror:0.13529\tvalidation_1-merror:0.196801\n",
      "[200]\tvalidation_0-merror:0.13508\tvalidation_1-merror:0.196801\n",
      "[201]\tvalidation_0-merror:0.13487\tvalidation_1-merror:0.195875\n",
      "[202]\tvalidation_0-merror:0.134301\tvalidation_1-merror:0.195623\n",
      "[203]\tvalidation_0-merror:0.134133\tvalidation_1-merror:0.195791\n",
      "[204]\tvalidation_0-merror:0.133965\tvalidation_1-merror:0.195875\n",
      "[205]\tvalidation_0-merror:0.133691\tvalidation_1-merror:0.19596\n",
      "[206]\tvalidation_0-merror:0.133333\tvalidation_1-merror:0.195875\n",
      "[207]\tvalidation_0-merror:0.132849\tvalidation_1-merror:0.196296\n",
      "[208]\tvalidation_0-merror:0.132723\tvalidation_1-merror:0.196128\n",
      "[209]\tvalidation_0-merror:0.132555\tvalidation_1-merror:0.195875\n",
      "[210]\tvalidation_0-merror:0.132323\tvalidation_1-merror:0.195875\n",
      "[211]\tvalidation_0-merror:0.132176\tvalidation_1-merror:0.195875\n",
      "[212]\tvalidation_0-merror:0.13205\tvalidation_1-merror:0.195791\n",
      "[213]\tvalidation_0-merror:0.131797\tvalidation_1-merror:0.19596\n",
      "[214]\tvalidation_0-merror:0.131503\tvalidation_1-merror:0.196212\n",
      "[215]\tvalidation_0-merror:0.131418\tvalidation_1-merror:0.19596\n",
      "[216]\tvalidation_0-merror:0.131082\tvalidation_1-merror:0.195707\n",
      "[217]\tvalidation_0-merror:0.130598\tvalidation_1-merror:0.195455\n",
      "[218]\tvalidation_0-merror:0.130282\tvalidation_1-merror:0.19537\n",
      "[219]\tvalidation_0-merror:0.130261\tvalidation_1-merror:0.195455\n",
      "[220]\tvalidation_0-merror:0.129798\tvalidation_1-merror:0.196128\n",
      "[221]\tvalidation_0-merror:0.129672\tvalidation_1-merror:0.196296\n",
      "[222]\tvalidation_0-merror:0.129545\tvalidation_1-merror:0.196128\n",
      "[223]\tvalidation_0-merror:0.129188\tvalidation_1-merror:0.196212\n",
      "[224]\tvalidation_0-merror:0.128809\tvalidation_1-merror:0.19596\n",
      "[225]\tvalidation_0-merror:0.128598\tvalidation_1-merror:0.195623\n",
      "[226]\tvalidation_0-merror:0.128598\tvalidation_1-merror:0.19596\n",
      "[227]\tvalidation_0-merror:0.128346\tvalidation_1-merror:0.195539\n",
      "[228]\tvalidation_0-merror:0.12782\tvalidation_1-merror:0.195539\n",
      "[229]\tvalidation_0-merror:0.12742\tvalidation_1-merror:0.195286\n",
      "[230]\tvalidation_0-merror:0.127273\tvalidation_1-merror:0.195286\n",
      "[231]\tvalidation_0-merror:0.127104\tvalidation_1-merror:0.194865\n",
      "[232]\tvalidation_0-merror:0.126747\tvalidation_1-merror:0.195118\n",
      "[233]\tvalidation_0-merror:0.126515\tvalidation_1-merror:0.194949\n",
      "[234]\tvalidation_0-merror:0.125884\tvalidation_1-merror:0.195202\n",
      "[235]\tvalidation_0-merror:0.125274\tvalidation_1-merror:0.195455\n",
      "[236]\tvalidation_0-merror:0.125253\tvalidation_1-merror:0.195539\n",
      "[237]\tvalidation_0-merror:0.124979\tvalidation_1-merror:0.195118\n",
      "[238]\tvalidation_0-merror:0.1246\tvalidation_1-merror:0.195202\n",
      "[239]\tvalidation_0-merror:0.124474\tvalidation_1-merror:0.19537\n",
      "[240]\tvalidation_0-merror:0.124116\tvalidation_1-merror:0.195118\n",
      "[241]\tvalidation_0-merror:0.123927\tvalidation_1-merror:0.195202\n",
      "[242]\tvalidation_0-merror:0.123569\tvalidation_1-merror:0.195455\n",
      "[243]\tvalidation_0-merror:0.123274\tvalidation_1-merror:0.195286\n",
      "[244]\tvalidation_0-merror:0.123106\tvalidation_1-merror:0.195118\n",
      "[245]\tvalidation_0-merror:0.122875\tvalidation_1-merror:0.195286\n",
      "[246]\tvalidation_0-merror:0.122559\tvalidation_1-merror:0.195202\n",
      "[247]\tvalidation_0-merror:0.122201\tvalidation_1-merror:0.195455\n",
      "[248]\tvalidation_0-merror:0.121949\tvalidation_1-merror:0.195539\n",
      "[249]\tvalidation_0-merror:0.121886\tvalidation_1-merror:0.195455\n",
      "[250]\tvalidation_0-merror:0.121549\tvalidation_1-merror:0.195539\n",
      "[251]\tvalidation_0-merror:0.121149\tvalidation_1-merror:0.194865\n",
      "[252]\tvalidation_0-merror:0.121002\tvalidation_1-merror:0.194697\n",
      "[253]\tvalidation_0-merror:0.120749\tvalidation_1-merror:0.194781\n",
      "[254]\tvalidation_0-merror:0.120518\tvalidation_1-merror:0.194697\n",
      "[255]\tvalidation_0-merror:0.120118\tvalidation_1-merror:0.194865\n",
      "[256]\tvalidation_0-merror:0.119844\tvalidation_1-merror:0.194781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257]\tvalidation_0-merror:0.119802\tvalidation_1-merror:0.194865\n",
      "[258]\tvalidation_0-merror:0.119423\tvalidation_1-merror:0.194781\n",
      "[259]\tvalidation_0-merror:0.119297\tvalidation_1-merror:0.194865\n",
      "[260]\tvalidation_0-merror:0.119108\tvalidation_1-merror:0.195202\n",
      "[261]\tvalidation_0-merror:0.118708\tvalidation_1-merror:0.194949\n",
      "[262]\tvalidation_0-merror:0.118519\tvalidation_1-merror:0.194276\n",
      "[263]\tvalidation_0-merror:0.118434\tvalidation_1-merror:0.194529\n",
      "[264]\tvalidation_0-merror:0.117971\tvalidation_1-merror:0.194192\n",
      "[265]\tvalidation_0-merror:0.117551\tvalidation_1-merror:0.194529\n",
      "[266]\tvalidation_0-merror:0.117424\tvalidation_1-merror:0.194697\n",
      "[267]\tvalidation_0-merror:0.117151\tvalidation_1-merror:0.194865\n",
      "[268]\tvalidation_0-merror:0.116793\tvalidation_1-merror:0.194529\n",
      "[269]\tvalidation_0-merror:0.116625\tvalidation_1-merror:0.194276\n",
      "[270]\tvalidation_0-merror:0.116309\tvalidation_1-merror:0.194276\n",
      "[271]\tvalidation_0-merror:0.11612\tvalidation_1-merror:0.19436\n",
      "[272]\tvalidation_0-merror:0.115825\tvalidation_1-merror:0.193855\n",
      "[273]\tvalidation_0-merror:0.115741\tvalidation_1-merror:0.193855\n",
      "[274]\tvalidation_0-merror:0.115067\tvalidation_1-merror:0.193939\n",
      "[275]\tvalidation_0-merror:0.114625\tvalidation_1-merror:0.193771\n",
      "[276]\tvalidation_0-merror:0.114457\tvalidation_1-merror:0.194108\n",
      "[277]\tvalidation_0-merror:0.114226\tvalidation_1-merror:0.194276\n",
      "[278]\tvalidation_0-merror:0.113973\tvalidation_1-merror:0.194024\n",
      "[279]\tvalidation_0-merror:0.113763\tvalidation_1-merror:0.193434\n",
      "[280]\tvalidation_0-merror:0.11351\tvalidation_1-merror:0.193687\n",
      "[281]\tvalidation_0-merror:0.113363\tvalidation_1-merror:0.193687\n",
      "[282]\tvalidation_0-merror:0.113152\tvalidation_1-merror:0.193855\n",
      "[283]\tvalidation_0-merror:0.112837\tvalidation_1-merror:0.194276\n",
      "[284]\tvalidation_0-merror:0.112374\tvalidation_1-merror:0.194276\n",
      "[285]\tvalidation_0-merror:0.112247\tvalidation_1-merror:0.19436\n",
      "[286]\tvalidation_0-merror:0.112079\tvalidation_1-merror:0.194192\n",
      "[287]\tvalidation_0-merror:0.111679\tvalidation_1-merror:0.194024\n",
      "[288]\tvalidation_0-merror:0.111448\tvalidation_1-merror:0.194276\n",
      "[289]\tvalidation_0-merror:0.111364\tvalidation_1-merror:0.193434\n",
      "[290]\tvalidation_0-merror:0.111069\tvalidation_1-merror:0.19335\n",
      "[291]\tvalidation_0-merror:0.111069\tvalidation_1-merror:0.192929\n",
      "[292]\tvalidation_0-merror:0.110817\tvalidation_1-merror:0.193098\n",
      "[293]\tvalidation_0-merror:0.110543\tvalidation_1-merror:0.193013\n",
      "[294]\tvalidation_0-merror:0.11048\tvalidation_1-merror:0.193182\n",
      "[295]\tvalidation_0-merror:0.110438\tvalidation_1-merror:0.193434\n",
      "[296]\tvalidation_0-merror:0.110143\tvalidation_1-merror:0.193182\n",
      "[297]\tvalidation_0-merror:0.109743\tvalidation_1-merror:0.193182\n",
      "[298]\tvalidation_0-merror:0.109449\tvalidation_1-merror:0.193266\n",
      "[299]\tvalidation_0-merror:0.108986\tvalidation_1-merror:0.193013\n",
      "[300]\tvalidation_0-merror:0.108586\tvalidation_1-merror:0.193098\n",
      "[301]\tvalidation_0-merror:0.108333\tvalidation_1-merror:0.193098\n",
      "[302]\tvalidation_0-merror:0.10806\tvalidation_1-merror:0.193098\n",
      "[303]\tvalidation_0-merror:0.107807\tvalidation_1-merror:0.193182\n",
      "[304]\tvalidation_0-merror:0.107723\tvalidation_1-merror:0.193519\n",
      "[305]\tvalidation_0-merror:0.107449\tvalidation_1-merror:0.193434\n",
      "[306]\tvalidation_0-merror:0.107134\tvalidation_1-merror:0.193266\n",
      "[307]\tvalidation_0-merror:0.106923\tvalidation_1-merror:0.193434\n",
      "[308]\tvalidation_0-merror:0.106566\tvalidation_1-merror:0.193266\n",
      "[309]\tvalidation_0-merror:0.106334\tvalidation_1-merror:0.193434\n",
      "[310]\tvalidation_0-merror:0.106166\tvalidation_1-merror:0.193603\n",
      "[311]\tvalidation_0-merror:0.105892\tvalidation_1-merror:0.193434\n",
      "[312]\tvalidation_0-merror:0.105766\tvalidation_1-merror:0.193519\n",
      "[313]\tvalidation_0-merror:0.105682\tvalidation_1-merror:0.193603\n",
      "[314]\tvalidation_0-merror:0.105556\tvalidation_1-merror:0.193434\n",
      "[315]\tvalidation_0-merror:0.105324\tvalidation_1-merror:0.193434\n",
      "[316]\tvalidation_0-merror:0.105198\tvalidation_1-merror:0.193687\n",
      "[317]\tvalidation_0-merror:0.104966\tvalidation_1-merror:0.193939\n",
      "[318]\tvalidation_0-merror:0.104798\tvalidation_1-merror:0.193771\n",
      "[319]\tvalidation_0-merror:0.104419\tvalidation_1-merror:0.193519\n",
      "[320]\tvalidation_0-merror:0.104356\tvalidation_1-merror:0.193687\n",
      "[321]\tvalidation_0-merror:0.104104\tvalidation_1-merror:0.193603\n",
      "[322]\tvalidation_0-merror:0.103535\tvalidation_1-merror:0.193434\n",
      "[323]\tvalidation_0-merror:0.103409\tvalidation_1-merror:0.193434\n",
      "[324]\tvalidation_0-merror:0.10322\tvalidation_1-merror:0.193603\n",
      "[325]\tvalidation_0-merror:0.103136\tvalidation_1-merror:0.193519\n",
      "[326]\tvalidation_0-merror:0.102715\tvalidation_1-merror:0.193519\n",
      "[327]\tvalidation_0-merror:0.102357\tvalidation_1-merror:0.193771\n",
      "[328]\tvalidation_0-merror:0.102125\tvalidation_1-merror:0.193603\n",
      "[329]\tvalidation_0-merror:0.101768\tvalidation_1-merror:0.193855\n",
      "[330]\tvalidation_0-merror:0.101599\tvalidation_1-merror:0.193939\n",
      "[331]\tvalidation_0-merror:0.101368\tvalidation_1-merror:0.193603\n",
      "[332]\tvalidation_0-merror:0.101263\tvalidation_1-merror:0.193855\n",
      "[333]\tvalidation_0-merror:0.10101\tvalidation_1-merror:0.19335\n",
      "[334]\tvalidation_0-merror:0.100715\tvalidation_1-merror:0.19335\n",
      "[335]\tvalidation_0-merror:0.100758\tvalidation_1-merror:0.193519\n",
      "[336]\tvalidation_0-merror:0.100505\tvalidation_1-merror:0.193603\n",
      "[337]\tvalidation_0-merror:0.100295\tvalidation_1-merror:0.19335\n",
      "[338]\tvalidation_0-merror:0.100231\tvalidation_1-merror:0.193434\n",
      "[339]\tvalidation_0-merror:0.099979\tvalidation_1-merror:0.193771\n",
      "[340]\tvalidation_0-merror:0.099705\tvalidation_1-merror:0.193771\n",
      "[341]\tvalidation_0-merror:0.099579\tvalidation_1-merror:0.193855\n",
      "Stopping. Best iteration:\n",
      "[291]\tvalidation_0-merror:0.111069\tvalidation_1-merror:0.192929\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit_transform on train, transform on val\n",
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=1000,  # <= 1000 trees, depends on early stopping\n",
    "    max_depth=7,        # try deeper trees because of high cardinality categoricals\n",
    "    learning_rate=0.1,   # try higher learning rate\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "eval_set = [(X_train_encoded, y_train), \n",
    "            (X_val_encoded, y_val)]\n",
    "\n",
    "model.fit(X_train_encoded, y_train,\n",
    "          eval_set=eval_set,\n",
    "          eval_metric='merror',\n",
    "          early_stopping_rounds=50)  # Stop if the score hasn't improved in 50 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_0': {'merror': [0.250884,\n",
       "   0.252294,\n",
       "   0.251747,\n",
       "   0.249895,\n",
       "   0.248864,\n",
       "   0.24678,\n",
       "   0.243687,\n",
       "   0.240404,\n",
       "   0.2379,\n",
       "   0.235816,\n",
       "   0.234975,\n",
       "   0.23388,\n",
       "   0.233228,\n",
       "   0.231776,\n",
       "   0.232008,\n",
       "   0.230535,\n",
       "   0.229104,\n",
       "   0.228325,\n",
       "   0.227125,\n",
       "   0.226515,\n",
       "   0.225526,\n",
       "   0.224495,\n",
       "   0.22298,\n",
       "   0.221843,\n",
       "   0.221044,\n",
       "   0.220244,\n",
       "   0.218939,\n",
       "   0.217151,\n",
       "   0.215109,\n",
       "   0.213636,\n",
       "   0.212563,\n",
       "   0.211132,\n",
       "   0.209996,\n",
       "   0.209049,\n",
       "   0.207765,\n",
       "   0.206734,\n",
       "   0.205724,\n",
       "   0.204882,\n",
       "   0.203998,\n",
       "   0.20221,\n",
       "   0.200968,\n",
       "   0.199474,\n",
       "   0.198695,\n",
       "   0.197769,\n",
       "   0.196275,\n",
       "   0.195707,\n",
       "   0.194739,\n",
       "   0.194192,\n",
       "   0.193287,\n",
       "   0.192466,\n",
       "   0.19194,\n",
       "   0.191225,\n",
       "   0.190278,\n",
       "   0.18971,\n",
       "   0.189205,\n",
       "   0.188279,\n",
       "   0.187184,\n",
       "   0.186385,\n",
       "   0.185501,\n",
       "   0.18487,\n",
       "   0.184364,\n",
       "   0.183586,\n",
       "   0.183123,\n",
       "   0.182302,\n",
       "   0.182029,\n",
       "   0.181839,\n",
       "   0.181145,\n",
       "   0.180745,\n",
       "   0.180156,\n",
       "   0.179735,\n",
       "   0.179398,\n",
       "   0.178767,\n",
       "   0.17822,\n",
       "   0.177946,\n",
       "   0.176684,\n",
       "   0.176157,\n",
       "   0.175231,\n",
       "   0.174958,\n",
       "   0.174579,\n",
       "   0.17399,\n",
       "   0.173695,\n",
       "   0.17338,\n",
       "   0.173211,\n",
       "   0.172727,\n",
       "   0.172306,\n",
       "   0.171928,\n",
       "   0.171907,\n",
       "   0.17138,\n",
       "   0.170581,\n",
       "   0.17037,\n",
       "   0.169634,\n",
       "   0.169423,\n",
       "   0.169213,\n",
       "   0.168624,\n",
       "   0.168119,\n",
       "   0.167908,\n",
       "   0.167551,\n",
       "   0.167424,\n",
       "   0.167109,\n",
       "   0.166561,\n",
       "   0.166246,\n",
       "   0.166077,\n",
       "   0.16553,\n",
       "   0.165236,\n",
       "   0.164857,\n",
       "   0.164583,\n",
       "   0.164394,\n",
       "   0.164141,\n",
       "   0.163784,\n",
       "   0.163237,\n",
       "   0.163047,\n",
       "   0.162584,\n",
       "   0.162353,\n",
       "   0.162163,\n",
       "   0.161848,\n",
       "   0.161616,\n",
       "   0.161258,\n",
       "   0.161027,\n",
       "   0.160354,\n",
       "   0.159891,\n",
       "   0.159638,\n",
       "   0.159322,\n",
       "   0.159049,\n",
       "   0.158228,\n",
       "   0.158228,\n",
       "   0.157639,\n",
       "   0.157302,\n",
       "   0.156692,\n",
       "   0.156629,\n",
       "   0.156313,\n",
       "   0.156124,\n",
       "   0.155997,\n",
       "   0.155829,\n",
       "   0.155513,\n",
       "   0.154651,\n",
       "   0.154461,\n",
       "   0.154209,\n",
       "   0.153746,\n",
       "   0.153367,\n",
       "   0.152883,\n",
       "   0.152462,\n",
       "   0.152189,\n",
       "   0.151915,\n",
       "   0.15162,\n",
       "   0.151494,\n",
       "   0.151115,\n",
       "   0.150758,\n",
       "   0.15061,\n",
       "   0.149874,\n",
       "   0.149369,\n",
       "   0.149158,\n",
       "   0.148843,\n",
       "   0.148506,\n",
       "   0.14838,\n",
       "   0.148001,\n",
       "   0.14779,\n",
       "   0.147517,\n",
       "   0.147559,\n",
       "   0.147054,\n",
       "   0.146949,\n",
       "   0.146591,\n",
       "   0.146444,\n",
       "   0.146233,\n",
       "   0.146065,\n",
       "   0.145644,\n",
       "   0.145118,\n",
       "   0.144592,\n",
       "   0.144129,\n",
       "   0.143813,\n",
       "   0.14354,\n",
       "   0.143119,\n",
       "   0.142761,\n",
       "   0.142635,\n",
       "   0.142277,\n",
       "   0.142045,\n",
       "   0.141582,\n",
       "   0.141246,\n",
       "   0.140783,\n",
       "   0.14053,\n",
       "   0.140109,\n",
       "   0.139752,\n",
       "   0.139773,\n",
       "   0.139436,\n",
       "   0.139247,\n",
       "   0.138889,\n",
       "   0.138636,\n",
       "   0.138173,\n",
       "   0.137921,\n",
       "   0.137858,\n",
       "   0.137521,\n",
       "   0.137395,\n",
       "   0.137205,\n",
       "   0.136953,\n",
       "   0.136532,\n",
       "   0.136574,\n",
       "   0.136322,\n",
       "   0.136153,\n",
       "   0.135795,\n",
       "   0.135396,\n",
       "   0.13529,\n",
       "   0.13508,\n",
       "   0.13487,\n",
       "   0.134301,\n",
       "   0.134133,\n",
       "   0.133965,\n",
       "   0.133691,\n",
       "   0.133333,\n",
       "   0.132849,\n",
       "   0.132723,\n",
       "   0.132555,\n",
       "   0.132323,\n",
       "   0.132176,\n",
       "   0.13205,\n",
       "   0.131797,\n",
       "   0.131503,\n",
       "   0.131418,\n",
       "   0.131082,\n",
       "   0.130598,\n",
       "   0.130282,\n",
       "   0.130261,\n",
       "   0.129798,\n",
       "   0.129672,\n",
       "   0.129545,\n",
       "   0.129188,\n",
       "   0.128809,\n",
       "   0.128598,\n",
       "   0.128598,\n",
       "   0.128346,\n",
       "   0.12782,\n",
       "   0.12742,\n",
       "   0.127273,\n",
       "   0.127104,\n",
       "   0.126747,\n",
       "   0.126515,\n",
       "   0.125884,\n",
       "   0.125274,\n",
       "   0.125253,\n",
       "   0.124979,\n",
       "   0.1246,\n",
       "   0.124474,\n",
       "   0.124116,\n",
       "   0.123927,\n",
       "   0.123569,\n",
       "   0.123274,\n",
       "   0.123106,\n",
       "   0.122875,\n",
       "   0.122559,\n",
       "   0.122201,\n",
       "   0.121949,\n",
       "   0.121886,\n",
       "   0.121549,\n",
       "   0.121149,\n",
       "   0.121002,\n",
       "   0.120749,\n",
       "   0.120518,\n",
       "   0.120118,\n",
       "   0.119844,\n",
       "   0.119802,\n",
       "   0.119423,\n",
       "   0.119297,\n",
       "   0.119108,\n",
       "   0.118708,\n",
       "   0.118519,\n",
       "   0.118434,\n",
       "   0.117971,\n",
       "   0.117551,\n",
       "   0.117424,\n",
       "   0.117151,\n",
       "   0.116793,\n",
       "   0.116625,\n",
       "   0.116309,\n",
       "   0.11612,\n",
       "   0.115825,\n",
       "   0.115741,\n",
       "   0.115067,\n",
       "   0.114625,\n",
       "   0.114457,\n",
       "   0.114226,\n",
       "   0.113973,\n",
       "   0.113763,\n",
       "   0.11351,\n",
       "   0.113363,\n",
       "   0.113152,\n",
       "   0.112837,\n",
       "   0.112374,\n",
       "   0.112247,\n",
       "   0.112079,\n",
       "   0.111679,\n",
       "   0.111448,\n",
       "   0.111364,\n",
       "   0.111069,\n",
       "   0.111069,\n",
       "   0.110817,\n",
       "   0.110543,\n",
       "   0.11048,\n",
       "   0.110438,\n",
       "   0.110143,\n",
       "   0.109743,\n",
       "   0.109449,\n",
       "   0.108986,\n",
       "   0.108586,\n",
       "   0.108333,\n",
       "   0.10806,\n",
       "   0.107807,\n",
       "   0.107723,\n",
       "   0.107449,\n",
       "   0.107134,\n",
       "   0.106923,\n",
       "   0.106566,\n",
       "   0.106334,\n",
       "   0.106166,\n",
       "   0.105892,\n",
       "   0.105766,\n",
       "   0.105682,\n",
       "   0.105556,\n",
       "   0.105324,\n",
       "   0.105198,\n",
       "   0.104966,\n",
       "   0.104798,\n",
       "   0.104419,\n",
       "   0.104356,\n",
       "   0.104104,\n",
       "   0.103535,\n",
       "   0.103409,\n",
       "   0.10322,\n",
       "   0.103136,\n",
       "   0.102715,\n",
       "   0.102357,\n",
       "   0.102125,\n",
       "   0.101768,\n",
       "   0.101599,\n",
       "   0.101368,\n",
       "   0.101263,\n",
       "   0.10101,\n",
       "   0.100715,\n",
       "   0.100758,\n",
       "   0.100505,\n",
       "   0.100295,\n",
       "   0.100231,\n",
       "   0.099979,\n",
       "   0.099705]},\n",
       " 'validation_1': {'merror': [0.261953,\n",
       "   0.264057,\n",
       "   0.264731,\n",
       "   0.262037,\n",
       "   0.26069,\n",
       "   0.257239,\n",
       "   0.255051,\n",
       "   0.250421,\n",
       "   0.248316,\n",
       "   0.247054,\n",
       "   0.24596,\n",
       "   0.245118,\n",
       "   0.245286,\n",
       "   0.244529,\n",
       "   0.244529,\n",
       "   0.243855,\n",
       "   0.241835,\n",
       "   0.241919,\n",
       "   0.239899,\n",
       "   0.238973,\n",
       "   0.238973,\n",
       "   0.237626,\n",
       "   0.23569,\n",
       "   0.235522,\n",
       "   0.235774,\n",
       "   0.235269,\n",
       "   0.234428,\n",
       "   0.232492,\n",
       "   0.230892,\n",
       "   0.229882,\n",
       "   0.228283,\n",
       "   0.227357,\n",
       "   0.227104,\n",
       "   0.226683,\n",
       "   0.226515,\n",
       "   0.226347,\n",
       "   0.225589,\n",
       "   0.225168,\n",
       "   0.224158,\n",
       "   0.222475,\n",
       "   0.221633,\n",
       "   0.220539,\n",
       "   0.220707,\n",
       "   0.220286,\n",
       "   0.219613,\n",
       "   0.219108,\n",
       "   0.218266,\n",
       "   0.217172,\n",
       "   0.217172,\n",
       "   0.216667,\n",
       "   0.216835,\n",
       "   0.216077,\n",
       "   0.215152,\n",
       "   0.21431,\n",
       "   0.214478,\n",
       "   0.212879,\n",
       "   0.212795,\n",
       "   0.211953,\n",
       "   0.211448,\n",
       "   0.211448,\n",
       "   0.211364,\n",
       "   0.210859,\n",
       "   0.21069,\n",
       "   0.210354,\n",
       "   0.210522,\n",
       "   0.209512,\n",
       "   0.209259,\n",
       "   0.209259,\n",
       "   0.208923,\n",
       "   0.208923,\n",
       "   0.208754,\n",
       "   0.208923,\n",
       "   0.208923,\n",
       "   0.209091,\n",
       "   0.208502,\n",
       "   0.207997,\n",
       "   0.207576,\n",
       "   0.208165,\n",
       "   0.206313,\n",
       "   0.206145,\n",
       "   0.205556,\n",
       "   0.205135,\n",
       "   0.205219,\n",
       "   0.204798,\n",
       "   0.204798,\n",
       "   0.204714,\n",
       "   0.204545,\n",
       "   0.204209,\n",
       "   0.204545,\n",
       "   0.204293,\n",
       "   0.204461,\n",
       "   0.204545,\n",
       "   0.204377,\n",
       "   0.204545,\n",
       "   0.204377,\n",
       "   0.204377,\n",
       "   0.204545,\n",
       "   0.204461,\n",
       "   0.204377,\n",
       "   0.204293,\n",
       "   0.203788,\n",
       "   0.203367,\n",
       "   0.203704,\n",
       "   0.20362,\n",
       "   0.20362,\n",
       "   0.203704,\n",
       "   0.203114,\n",
       "   0.203199,\n",
       "   0.203451,\n",
       "   0.203367,\n",
       "   0.203283,\n",
       "   0.202778,\n",
       "   0.202694,\n",
       "   0.203114,\n",
       "   0.202778,\n",
       "   0.202609,\n",
       "   0.202525,\n",
       "   0.20303,\n",
       "   0.203283,\n",
       "   0.202946,\n",
       "   0.202946,\n",
       "   0.202778,\n",
       "   0.202946,\n",
       "   0.20202,\n",
       "   0.201852,\n",
       "   0.20202,\n",
       "   0.20202,\n",
       "   0.201431,\n",
       "   0.201178,\n",
       "   0.201347,\n",
       "   0.200926,\n",
       "   0.201263,\n",
       "   0.201094,\n",
       "   0.200589,\n",
       "   0.200673,\n",
       "   0.200673,\n",
       "   0.200589,\n",
       "   0.200337,\n",
       "   0.2,\n",
       "   0.199832,\n",
       "   0.2,\n",
       "   0.200168,\n",
       "   0.200337,\n",
       "   0.200168,\n",
       "   0.199916,\n",
       "   0.2,\n",
       "   0.199663,\n",
       "   0.199411,\n",
       "   0.199579,\n",
       "   0.199327,\n",
       "   0.199158,\n",
       "   0.199663,\n",
       "   0.199832,\n",
       "   0.2,\n",
       "   0.199242,\n",
       "   0.199327,\n",
       "   0.199579,\n",
       "   0.199747,\n",
       "   0.199663,\n",
       "   0.199832,\n",
       "   0.199411,\n",
       "   0.199579,\n",
       "   0.199411,\n",
       "   0.198906,\n",
       "   0.198569,\n",
       "   0.198148,\n",
       "   0.198401,\n",
       "   0.198316,\n",
       "   0.198232,\n",
       "   0.197896,\n",
       "   0.197727,\n",
       "   0.19798,\n",
       "   0.198232,\n",
       "   0.198401,\n",
       "   0.198148,\n",
       "   0.198148,\n",
       "   0.198064,\n",
       "   0.198401,\n",
       "   0.198148,\n",
       "   0.198064,\n",
       "   0.198064,\n",
       "   0.197811,\n",
       "   0.197559,\n",
       "   0.197475,\n",
       "   0.197306,\n",
       "   0.197222,\n",
       "   0.196886,\n",
       "   0.196886,\n",
       "   0.19697,\n",
       "   0.197054,\n",
       "   0.19697,\n",
       "   0.197138,\n",
       "   0.197054,\n",
       "   0.19697,\n",
       "   0.197138,\n",
       "   0.197138,\n",
       "   0.19697,\n",
       "   0.196717,\n",
       "   0.196465,\n",
       "   0.196801,\n",
       "   0.196801,\n",
       "   0.195875,\n",
       "   0.195623,\n",
       "   0.195791,\n",
       "   0.195875,\n",
       "   0.19596,\n",
       "   0.195875,\n",
       "   0.196296,\n",
       "   0.196128,\n",
       "   0.195875,\n",
       "   0.195875,\n",
       "   0.195875,\n",
       "   0.195791,\n",
       "   0.19596,\n",
       "   0.196212,\n",
       "   0.19596,\n",
       "   0.195707,\n",
       "   0.195455,\n",
       "   0.19537,\n",
       "   0.195455,\n",
       "   0.196128,\n",
       "   0.196296,\n",
       "   0.196128,\n",
       "   0.196212,\n",
       "   0.19596,\n",
       "   0.195623,\n",
       "   0.19596,\n",
       "   0.195539,\n",
       "   0.195539,\n",
       "   0.195286,\n",
       "   0.195286,\n",
       "   0.194865,\n",
       "   0.195118,\n",
       "   0.194949,\n",
       "   0.195202,\n",
       "   0.195455,\n",
       "   0.195539,\n",
       "   0.195118,\n",
       "   0.195202,\n",
       "   0.19537,\n",
       "   0.195118,\n",
       "   0.195202,\n",
       "   0.195455,\n",
       "   0.195286,\n",
       "   0.195118,\n",
       "   0.195286,\n",
       "   0.195202,\n",
       "   0.195455,\n",
       "   0.195539,\n",
       "   0.195455,\n",
       "   0.195539,\n",
       "   0.194865,\n",
       "   0.194697,\n",
       "   0.194781,\n",
       "   0.194697,\n",
       "   0.194865,\n",
       "   0.194781,\n",
       "   0.194865,\n",
       "   0.194781,\n",
       "   0.194865,\n",
       "   0.195202,\n",
       "   0.194949,\n",
       "   0.194276,\n",
       "   0.194529,\n",
       "   0.194192,\n",
       "   0.194529,\n",
       "   0.194697,\n",
       "   0.194865,\n",
       "   0.194529,\n",
       "   0.194276,\n",
       "   0.194276,\n",
       "   0.19436,\n",
       "   0.193855,\n",
       "   0.193855,\n",
       "   0.193939,\n",
       "   0.193771,\n",
       "   0.194108,\n",
       "   0.194276,\n",
       "   0.194024,\n",
       "   0.193434,\n",
       "   0.193687,\n",
       "   0.193687,\n",
       "   0.193855,\n",
       "   0.194276,\n",
       "   0.194276,\n",
       "   0.19436,\n",
       "   0.194192,\n",
       "   0.194024,\n",
       "   0.194276,\n",
       "   0.193434,\n",
       "   0.19335,\n",
       "   0.192929,\n",
       "   0.193098,\n",
       "   0.193013,\n",
       "   0.193182,\n",
       "   0.193434,\n",
       "   0.193182,\n",
       "   0.193182,\n",
       "   0.193266,\n",
       "   0.193013,\n",
       "   0.193098,\n",
       "   0.193098,\n",
       "   0.193098,\n",
       "   0.193182,\n",
       "   0.193519,\n",
       "   0.193434,\n",
       "   0.193266,\n",
       "   0.193434,\n",
       "   0.193266,\n",
       "   0.193434,\n",
       "   0.193603,\n",
       "   0.193434,\n",
       "   0.193519,\n",
       "   0.193603,\n",
       "   0.193434,\n",
       "   0.193434,\n",
       "   0.193687,\n",
       "   0.193939,\n",
       "   0.193771,\n",
       "   0.193519,\n",
       "   0.193687,\n",
       "   0.193603,\n",
       "   0.193434,\n",
       "   0.193434,\n",
       "   0.193603,\n",
       "   0.193519,\n",
       "   0.193519,\n",
       "   0.193771,\n",
       "   0.193603,\n",
       "   0.193855,\n",
       "   0.193939,\n",
       "   0.193603,\n",
       "   0.193855,\n",
       "   0.19335,\n",
       "   0.19335,\n",
       "   0.193519,\n",
       "   0.193603,\n",
       "   0.19335,\n",
       "   0.193434,\n",
       "   0.193771,\n",
       "   0.193771]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.evals_result()\n",
    "train_error = results['validation_0']['merror']\n",
    "val_error = results['validation_1']['merror']\n",
    "epoch = range(1, len(train_error)+1)\n",
    "plt.plot(epoch, train_error, label='Train Error')\n",
    "plt.plot(epoch, val_error, label='Validation Error')\n",
    "plt.ylabel('Classification Error')\n",
    "plt.xlabel('Model Complexity (n_estimators)')\n",
    "plt.ylim((0.18, 0.22))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZF7-ml6BhRRf"
   },
   "source": [
    "## Try adjusting these hyperparameters\n",
    "\n",
    "#### Random Forest\n",
    "- class_weight (for imbalanced classes)\n",
    "- max_depth (usually high, can try decreasing)\n",
    "- n_estimators (too low underfits, too high wastes time)\n",
    "- min_samples_leaf (increase if overfitting)\n",
    "- max_features (decrease for more diverse trees)\n",
    "\n",
    "#### Xgboost\n",
    "- scale_pos_weight (for imbalanced classes)\n",
    "- max_depth (usually low, can try increasing)\n",
    "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
    "- learning_rate (too low underfits, too high overfits)\n",
    "\n",
    "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
