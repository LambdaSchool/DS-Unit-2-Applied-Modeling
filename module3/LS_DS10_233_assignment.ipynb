{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS10_233_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Okocha76/DS-Unit-2-Applied-Modeling/blob/master/module3/LS_DS10_233_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 3*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Permutation & Boosting\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your work.\n",
        "\n",
        "- [ ] If you haven't completed assignment #1, please do so first.\n",
        "- [ ] Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- [ ] Fit a model. Does it beat your baseline? \n",
        "- [ ] Try xgboost.\n",
        "- [ ] Get your model's permutation importances.\n",
        "\n",
        "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "But, if you aren't ready to try xgboost and permutation importances with your dataset today, that's okay. You can practice with another dataset instead. You may choose any dataset you've worked with previously.\n",
        "\n",
        "The data subdirectory includes the Titanic dataset for classification and the NYC apartments dataset for regression. You may want to choose one of these datasets, because example solutions will be available for each.\n",
        "\n",
        "\n",
        "## Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Permutation Importances\n",
        "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
        "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "\n",
        "#### (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "#### Gradient Boosting\n",
        "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
        "  - _**[A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)**_\n",
        "  - [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8\n",
        "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)\n",
        "  - _**[Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw) (2.5 minute video)**_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txS3vQkTRsjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "!pip install category_encoders==2.*\n",
        "!pip install pandas-profiling==2.*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qPIdscE1w3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Okocha76/Okocha76.github.io/master/euro_data.csv', sep=';', engine='python', encoding = \"ISO-8859-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vV6W2Y-umB",
        "colab_type": "code",
        "outputId": "801c40d6-a018-4231-e485-8883a349764f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8010, 41)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIME</th>\n",
              "      <th>GEO</th>\n",
              "      <th>GEO_LABEL</th>\n",
              "      <th>AGEMOTH</th>\n",
              "      <th>MEDAGEMOTH</th>\n",
              "      <th>TOTFERRT</th>\n",
              "      <th>JAN</th>\n",
              "      <th>CNMIGRAT</th>\n",
              "      <th>CNMIGRATRT</th>\n",
              "      <th>DEATH</th>\n",
              "      <th>GBIRTHRT</th>\n",
              "      <th>GDEATHRT</th>\n",
              "      <th>GROW</th>\n",
              "      <th>GROWRT</th>\n",
              "      <th>LBIRTH</th>\n",
              "      <th>NATGROW</th>\n",
              "      <th>NATGROWRT</th>\n",
              "      <th>RT</th>\n",
              "      <th>PER_KM2</th>\n",
              "      <th>EUR_HAB_2GDP</th>\n",
              "      <th>EUR_HAB_EU</th>\n",
              "      <th>EUR_HAB_EU27_2019</th>\n",
              "      <th>MIO_EUR</th>\n",
              "      <th>MIO_NAC</th>\n",
              "      <th>MIO_PPS</th>\n",
              "      <th>MIO_PPS_EU27_2019</th>\n",
              "      <th>PPS_EU27_2019_HAB</th>\n",
              "      <th>PPS_HAB</th>\n",
              "      <th>PPS_HAB_EU</th>\n",
              "      <th>PPS_HAB_EU27_2019</th>\n",
              "      <th>EMP</th>\n",
              "      <th>SAL</th>\n",
              "      <th>EUR_HAB_2HHINC</th>\n",
              "      <th>ED0-2_25_64</th>\n",
              "      <th>ED3_4_25_64</th>\n",
              "      <th>ED3-8_25_64</th>\n",
              "      <th>ED5-8_25_64</th>\n",
              "      <th>ED0-2_30_34</th>\n",
              "      <th>ED3_4_30_34</th>\n",
              "      <th>ED3-8_30_34</th>\n",
              "      <th>ED5-8_30_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.7</td>\n",
              "      <td>29.4</td>\n",
              "      <td>1.35</td>\n",
              "      <td>8002186</td>\n",
              "      <td>17272</td>\n",
              "      <td>2.2</td>\n",
              "      <td>76780</td>\n",
              "      <td>9.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>18760</td>\n",
              "      <td>2.3</td>\n",
              "      <td>78268</td>\n",
              "      <td>1488</td>\n",
              "      <td>0.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>97.2</td>\n",
              "      <td>26700</td>\n",
              "      <td>134</td>\n",
              "      <td>145</td>\n",
              "      <td>213606.48</td>\n",
              "      <td>213606.48</td>\n",
              "      <td>206251.54</td>\n",
              "      <td>195513.50</td>\n",
              "      <td>24400</td>\n",
              "      <td>25700</td>\n",
              "      <td>130</td>\n",
              "      <td>133</td>\n",
              "      <td>3755.0</td>\n",
              "      <td>3243.7</td>\n",
              "      <td>18000</td>\n",
              "      <td>23.8</td>\n",
              "      <td>62.1</td>\n",
              "      <td>76.2</td>\n",
              "      <td>14.1</td>\n",
              "      <td>16.7</td>\n",
              "      <td>67.4</td>\n",
              "      <td>83.3</td>\n",
              "      <td>15.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.9</td>\n",
              "      <td>29.6</td>\n",
              "      <td>1.31</td>\n",
              "      <td>8020946</td>\n",
              "      <td>42003</td>\n",
              "      <td>5.2</td>\n",
              "      <td>74767</td>\n",
              "      <td>9.4</td>\n",
              "      <td>9.3</td>\n",
              "      <td>42694</td>\n",
              "      <td>5.3</td>\n",
              "      <td>75458</td>\n",
              "      <td>691</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.8</td>\n",
              "      <td>97.5</td>\n",
              "      <td>27400</td>\n",
              "      <td>133</td>\n",
              "      <td>143</td>\n",
              "      <td>220525.08</td>\n",
              "      <td>220525.08</td>\n",
              "      <td>207461.48</td>\n",
              "      <td>197764.57</td>\n",
              "      <td>24600</td>\n",
              "      <td>25800</td>\n",
              "      <td>125</td>\n",
              "      <td>128</td>\n",
              "      <td>3782.0</td>\n",
              "      <td>3265.1</td>\n",
              "      <td>18300</td>\n",
              "      <td>22.5</td>\n",
              "      <td>62.6</td>\n",
              "      <td>77.5</td>\n",
              "      <td>14.8</td>\n",
              "      <td>16.0</td>\n",
              "      <td>67.9</td>\n",
              "      <td>84.0</td>\n",
              "      <td>16.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.1</td>\n",
              "      <td>29.8</td>\n",
              "      <td>1.38</td>\n",
              "      <td>8063640</td>\n",
              "      <td>34365</td>\n",
              "      <td>4.3</td>\n",
              "      <td>76131</td>\n",
              "      <td>9.7</td>\n",
              "      <td>9.4</td>\n",
              "      <td>36633</td>\n",
              "      <td>4.5</td>\n",
              "      <td>78399</td>\n",
              "      <td>2268</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>28100</td>\n",
              "      <td>132</td>\n",
              "      <td>141</td>\n",
              "      <td>226735.22</td>\n",
              "      <td>226735.22</td>\n",
              "      <td>216432.92</td>\n",
              "      <td>206562.16</td>\n",
              "      <td>25600</td>\n",
              "      <td>26800</td>\n",
              "      <td>126</td>\n",
              "      <td>129</td>\n",
              "      <td>3778.4</td>\n",
              "      <td>3258.1</td>\n",
              "      <td>18500</td>\n",
              "      <td>21.7</td>\n",
              "      <td>62.7</td>\n",
              "      <td>78.3</td>\n",
              "      <td>15.7</td>\n",
              "      <td>15.9</td>\n",
              "      <td>66.9</td>\n",
              "      <td>84.1</td>\n",
              "      <td>17.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.2</td>\n",
              "      <td>29.9</td>\n",
              "      <td>1.36</td>\n",
              "      <td>8100273</td>\n",
              "      <td>42565</td>\n",
              "      <td>5.2</td>\n",
              "      <td>77209</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>42300</td>\n",
              "      <td>5.2</td>\n",
              "      <td>76944</td>\n",
              "      <td>-265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>98.5</td>\n",
              "      <td>28600</td>\n",
              "      <td>132</td>\n",
              "      <td>140</td>\n",
              "      <td>231862.46</td>\n",
              "      <td>231862.46</td>\n",
              "      <td>221219.87</td>\n",
              "      <td>214271.17</td>\n",
              "      <td>26400</td>\n",
              "      <td>27200</td>\n",
              "      <td>126</td>\n",
              "      <td>130</td>\n",
              "      <td>3803.0</td>\n",
              "      <td>3275.3</td>\n",
              "      <td>18900</td>\n",
              "      <td>21.0</td>\n",
              "      <td>63.3</td>\n",
              "      <td>79.0</td>\n",
              "      <td>15.7</td>\n",
              "      <td>14.3</td>\n",
              "      <td>68.1</td>\n",
              "      <td>85.7</td>\n",
              "      <td>17.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.8</td>\n",
              "      <td>29.5</td>\n",
              "      <td>1.42</td>\n",
              "      <td>8142573</td>\n",
              "      <td>54110</td>\n",
              "      <td>6.6</td>\n",
              "      <td>74292</td>\n",
              "      <td>9.7</td>\n",
              "      <td>9.1</td>\n",
              "      <td>58786</td>\n",
              "      <td>7.2</td>\n",
              "      <td>78968</td>\n",
              "      <td>4676</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.5</td>\n",
              "      <td>99.1</td>\n",
              "      <td>29700</td>\n",
              "      <td>132</td>\n",
              "      <td>140</td>\n",
              "      <td>242348.26</td>\n",
              "      <td>242348.26</td>\n",
              "      <td>233343.6</td>\n",
              "      <td>225461.43</td>\n",
              "      <td>27600</td>\n",
              "      <td>28600</td>\n",
              "      <td>127</td>\n",
              "      <td>130</td>\n",
              "      <td>3826.8</td>\n",
              "      <td>3290.1</td>\n",
              "      <td>19700</td>\n",
              "      <td>20.2</td>\n",
              "      <td>61.8</td>\n",
              "      <td>79.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>65.6</td>\n",
              "      <td>86.5</td>\n",
              "      <td>20.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TIME GEO GEO_LABEL  ...  ED3_4_30_34  ED3-8_30_34  ED5-8_30_34\n",
              "0  2000  AT   Austria  ...         67.4         83.3         15.9\n",
              "1  2001  AT   Austria  ...         67.9         84.0         16.1\n",
              "2  2002  AT   Austria  ...         66.9         84.1         17.2\n",
              "3  2003  AT   Austria  ...         68.1         85.7         17.6\n",
              "4  2004  AT   Austria  ...         65.6         86.5         20.9\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uaxerNAlcVP",
        "colab_type": "code",
        "outputId": "d76ce62f-bca9-4abc-ecf0-6949306c6f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = df[df['TIME'] <= 2011]\n",
        "val = df[(df['TIME'] > 2011) & (df['TIME'] < 2015)]\n",
        "test = df[df['TIME'] >= 2015]\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5340, 41), (1335, 41), (1335, 41))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYtAKbLUCap0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "\n",
        "    # Feature selection is not final. Just a quick & dirty approach for now.\n",
        "\n",
        "    X = X.drop(\n",
        "        ['CNMIGRAT','DEATH','GROW','GROWRT','LBIRTH','NATGROW','NATGROWRT',\n",
        "        'EUR_HAB_2GDP','EUR_HAB_EU27_2019','MIO_EUR','MIO_NAC','MIO_PPS',\n",
        "        'MIO_PPS_EU27_2019','PPS_EU27_2019_HAB','PPS_HAB','PPS_HAB_EU27_2019',\n",
        "        'SAL','EUR_HAB_2HHINC','ED0-2_25_64','ED3_4_25_64','ED3-8_25_64',\n",
        "        'ED5-8_25_64','ED3-8_30_34','MEDAGEMOTH','PPS_HAB_EU','ED3_4_30_34']\n",
        "        ,axis=1)\n",
        "    \n",
        "    X['JAN'] = pd.to_numeric(X['JAN'],errors='coerce')\n",
        "    # X['JAN'] = X['JAN'].astype(int)\n",
        "    X['TIME'] = X['TIME'].astype('category')\n",
        "\n",
        "    # A bit of feature engineering. EMP_PC is percentage employed.\n",
        "    X['EMP_PC'] = round((X['EMP'] * 100000)/X['JAN'],1)\n",
        "    X['EMP_PC'] = X['EMP_PC'].replace(np.inf, np.nan)\n",
        "    X = X.drop(['JAN','EMP'], axis=1)\n",
        "\n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    cols_with_zeros = ['AGEMOTH', 'ED0-2_30_34', 'ED5-8_30_34','EMP_PC',\n",
        "                       'EUR_HAB_EU','GBIRTHRT','GDEATHRT','PER_KM2','RT',\n",
        "                       'TOTFERRT']\n",
        "\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "\n",
        "    X = X.rename(columns={\"ED0-2_30_34\": \"ED_LOW\", \"ED5-8_30_34\": \"ED_HIGH\"})\n",
        "    \n",
        "    # Not sure yet, whether to drop or impute NaNs\n",
        "    # X.dropna(inplace=True)\n",
        "\n",
        "    # Make target feature categorical\n",
        "    X['MIG_CAT'] = pd.qcut(X['CNMIGRATRT'], 3, labels=[\"low\", \"avg\", \"high\"])\n",
        "    X = X.drop(['CNMIGRATRT'], axis=1)   \n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPo0zB1YEG4M",
        "colab_type": "code",
        "outputId": "970b30b8-ab42-4b71-b4cd-dbc0507088c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "print(train.shape)\n",
        "df.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5340, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIME</th>\n",
              "      <th>GEO</th>\n",
              "      <th>GEO_LABEL</th>\n",
              "      <th>AGEMOTH</th>\n",
              "      <th>MEDAGEMOTH</th>\n",
              "      <th>TOTFERRT</th>\n",
              "      <th>JAN</th>\n",
              "      <th>CNMIGRAT</th>\n",
              "      <th>CNMIGRATRT</th>\n",
              "      <th>DEATH</th>\n",
              "      <th>GBIRTHRT</th>\n",
              "      <th>GDEATHRT</th>\n",
              "      <th>GROW</th>\n",
              "      <th>GROWRT</th>\n",
              "      <th>LBIRTH</th>\n",
              "      <th>NATGROW</th>\n",
              "      <th>NATGROWRT</th>\n",
              "      <th>RT</th>\n",
              "      <th>PER_KM2</th>\n",
              "      <th>EUR_HAB_2GDP</th>\n",
              "      <th>EUR_HAB_EU</th>\n",
              "      <th>EUR_HAB_EU27_2019</th>\n",
              "      <th>MIO_EUR</th>\n",
              "      <th>MIO_NAC</th>\n",
              "      <th>MIO_PPS</th>\n",
              "      <th>MIO_PPS_EU27_2019</th>\n",
              "      <th>PPS_EU27_2019_HAB</th>\n",
              "      <th>PPS_HAB</th>\n",
              "      <th>PPS_HAB_EU</th>\n",
              "      <th>PPS_HAB_EU27_2019</th>\n",
              "      <th>EMP</th>\n",
              "      <th>SAL</th>\n",
              "      <th>EUR_HAB_2HHINC</th>\n",
              "      <th>ED0-2_25_64</th>\n",
              "      <th>ED3_4_25_64</th>\n",
              "      <th>ED3-8_25_64</th>\n",
              "      <th>ED5-8_25_64</th>\n",
              "      <th>ED0-2_30_34</th>\n",
              "      <th>ED3_4_30_34</th>\n",
              "      <th>ED3-8_30_34</th>\n",
              "      <th>ED5-8_30_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1638</th>\n",
              "      <td>2000</td>\n",
              "      <td>DEB2</td>\n",
              "      <td>Trier</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>511548</td>\n",
              "      <td>634</td>\n",
              "      <td>1.2</td>\n",
              "      <td>5294</td>\n",
              "      <td>9.5</td>\n",
              "      <td>10.3</td>\n",
              "      <td>206</td>\n",
              "      <td>0.4</td>\n",
              "      <td>4866</td>\n",
              "      <td>-428</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.9</td>\n",
              "      <td>20100</td>\n",
              "      <td>101</td>\n",
              "      <td>109</td>\n",
              "      <td>10313.41</td>\n",
              "      <td>10313.41</td>\n",
              "      <td>9582.55</td>\n",
              "      <td>9083.66</td>\n",
              "      <td>17700</td>\n",
              "      <td>18600</td>\n",
              "      <td>94</td>\n",
              "      <td>96</td>\n",
              "      <td>233.24</td>\n",
              "      <td>204.47</td>\n",
              "      <td>17200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2440</th>\n",
              "      <td>2010</td>\n",
              "      <td>ES11</td>\n",
              "      <td>Galicia</td>\n",
              "      <td>31.8</td>\n",
              "      <td>32.9</td>\n",
              "      <td>1.09</td>\n",
              "      <td>2772466</td>\n",
              "      <td>8647</td>\n",
              "      <td>3.1</td>\n",
              "      <td>29749</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.7</td>\n",
              "      <td>945</td>\n",
              "      <td>0.3</td>\n",
              "      <td>22047</td>\n",
              "      <td>-7702</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>2.2</td>\n",
              "      <td>94.5</td>\n",
              "      <td>20600</td>\n",
              "      <td>81</td>\n",
              "      <td>83</td>\n",
              "      <td>57028.03</td>\n",
              "      <td>57028.03</td>\n",
              "      <td>60032.55</td>\n",
              "      <td>59380.54</td>\n",
              "      <td>21400</td>\n",
              "      <td>21700</td>\n",
              "      <td>85</td>\n",
              "      <td>86</td>\n",
              "      <td>1126.80</td>\n",
              "      <td>937.40</td>\n",
              "      <td>12900</td>\n",
              "      <td>51.2</td>\n",
              "      <td>18.7</td>\n",
              "      <td>48.8</td>\n",
              "      <td>30.1</td>\n",
              "      <td>33.7</td>\n",
              "      <td>21.8</td>\n",
              "      <td>66.3</td>\n",
              "      <td>44.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>2017</td>\n",
              "      <td>CZ07</td>\n",
              "      <td>Strední Morava</td>\n",
              "      <td>30.2</td>\n",
              "      <td>30.6</td>\n",
              "      <td>1.67</td>\n",
              "      <td>1217623</td>\n",
              "      <td>-730</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>13422</td>\n",
              "      <td>10.5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>-1389</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>12763</td>\n",
              "      <td>-659</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>3.1</td>\n",
              "      <td>133.4</td>\n",
              "      <td>14800</td>\n",
              "      <td>49</td>\n",
              "      <td>51</td>\n",
              "      <td>18024.15</td>\n",
              "      <td>474503.79</td>\n",
              "      <td>26739.09</td>\n",
              "      <td>26248.56</td>\n",
              "      <td>21600</td>\n",
              "      <td>22000</td>\n",
              "      <td>73</td>\n",
              "      <td>74</td>\n",
              "      <td>582.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>73.9</td>\n",
              "      <td>93.6</td>\n",
              "      <td>19.7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>65.7</td>\n",
              "      <td>95.0</td>\n",
              "      <td>29.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3720</th>\n",
              "      <td>2012</td>\n",
              "      <td>FRY2</td>\n",
              "      <td>Martinique</td>\n",
              "      <td>29.2</td>\n",
              "      <td>29.8</td>\n",
              "      <td>1.98</td>\n",
              "      <td>388364</td>\n",
              "      <td>-4453</td>\n",
              "      <td>-11.5</td>\n",
              "      <td>2818</td>\n",
              "      <td>11.5</td>\n",
              "      <td>7.3</td>\n",
              "      <td>-2813</td>\n",
              "      <td>-7.3</td>\n",
              "      <td>4458</td>\n",
              "      <td>1640</td>\n",
              "      <td>4.2</td>\n",
              "      <td>7.4</td>\n",
              "      <td>343.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1293</th>\n",
              "      <td>2015</td>\n",
              "      <td>DE60</td>\n",
              "      <td>Hamburg</td>\n",
              "      <td>31.8</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.45</td>\n",
              "      <td>1762791</td>\n",
              "      <td>22414</td>\n",
              "      <td>12.6</td>\n",
              "      <td>17565</td>\n",
              "      <td>11.1</td>\n",
              "      <td>9.9</td>\n",
              "      <td>24617</td>\n",
              "      <td>13.9</td>\n",
              "      <td>19768</td>\n",
              "      <td>2203</td>\n",
              "      <td>1.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>2351.1</td>\n",
              "      <td>62200</td>\n",
              "      <td>214</td>\n",
              "      <td>226</td>\n",
              "      <td>110434.62</td>\n",
              "      <td>110434.62</td>\n",
              "      <td>106667</td>\n",
              "      <td>102035.80</td>\n",
              "      <td>57500</td>\n",
              "      <td>60100</td>\n",
              "      <td>207</td>\n",
              "      <td>209</td>\n",
              "      <td>1204.02</td>\n",
              "      <td>1086.08</td>\n",
              "      <td>30800</td>\n",
              "      <td>14.7</td>\n",
              "      <td>50.4</td>\n",
              "      <td>85.3</td>\n",
              "      <td>34.9</td>\n",
              "      <td>11.8</td>\n",
              "      <td>43.8</td>\n",
              "      <td>88.2</td>\n",
              "      <td>44.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4856</th>\n",
              "      <td>2014</td>\n",
              "      <td>MK00</td>\n",
              "      <td>Severna Makedonija</td>\n",
              "      <td>28.4</td>\n",
              "      <td>28.4</td>\n",
              "      <td>1.52</td>\n",
              "      <td>2065410</td>\n",
              "      <td>-408</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>19718</td>\n",
              "      <td>11.4</td>\n",
              "      <td>9.5</td>\n",
              "      <td>3454</td>\n",
              "      <td>1.7</td>\n",
              "      <td>23580</td>\n",
              "      <td>3862</td>\n",
              "      <td>1.9</td>\n",
              "      <td>9.9</td>\n",
              "      <td>83.0</td>\n",
              "      <td>4100</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>8562.00</td>\n",
              "      <td>527631.00</td>\n",
              "      <td>20474.5</td>\n",
              "      <td>19898.00</td>\n",
              "      <td>9600</td>\n",
              "      <td>9900</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>763.00</td>\n",
              "      <td>529.50</td>\n",
              "      <td>0</td>\n",
              "      <td>34.3</td>\n",
              "      <td>48.1</td>\n",
              "      <td>65.7</td>\n",
              "      <td>17.6</td>\n",
              "      <td>26.5</td>\n",
              "      <td>48.5</td>\n",
              "      <td>73.5</td>\n",
              "      <td>24.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3677</th>\n",
              "      <td>2005</td>\n",
              "      <td>FRY</td>\n",
              "      <td>RUP FR - Régions ultrapériphériques françaises</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1833</th>\n",
              "      <td>2015</td>\n",
              "      <td>DEF</td>\n",
              "      <td>Schleswig-Holstein</td>\n",
              "      <td>30.8</td>\n",
              "      <td>31.1</td>\n",
              "      <td>1.52</td>\n",
              "      <td>2830864</td>\n",
              "      <td>37964</td>\n",
              "      <td>13.3</td>\n",
              "      <td>33663</td>\n",
              "      <td>8.3</td>\n",
              "      <td>11.8</td>\n",
              "      <td>27850</td>\n",
              "      <td>9.8</td>\n",
              "      <td>23549</td>\n",
              "      <td>-10114</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>30500</td>\n",
              "      <td>105</td>\n",
              "      <td>111</td>\n",
              "      <td>86885.50</td>\n",
              "      <td>86885.50</td>\n",
              "      <td>83921.29</td>\n",
              "      <td>80277.65</td>\n",
              "      <td>28200</td>\n",
              "      <td>29500</td>\n",
              "      <td>101</td>\n",
              "      <td>103</td>\n",
              "      <td>1354.71</td>\n",
              "      <td>1197.45</td>\n",
              "      <td>25400</td>\n",
              "      <td>11.7</td>\n",
              "      <td>64.5</td>\n",
              "      <td>88.3</td>\n",
              "      <td>23.8</td>\n",
              "      <td>11.9</td>\n",
              "      <td>64.5</td>\n",
              "      <td>88.1</td>\n",
              "      <td>23.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7717</th>\n",
              "      <td>2013</td>\n",
              "      <td>UKJ4</td>\n",
              "      <td>Kent</td>\n",
              "      <td>29.6</td>\n",
              "      <td>29.6</td>\n",
              "      <td>1.91</td>\n",
              "      <td>1756070</td>\n",
              "      <td>12672</td>\n",
              "      <td>7.2</td>\n",
              "      <td>16060</td>\n",
              "      <td>11.6</td>\n",
              "      <td>9.1</td>\n",
              "      <td>17070</td>\n",
              "      <td>9.7</td>\n",
              "      <td>20458</td>\n",
              "      <td>4398</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.9</td>\n",
              "      <td>472.4</td>\n",
              "      <td>26200</td>\n",
              "      <td>98</td>\n",
              "      <td>101</td>\n",
              "      <td>46261.75</td>\n",
              "      <td>39288.26</td>\n",
              "      <td>41513.21</td>\n",
              "      <td>40760.16</td>\n",
              "      <td>23100</td>\n",
              "      <td>23500</td>\n",
              "      <td>88</td>\n",
              "      <td>89</td>\n",
              "      <td>690.00</td>\n",
              "      <td>582.00</td>\n",
              "      <td>23600</td>\n",
              "      <td>22.4</td>\n",
              "      <td>42.3</td>\n",
              "      <td>77.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>14.9</td>\n",
              "      <td>45.9</td>\n",
              "      <td>85.1</td>\n",
              "      <td>39.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7667</th>\n",
              "      <td>2017</td>\n",
              "      <td>UKJ1</td>\n",
              "      <td>Berkshire, Buckinghamshire and Oxfordshire</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2385514</td>\n",
              "      <td>6673</td>\n",
              "      <td>2.8</td>\n",
              "      <td>17954</td>\n",
              "      <td>11.8</td>\n",
              "      <td>7.5</td>\n",
              "      <td>16993</td>\n",
              "      <td>7.1</td>\n",
              "      <td>28274</td>\n",
              "      <td>10320</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.3</td>\n",
              "      <td>417.0</td>\n",
              "      <td>48600</td>\n",
              "      <td>162</td>\n",
              "      <td>166</td>\n",
              "      <td>116149.91</td>\n",
              "      <td>101825.14</td>\n",
              "      <td>104039.38</td>\n",
              "      <td>102131.05</td>\n",
              "      <td>42700</td>\n",
              "      <td>43500</td>\n",
              "      <td>145</td>\n",
              "      <td>146</td>\n",
              "      <td>1429.00</td>\n",
              "      <td>1206.00</td>\n",
              "      <td>0</td>\n",
              "      <td>13.2</td>\n",
              "      <td>33.0</td>\n",
              "      <td>86.8</td>\n",
              "      <td>53.9</td>\n",
              "      <td>11.2</td>\n",
              "      <td>33.3</td>\n",
              "      <td>88.8</td>\n",
              "      <td>55.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      TIME   GEO  ... ED3-8_30_34  ED5-8_30_34\n",
              "1638  2000  DEB2  ...         0.0          0.0\n",
              "2440  2010  ES11  ...        66.3         44.4\n",
              "881   2017  CZ07  ...        95.0         29.3\n",
              "3720  2012  FRY2  ...         0.0          0.0\n",
              "1293  2015  DE60  ...        88.2         44.5\n",
              "4856  2014  MK00  ...        73.5         24.9\n",
              "3677  2005   FRY  ...         0.0          0.0\n",
              "1833  2015   DEF  ...        88.1         23.5\n",
              "7717  2013  UKJ4  ...        85.1         39.2\n",
              "7667  2017  UKJ1  ...        88.8         55.5\n",
              "\n",
              "[10 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIhZcmRAUvbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "1a59c7cb-dadf-4c8c-afe5-54f5d7286a60"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGEMOTH</th>\n",
              "      <th>TOTFERRT</th>\n",
              "      <th>GBIRTHRT</th>\n",
              "      <th>GDEATHRT</th>\n",
              "      <th>RT</th>\n",
              "      <th>PER_KM2</th>\n",
              "      <th>EUR_HAB_EU</th>\n",
              "      <th>ED_LOW</th>\n",
              "      <th>ED_HIGH</th>\n",
              "      <th>EMP_PC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4553.000000</td>\n",
              "      <td>4553.000000</td>\n",
              "      <td>4726.000000</td>\n",
              "      <td>4688.000000</td>\n",
              "      <td>4535.000000</td>\n",
              "      <td>5063.000000</td>\n",
              "      <td>4274.000000</td>\n",
              "      <td>4501.000000</td>\n",
              "      <td>4517.000000</td>\n",
              "      <td>3799.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.331496</td>\n",
              "      <td>1.582546</td>\n",
              "      <td>10.762992</td>\n",
              "      <td>9.887991</td>\n",
              "      <td>4.932172</td>\n",
              "      <td>382.158681</td>\n",
              "      <td>94.124474</td>\n",
              "      <td>25.558454</td>\n",
              "      <td>27.560040</td>\n",
              "      <td>45.534483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.337198</td>\n",
              "      <td>0.325652</td>\n",
              "      <td>2.568682</td>\n",
              "      <td>1.922314</td>\n",
              "      <td>2.980237</td>\n",
              "      <td>978.579942</td>\n",
              "      <td>61.314426</td>\n",
              "      <td>16.774505</td>\n",
              "      <td>11.283108</td>\n",
              "      <td>8.912151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>24.300000</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>27.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>28.700000</td>\n",
              "      <td>1.350000</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>29.400000</td>\n",
              "      <td>1.520000</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>112.800000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>20.400000</td>\n",
              "      <td>26.800000</td>\n",
              "      <td>45.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>30.200000</td>\n",
              "      <td>1.810000</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>10.900000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>265.700000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>31.900000</td>\n",
              "      <td>35.700000</td>\n",
              "      <td>48.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>32.500000</td>\n",
              "      <td>3.940000</td>\n",
              "      <td>30.900000</td>\n",
              "      <td>19.800000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>10205.400000</td>\n",
              "      <td>716.000000</td>\n",
              "      <td>88.900000</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>156.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           AGEMOTH     TOTFERRT  ...      ED_HIGH       EMP_PC\n",
              "count  4553.000000  4553.000000  ...  4517.000000  3799.000000\n",
              "mean     29.331496     1.582546  ...    27.560040    45.534483\n",
              "std       1.337198     0.325652  ...    11.283108     8.912151\n",
              "min      24.300000     0.860000  ...     2.900000    27.600000\n",
              "25%      28.700000     1.350000  ...    19.000000    41.000000\n",
              "50%      29.400000     1.520000  ...    26.800000    45.200000\n",
              "75%      30.200000     1.810000  ...    35.700000    48.700000\n",
              "max      32.500000     3.940000  ...    77.500000   156.700000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW11JyIx2Dio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate Pandas Profiling Report and export to html\n",
        "\n",
        "import pandas_profiling\n",
        "\n",
        "profile_report = train.profile_report(\n",
        "    check_correlation_pearson=True,\n",
        "    correlations={\n",
        "        'pearson': True,\n",
        "        'spearman': False,\n",
        "        'kendall': False,\n",
        "        'phi_k': False,\n",
        "        'cramers': False,\n",
        "        'recoded': False,\n",
        "    },\n",
        "    plot={'histogram': {'bayesian_blocks_bins': False}},\n",
        "    )\n",
        "\n",
        "profile_report.to_file(output_file=\"train.html\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTi09Ru40pO9",
        "colab_type": "text"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEoyD5YrunPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2f63df04-d3cb-4f5b-ed54-6394f39641c8"
      },
      "source": [
        "y = train['MIG_CAT']\n",
        "y.value_counts(normalize=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "low     0.359925\n",
              "high    0.326217\n",
              "avg     0.313858\n",
              "Name: MIG_CAT, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwAFi8Zr1iBj",
        "colab_type": "text"
      },
      "source": [
        "**STILL TO DO: Make val & test use the same 3 bins!**\n",
        "\n",
        "In wrangle function migration rates are 'pd.qcut' into 3 groups. As Eurostat migration rates are rounded to 0.1 percentage point, bins are not exactly same size.\n",
        "\n",
        "Baseline prediction: majority class (low) occurs with 36% frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZY5Dnv2SrSQ",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgqQV5DtSskN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'MIG_CAT'\n",
        "features = train.columns.drop([target, 'GEO_LABEL'])\n",
        "\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "X_test = test[features]\n",
        "\n",
        "y_train = train[target]\n",
        "y_val = val[target]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JwPZjEwTPXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0df6ece-2848-42ff-d7f7-5f2f581e0d2c"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.5955056179775281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnuJWxs2uicb",
        "colab_type": "text"
      },
      "source": [
        "## Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l57qMzzukph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "ec4da908-566c-41dd-d44d-102683e9110a"
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 12\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAooAAAF4CAYAAADTxtgDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEqSJKmSQVGSJEmV/j8+IcheZPIvJwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_6WYFTmut11",
        "colab_type": "text"
      },
      "source": [
        "## Drop-Column Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R56XzaQ9uzkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "99cd1920-8d9a-4582-c94a-a8569b82f6a8"
      },
      "source": [
        "column  = 'EUR_HAB_EU'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without EUR_HAB_EU: 0.5737827715355805\n",
            "Validation Accuracy with EUR_HAB_EU: 0.5955056179775281\n",
            "Drop-Column Importance for EUR_HAB_EU: 0.021722846441947552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1TWYipovATO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d74255c8-89fc-4a73-c40f-cdbd9da2e25e"
      },
      "source": [
        "column  = 'GEO'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without GEO: 0.5655430711610487\n",
            "Drop-Column Importance for GEO: 0.029962546816479363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muVjlJlTvNC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "456a632f-b034-4bd4-909f-437e7afe66c5"
      },
      "source": [
        "column  = 'PER_KM2'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without PER_KM2: 0.5812734082397004\n",
            "Drop-Column Importance for PER_KM2: 0.014232209737827684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETf-syH7vUDL",
        "colab_type": "text"
      },
      "source": [
        "## Permutation Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucfSHw_PJJ8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median')\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpSemTkFFP8i",
        "outputId": "f0ce1e57-4087-49d2-e213-6a04f1d65570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCeRRyAWvtco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "99728dc8-f309-4780-ced1-7d61ae95b061"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.10.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.3.3)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zfHiZZKJmqf",
        "colab_type": "code",
        "outputId": "481e4a05-0d11-43b5-b479-07671812dff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "# 1. Calculate permutation importances\n",
        "permuter = PermutationImportance(\n",
        "    model, \n",
        "    scoring='accuracy', \n",
        "    n_iter=5, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PermutationImportance(cv='prefit',\n",
              "                      estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                       class_weight=None,\n",
              "                                                       criterion='gini',\n",
              "                                                       max_depth=None,\n",
              "                                                       max_features='auto',\n",
              "                                                       max_leaf_nodes=None,\n",
              "                                                       min_impurity_decrease=0.0,\n",
              "                                                       min_impurity_split=None,\n",
              "                                                       min_samples_leaf=1,\n",
              "                                                       min_samples_split=2,\n",
              "                                                       min_weight_fraction_leaf=0.0,\n",
              "                                                       n_estimators=100,\n",
              "                                                       n_jobs=-1,\n",
              "                                                       oob_score=False,\n",
              "                                                       random_state=42,\n",
              "                                                       verbose=0,\n",
              "                                                       warm_start=False),\n",
              "                      n_iter=5, random_state=42, refit=True,\n",
              "                      scoring='accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peq3dVRzv5id",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "608f391e-5ba6-43ac-9cbe-d4faaf228aa2"
      },
      "source": [
        "feature_names = X_val.columns.tolist()\n",
        "# pd.Series(permuter.feature_importances_, feature_names).sort_values()\n",
        "\n",
        "# 2. Display permutation importances\n",
        "eli5.show_weights(\n",
        "    permuter, \n",
        "    top=None, # show permutation importances for all features\n",
        "    feature_names=feature_names # must be a list\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0821\n",
              "                \n",
              "                    &plusmn; 0.0065\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                EUR_HAB_EU\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 84.84%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0553\n",
              "                \n",
              "                    &plusmn; 0.0152\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                EMP_PC\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 86.97%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0445\n",
              "                \n",
              "                    &plusmn; 0.0133\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                GEO\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0379\n",
              "                \n",
              "                    &plusmn; 0.0054\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                GDEATHRT\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.98%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0351\n",
              "                \n",
              "                    &plusmn; 0.0067\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PER_KM2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 92.19%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0214\n",
              "                \n",
              "                    &plusmn; 0.0175\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                AGEMOTH\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0141\n",
              "                \n",
              "                    &plusmn; 0.0113\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ED_HIGH\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.17%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0108\n",
              "                \n",
              "                    &plusmn; 0.0143\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                RT\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.17%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0108\n",
              "                \n",
              "                    &plusmn; 0.0111\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ED_LOW\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.52%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0067\n",
              "                \n",
              "                    &plusmn; 0.0098\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                TOTFERRT\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.20%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0049\n",
              "                \n",
              "                    &plusmn; 0.0051\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                GBIRTHRT\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                TIME\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5-ahM4PyRgT",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRGt5fTGyVCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this case just an elaborate way to drop 'TIME'.\n",
        "\n",
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "features = X_train.columns[mask]\n",
        "X_train = X_train[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sTTvB4PyY7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "744c56c7-2a9c-4377-df99-6475978a3fb8"
      },
      "source": [
        "X_val = X_val[features]\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.6262172284644195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnzzYyXSyuxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e84c9271-57d9-4f54-8bb4-ca46cf978e20"
      },
      "source": [
        "permuter.feature_importances_ - permuter.feature_importances_std_ > 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA2tT5jCwbKo",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M53ZRadiweWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "ad7da805-dd64-457a-9ec3-d881ca00c5fe"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['GEO'], drop_invariant=False,\n",
              "                                handle_missing='value', handle_unknown='value',\n",
              "                                mapping=[{'col': 'GEO', 'data_type': dtype('O'),\n",
              "                                          'mapping': AT        1\n",
              "AT1       2\n",
              "AT11      3\n",
              "AT12      4\n",
              "AT13      5\n",
              "       ... \n",
              "UKM8    442\n",
              "UKM9    443\n",
              "UKN     444\n",
              "UKN0    445\n",
              "NaN      -2\n",
              "Length: 446, dtype: int64}],\n",
              "                                return_df=True, verbose=0)),\n",
              "                ('xgbclassifier',\n",
              "                 XGBClassifier(base_score=0.5...oster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgsUR-Ljwj_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9f75563-86a6-4835-a92e-026a4cbfd556"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.5632958801498127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5cs7RUqwpug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48b3fea4-cd83-4ed1-81e6-52a1108cbf33"
      },
      "source": [
        "# fit_transfom on train, transform on val\n",
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000,  # <= 1000 trees, depends on early stopping\n",
        "    max_depth=5,       # try deeper trees because of high cardinality categoricals\n",
        "    learning_rate=0.4,  # try higher learning rate\n",
        "    min_child_weight=0.5,  \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "eval_set = [(X_train_encoded, y_train), \n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "model.fit(X_train_encoded, y_train, \n",
        "          eval_set=eval_set,\n",
        "          eval_metric='merror', \n",
        "          early_stopping_rounds=50) # Stop if the score hasn't improved in 50 rounds"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.319476\tvalidation_1-merror:0.530337\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.276779\tvalidation_1-merror:0.489139\n",
            "[2]\tvalidation_0-merror:0.248502\tvalidation_1-merror:0.46367\n",
            "[3]\tvalidation_0-merror:0.220412\tvalidation_1-merror:0.433708\n",
            "[4]\tvalidation_0-merror:0.218914\tvalidation_1-merror:0.434457\n",
            "[5]\tvalidation_0-merror:0.211985\tvalidation_1-merror:0.453184\n",
            "[6]\tvalidation_0-merror:0.201685\tvalidation_1-merror:0.444944\n",
            "[7]\tvalidation_0-merror:0.191573\tvalidation_1-merror:0.438202\n",
            "[8]\tvalidation_0-merror:0.18764\tvalidation_1-merror:0.434457\n",
            "[9]\tvalidation_0-merror:0.182022\tvalidation_1-merror:0.429963\n",
            "[10]\tvalidation_0-merror:0.175468\tvalidation_1-merror:0.431461\n",
            "[11]\tvalidation_0-merror:0.16779\tvalidation_1-merror:0.427715\n",
            "[12]\tvalidation_0-merror:0.158052\tvalidation_1-merror:0.42397\n",
            "[13]\tvalidation_0-merror:0.154307\tvalidation_1-merror:0.426217\n",
            "[14]\tvalidation_0-merror:0.156367\tvalidation_1-merror:0.429213\n",
            "[15]\tvalidation_0-merror:0.148689\tvalidation_1-merror:0.420225\n",
            "[16]\tvalidation_0-merror:0.146442\tvalidation_1-merror:0.423221\n",
            "[17]\tvalidation_0-merror:0.140824\tvalidation_1-merror:0.42397\n",
            "[18]\tvalidation_0-merror:0.13839\tvalidation_1-merror:0.422472\n",
            "[19]\tvalidation_0-merror:0.133895\tvalidation_1-merror:0.426217\n",
            "[20]\tvalidation_0-merror:0.12809\tvalidation_1-merror:0.420225\n",
            "[21]\tvalidation_0-merror:0.120412\tvalidation_1-merror:0.420225\n",
            "[22]\tvalidation_0-merror:0.118539\tvalidation_1-merror:0.424719\n",
            "[23]\tvalidation_0-merror:0.115543\tvalidation_1-merror:0.418727\n",
            "[24]\tvalidation_0-merror:0.110861\tvalidation_1-merror:0.417978\n",
            "[25]\tvalidation_0-merror:0.108052\tvalidation_1-merror:0.405993\n",
            "[26]\tvalidation_0-merror:0.103558\tvalidation_1-merror:0.403745\n",
            "[27]\tvalidation_0-merror:0.100375\tvalidation_1-merror:0.4\n",
            "[28]\tvalidation_0-merror:0.097753\tvalidation_1-merror:0.400749\n",
            "[29]\tvalidation_0-merror:0.096816\tvalidation_1-merror:0.402996\n",
            "[30]\tvalidation_0-merror:0.090637\tvalidation_1-merror:0.402247\n",
            "[31]\tvalidation_0-merror:0.084831\tvalidation_1-merror:0.403745\n",
            "[32]\tvalidation_0-merror:0.082959\tvalidation_1-merror:0.402247\n",
            "[33]\tvalidation_0-merror:0.080337\tvalidation_1-merror:0.397004\n",
            "[34]\tvalidation_0-merror:0.078464\tvalidation_1-merror:0.397753\n",
            "[35]\tvalidation_0-merror:0.075655\tvalidation_1-merror:0.393258\n",
            "[36]\tvalidation_0-merror:0.073783\tvalidation_1-merror:0.392509\n",
            "[37]\tvalidation_0-merror:0.071348\tvalidation_1-merror:0.390262\n",
            "[38]\tvalidation_0-merror:0.068539\tvalidation_1-merror:0.38427\n",
            "[39]\tvalidation_0-merror:0.065918\tvalidation_1-merror:0.382022\n",
            "[40]\tvalidation_0-merror:0.064794\tvalidation_1-merror:0.382772\n",
            "[41]\tvalidation_0-merror:0.058614\tvalidation_1-merror:0.382022\n",
            "[42]\tvalidation_0-merror:0.056742\tvalidation_1-merror:0.377528\n",
            "[43]\tvalidation_0-merror:0.054682\tvalidation_1-merror:0.381273\n",
            "[44]\tvalidation_0-merror:0.053371\tvalidation_1-merror:0.382022\n",
            "[45]\tvalidation_0-merror:0.05206\tvalidation_1-merror:0.377528\n",
            "[46]\tvalidation_0-merror:0.051873\tvalidation_1-merror:0.377528\n",
            "[47]\tvalidation_0-merror:0.049813\tvalidation_1-merror:0.379775\n",
            "[48]\tvalidation_0-merror:0.049064\tvalidation_1-merror:0.381273\n",
            "[49]\tvalidation_0-merror:0.049813\tvalidation_1-merror:0.379026\n",
            "[50]\tvalidation_0-merror:0.047753\tvalidation_1-merror:0.376779\n",
            "[51]\tvalidation_0-merror:0.04588\tvalidation_1-merror:0.375281\n",
            "[52]\tvalidation_0-merror:0.04382\tvalidation_1-merror:0.375281\n",
            "[53]\tvalidation_0-merror:0.043071\tvalidation_1-merror:0.37603\n",
            "[54]\tvalidation_0-merror:0.043071\tvalidation_1-merror:0.379026\n",
            "[55]\tvalidation_0-merror:0.038577\tvalidation_1-merror:0.382022\n",
            "[56]\tvalidation_0-merror:0.03633\tvalidation_1-merror:0.383521\n",
            "[57]\tvalidation_0-merror:0.036142\tvalidation_1-merror:0.382022\n",
            "[58]\tvalidation_0-merror:0.035768\tvalidation_1-merror:0.383521\n",
            "[59]\tvalidation_0-merror:0.03427\tvalidation_1-merror:0.381273\n",
            "[60]\tvalidation_0-merror:0.032397\tvalidation_1-merror:0.380524\n",
            "[61]\tvalidation_0-merror:0.032022\tvalidation_1-merror:0.38427\n",
            "[62]\tvalidation_0-merror:0.031648\tvalidation_1-merror:0.382772\n",
            "[63]\tvalidation_0-merror:0.030712\tvalidation_1-merror:0.381273\n",
            "[64]\tvalidation_0-merror:0.029588\tvalidation_1-merror:0.380524\n",
            "[65]\tvalidation_0-merror:0.029026\tvalidation_1-merror:0.381273\n",
            "[66]\tvalidation_0-merror:0.028277\tvalidation_1-merror:0.381273\n",
            "[67]\tvalidation_0-merror:0.026592\tvalidation_1-merror:0.377528\n",
            "[68]\tvalidation_0-merror:0.025094\tvalidation_1-merror:0.378277\n",
            "[69]\tvalidation_0-merror:0.024532\tvalidation_1-merror:0.379775\n",
            "[70]\tvalidation_0-merror:0.023221\tvalidation_1-merror:0.37603\n",
            "[71]\tvalidation_0-merror:0.022846\tvalidation_1-merror:0.375281\n",
            "[72]\tvalidation_0-merror:0.022472\tvalidation_1-merror:0.371536\n",
            "[73]\tvalidation_0-merror:0.02191\tvalidation_1-merror:0.371536\n",
            "[74]\tvalidation_0-merror:0.021161\tvalidation_1-merror:0.372285\n",
            "[75]\tvalidation_0-merror:0.020974\tvalidation_1-merror:0.373034\n",
            "[76]\tvalidation_0-merror:0.019663\tvalidation_1-merror:0.374532\n",
            "[77]\tvalidation_0-merror:0.018165\tvalidation_1-merror:0.373034\n",
            "[78]\tvalidation_0-merror:0.016479\tvalidation_1-merror:0.373034\n",
            "[79]\tvalidation_0-merror:0.016105\tvalidation_1-merror:0.373783\n",
            "[80]\tvalidation_0-merror:0.015918\tvalidation_1-merror:0.373034\n",
            "[81]\tvalidation_0-merror:0.015169\tvalidation_1-merror:0.374532\n",
            "[82]\tvalidation_0-merror:0.013858\tvalidation_1-merror:0.373034\n",
            "[83]\tvalidation_0-merror:0.014045\tvalidation_1-merror:0.373783\n",
            "[84]\tvalidation_0-merror:0.013858\tvalidation_1-merror:0.370787\n",
            "[85]\tvalidation_0-merror:0.013858\tvalidation_1-merror:0.370787\n",
            "[86]\tvalidation_0-merror:0.012921\tvalidation_1-merror:0.373783\n",
            "[87]\tvalidation_0-merror:0.012921\tvalidation_1-merror:0.373034\n",
            "[88]\tvalidation_0-merror:0.011985\tvalidation_1-merror:0.372285\n",
            "[89]\tvalidation_0-merror:0.011236\tvalidation_1-merror:0.373034\n",
            "[90]\tvalidation_0-merror:0.009551\tvalidation_1-merror:0.370787\n",
            "[91]\tvalidation_0-merror:0.009363\tvalidation_1-merror:0.370037\n",
            "[92]\tvalidation_0-merror:0.008989\tvalidation_1-merror:0.367041\n",
            "[93]\tvalidation_0-merror:0.009176\tvalidation_1-merror:0.364794\n",
            "[94]\tvalidation_0-merror:0.008989\tvalidation_1-merror:0.365543\n",
            "[95]\tvalidation_0-merror:0.00824\tvalidation_1-merror:0.366292\n",
            "[96]\tvalidation_0-merror:0.008052\tvalidation_1-merror:0.361049\n",
            "[97]\tvalidation_0-merror:0.007116\tvalidation_1-merror:0.361798\n",
            "[98]\tvalidation_0-merror:0.006929\tvalidation_1-merror:0.3603\n",
            "[99]\tvalidation_0-merror:0.007116\tvalidation_1-merror:0.358052\n",
            "[100]\tvalidation_0-merror:0.006554\tvalidation_1-merror:0.358052\n",
            "[101]\tvalidation_0-merror:0.00618\tvalidation_1-merror:0.3603\n",
            "[102]\tvalidation_0-merror:0.005805\tvalidation_1-merror:0.361798\n",
            "[103]\tvalidation_0-merror:0.004682\tvalidation_1-merror:0.361798\n",
            "[104]\tvalidation_0-merror:0.004307\tvalidation_1-merror:0.361049\n",
            "[105]\tvalidation_0-merror:0.003933\tvalidation_1-merror:0.3603\n",
            "[106]\tvalidation_0-merror:0.003933\tvalidation_1-merror:0.359551\n",
            "[107]\tvalidation_0-merror:0.003558\tvalidation_1-merror:0.358801\n",
            "[108]\tvalidation_0-merror:0.003371\tvalidation_1-merror:0.3603\n",
            "[109]\tvalidation_0-merror:0.003184\tvalidation_1-merror:0.3603\n",
            "[110]\tvalidation_0-merror:0.003184\tvalidation_1-merror:0.3603\n",
            "[111]\tvalidation_0-merror:0.002996\tvalidation_1-merror:0.3603\n",
            "[112]\tvalidation_0-merror:0.002996\tvalidation_1-merror:0.361049\n",
            "[113]\tvalidation_0-merror:0.002809\tvalidation_1-merror:0.358052\n",
            "[114]\tvalidation_0-merror:0.002434\tvalidation_1-merror:0.359551\n",
            "[115]\tvalidation_0-merror:0.002247\tvalidation_1-merror:0.359551\n",
            "[116]\tvalidation_0-merror:0.002247\tvalidation_1-merror:0.358801\n",
            "[117]\tvalidation_0-merror:0.001873\tvalidation_1-merror:0.358052\n",
            "[118]\tvalidation_0-merror:0.00206\tvalidation_1-merror:0.356554\n",
            "[119]\tvalidation_0-merror:0.00206\tvalidation_1-merror:0.356554\n",
            "[120]\tvalidation_0-merror:0.00206\tvalidation_1-merror:0.356554\n",
            "[121]\tvalidation_0-merror:0.00206\tvalidation_1-merror:0.355805\n",
            "[122]\tvalidation_0-merror:0.001873\tvalidation_1-merror:0.353558\n",
            "[123]\tvalidation_0-merror:0.001685\tvalidation_1-merror:0.354307\n",
            "[124]\tvalidation_0-merror:0.001498\tvalidation_1-merror:0.353558\n",
            "[125]\tvalidation_0-merror:0.001498\tvalidation_1-merror:0.355056\n",
            "[126]\tvalidation_0-merror:0.001498\tvalidation_1-merror:0.355056\n",
            "[127]\tvalidation_0-merror:0.001311\tvalidation_1-merror:0.355056\n",
            "[128]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.355056\n",
            "[129]\tvalidation_0-merror:0.001124\tvalidation_1-merror:0.355805\n",
            "[130]\tvalidation_0-merror:0.001124\tvalidation_1-merror:0.355805\n",
            "[131]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.357303\n",
            "[132]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.357303\n",
            "[133]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.356554\n",
            "[134]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.355805\n",
            "[135]\tvalidation_0-merror:0.001124\tvalidation_1-merror:0.357303\n",
            "[136]\tvalidation_0-merror:0.001124\tvalidation_1-merror:0.358801\n",
            "[137]\tvalidation_0-merror:0.001124\tvalidation_1-merror:0.356554\n",
            "[138]\tvalidation_0-merror:0.000749\tvalidation_1-merror:0.356554\n",
            "[139]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.356554\n",
            "[140]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.356554\n",
            "[141]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.358801\n",
            "[142]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.358801\n",
            "[143]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.357303\n",
            "[144]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.361049\n",
            "[145]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.361049\n",
            "[146]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.358801\n",
            "[147]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.3603\n",
            "[148]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.358801\n",
            "[149]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.358052\n",
            "[150]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.358801\n",
            "[151]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.359551\n",
            "[152]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.358801\n",
            "[153]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.358801\n",
            "[154]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.361049\n",
            "[155]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.354307\n",
            "[156]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.356554\n",
            "[157]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.352809\n",
            "[158]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.356554\n",
            "[159]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.355056\n",
            "[160]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.357303\n",
            "[161]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.357303\n",
            "[162]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.357303\n",
            "[163]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.359551\n",
            "[164]\tvalidation_0-merror:0.000187\tvalidation_1-merror:0.358801\n",
            "[165]\tvalidation_0-merror:0.000187\tvalidation_1-merror:0.359551\n",
            "[166]\tvalidation_0-merror:0.000187\tvalidation_1-merror:0.359551\n",
            "[167]\tvalidation_0-merror:0\tvalidation_1-merror:0.358801\n",
            "[168]\tvalidation_0-merror:0\tvalidation_1-merror:0.358052\n",
            "[169]\tvalidation_0-merror:0\tvalidation_1-merror:0.359551\n",
            "[170]\tvalidation_0-merror:0\tvalidation_1-merror:0.358052\n",
            "[171]\tvalidation_0-merror:0\tvalidation_1-merror:0.353558\n",
            "[172]\tvalidation_0-merror:0\tvalidation_1-merror:0.352809\n",
            "[173]\tvalidation_0-merror:0\tvalidation_1-merror:0.357303\n",
            "[174]\tvalidation_0-merror:0\tvalidation_1-merror:0.355056\n",
            "[175]\tvalidation_0-merror:0\tvalidation_1-merror:0.355056\n",
            "[176]\tvalidation_0-merror:0\tvalidation_1-merror:0.356554\n",
            "[177]\tvalidation_0-merror:0\tvalidation_1-merror:0.356554\n",
            "[178]\tvalidation_0-merror:0\tvalidation_1-merror:0.355056\n",
            "[179]\tvalidation_0-merror:0\tvalidation_1-merror:0.355805\n",
            "[180]\tvalidation_0-merror:0\tvalidation_1-merror:0.357303\n",
            "[181]\tvalidation_0-merror:0\tvalidation_1-merror:0.358801\n",
            "[182]\tvalidation_0-merror:0\tvalidation_1-merror:0.359551\n",
            "[183]\tvalidation_0-merror:0\tvalidation_1-merror:0.358801\n",
            "[184]\tvalidation_0-merror:0\tvalidation_1-merror:0.3603\n",
            "[185]\tvalidation_0-merror:0\tvalidation_1-merror:0.361049\n",
            "[186]\tvalidation_0-merror:0\tvalidation_1-merror:0.362547\n",
            "[187]\tvalidation_0-merror:0\tvalidation_1-merror:0.361049\n",
            "[188]\tvalidation_0-merror:0\tvalidation_1-merror:0.361798\n",
            "[189]\tvalidation_0-merror:0\tvalidation_1-merror:0.361798\n",
            "[190]\tvalidation_0-merror:0\tvalidation_1-merror:0.361798\n",
            "[191]\tvalidation_0-merror:0\tvalidation_1-merror:0.363296\n",
            "[192]\tvalidation_0-merror:0\tvalidation_1-merror:0.362547\n",
            "[193]\tvalidation_0-merror:0\tvalidation_1-merror:0.363296\n",
            "[194]\tvalidation_0-merror:0\tvalidation_1-merror:0.359551\n",
            "[195]\tvalidation_0-merror:0\tvalidation_1-merror:0.361049\n",
            "[196]\tvalidation_0-merror:0\tvalidation_1-merror:0.362547\n",
            "[197]\tvalidation_0-merror:0\tvalidation_1-merror:0.364794\n",
            "[198]\tvalidation_0-merror:0\tvalidation_1-merror:0.366292\n",
            "[199]\tvalidation_0-merror:0\tvalidation_1-merror:0.366292\n",
            "[200]\tvalidation_0-merror:0\tvalidation_1-merror:0.367041\n",
            "[201]\tvalidation_0-merror:0\tvalidation_1-merror:0.364045\n",
            "[202]\tvalidation_0-merror:0\tvalidation_1-merror:0.365543\n",
            "[203]\tvalidation_0-merror:0\tvalidation_1-merror:0.365543\n",
            "[204]\tvalidation_0-merror:0\tvalidation_1-merror:0.365543\n",
            "[205]\tvalidation_0-merror:0\tvalidation_1-merror:0.365543\n",
            "[206]\tvalidation_0-merror:0\tvalidation_1-merror:0.365543\n",
            "[207]\tvalidation_0-merror:0\tvalidation_1-merror:0.364794\n",
            "Stopping. Best iteration:\n",
            "[157]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.352809\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.4, max_delta_step=0, max_depth=5,\n",
              "              min_child_weight=0.5, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESaAI8ZrxswQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1ae81ba2-544b-44e8-e881-de36518033e4"
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "# plt.ylim((0.35, 0.4)) # Zoom in\n",
        "plt.legend();"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEKCAYAAADw2zkCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTQZKKaXQZKCUUgpNBkoppdBkoJRSCvh/pg941BLeSkwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}