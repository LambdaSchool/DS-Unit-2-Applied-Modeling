{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_applied_modeling_3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WL8mwm0rUaQo",
        "VVwrSjCM9B9R",
        "cjY9_sCt9EPv",
        "8aYdcNBycMpv",
        "SSTHtmKa-Y4x"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lechemrc/DS-Unit-2-Applied-Modeling/blob/master/module3/assignment_applied_modeling_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Applied Modeling, Module 3\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your work.\n",
        "\n",
        "- [ ] Continue to iterate on your project: data cleaning, exploration, feature engineering, modeling.\n",
        "- [ ] Make at least 1 partial dependence plot to explain your model.\n",
        "- [ ] Share at least 1 visualization on Slack.\n",
        "\n",
        "(If you have not yet completed an initial model yet for your portfolio project, then do today's assignment using your Tanzania Waterpumps model.)\n",
        "\n",
        "## Stretch Goals\n",
        "- [ ] Make multiple PDPs with 1 feature in isolation.\n",
        "- [ ] Make multiple PDPs with 2 features in interaction. \n",
        "- [ ] Use Plotly to make a 3D PDP.\n",
        "- [ ] Make PDPs with categorical feature(s). Use Ordinal Encoder, outside of a pipeline, to encode your data first. If there is a natural ordering, then take the time to encode it that way, instead of random integers. Then use the encoded data with pdpbox.I Get readable category names on your plot, instead of integer category codes.\n",
        "\n",
        "## Links\n",
        "- [Christoph Molnar: Interpretable Machine Learning — Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html) + [animated explanation](https://twitter.com/ChristophMolnar/status/1066398522608635904)\n",
        "- [Kaggle / Dan Becker: Machine Learning Explainability — Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
        "- [Plotly: 3D PDP example](https://plot.ly/scikit-learn/plot-partial-dependence/#partial-dependence-of-house-value-on-median-age-and-average-occupancy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL8mwm0rUaQo",
        "colab_type": "text"
      },
      "source": [
        "### Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLQ8sFRMUSef",
        "colab_type": "code",
        "outputId": "22ef2274-df1e-4629-96d3-a43df3beb07d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module1')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Total 77 (delta 0), reused 0 (delta 0), pack-reused 77\u001b[K\n",
            "Unpacking objects: 100% (77/77), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n",
            "Checking out files: 100% (26/26), done.\n",
            "Collecting category_encoders==2.0.0 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.8MB/s \n",
            "\u001b[?25hCollecting eli5==0.10.1 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
            "Collecting pandas-profiling==2.3.0 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 41.7MB/s \n",
            "\u001b[?25hCollecting pdpbox==0.2.0 (from -r requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/23/ac7da5ba1c6c03a87c412e7e7b6e91a10d6ecf4474906c3e736f93940d49/PDPbox-0.2.0.tar.gz (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 329kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.21.3)\n",
            "Collecting shap==0.30.0 (from -r requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/98/16829410426bdd08b836c30e164c56646d6a102afb9eadd81a6bd3a8bb65/shap-0.30.0.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.90)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.16.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (19.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (2.10.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.8.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 45.2MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.1.1->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (4.28.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.0.0->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5==0.10.1->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.1.1->-r requirements.txt (line 3)) (41.2.0)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.40.1)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/91/d68f68ce54cd3e8afa1ef73ea1ad44df2438521b64c0820e5fd9b9f13b7d/pytest-5.2.1-py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 41.4MB/s \n",
            "\u001b[?25hCollecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.3.3)\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.3.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (4.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (19.2)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (7.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.23)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/ed/1cb8e7b85a31807aa0bff8b3e60935370bed7e141df8b530aac6352bddff/pylint-2.4.2-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (17.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (0.46)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Collecting astroid<2.4,>=2.3.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/e1/74a63c85c501c29c52da5be604c025e368f4dd77daf1fa13c878a33e5a36/astroid-2.3.1-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 50.9MB/s \n",
            "\u001b[?25hCollecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 25.4MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 53.6MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy==1.4.* (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt==1.11.* in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.11.2)\n",
            "Building wheels for collected packages: pandas-profiling, pdpbox, shap, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145035 sha256=1d8d408279ad1602ddee47107b20ed2fe85e2d83468e33bbe242619eba54fcf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for pdpbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdpbox: filename=PDPbox-0.2.0-cp36-none-any.whl size=57690723 sha256=6c7c34d497dc4914eb1ecab6ed5df39b39056141b4a9a3f0b1560f643f5f1973\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/08/51/63fd122b04a2c87d780464eeffb94867c75bd96a64d500a3fe\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.30.0-cp36-cp36m-linux_x86_64.whl size=356738 sha256=63bc1a282141787158754c7274ff3921d3e5bd73fd1d4e4a6d41f56ef4f5d058\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/7a/5b/34feab81170fb8bf642a7536b5127e54e00bce373564435808\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=e71de197b5e45a860d199318e1b2190c0ded788ebd0df922ba829a34430da510\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17486 sha256=f142267bb4219a6b9588ecdc99a76613e0357974a8be470e32dc7839ae5eaad4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling pdpbox shap htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: category-encoders, eli5, htmlmin, pluggy, pytest, typed-ast, lazy-object-proxy, astroid, isort, mccabe, pylint, pytest-pylint, phik, confuse, pandas-profiling, pdpbox, shap\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.3.1 category-encoders-2.0.0 confuse-1.0.0 eli5-0.10.1 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.2 mccabe-0.6.1 pandas-profiling-2.3.0 pdpbox-0.2.0 phik-0.9.8 pluggy-0.13.0 pylint-2.4.2 pytest-5.2.1 pytest-pylint-0.14.1 shap-0.30.0 typed-ast-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVwrSjCM9B9R",
        "colab_type": "text"
      },
      "source": [
        "### Important Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnMUTmIuUfkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# libraries and math functions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas_profiling\n",
        "from scipy.io import arff # for loading .arff file\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# imports for pipeline and regression\n",
        "import category_encoders as ce\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from ipywidgets import interact, fixed\n",
        "\n",
        "# plotting\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjY9_sCt9EPv",
        "colab_type": "text"
      },
      "source": [
        "### Importing dataset\n",
        "\n",
        "Dataset has largely been cleaned previously "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrfx0ECB9Fo9",
        "colab_type": "code",
        "outputId": "a2469d33-f8a2-4834-febb-665ff05e8a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/lechemrc/Datasets-to-ref/master/Autism%20Screening%20for%20Children/csv_result-Autism-Child-Data.csv', na_values='?')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(292, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>A1_Score</th>\n",
              "      <th>A2_Score</th>\n",
              "      <th>A3_Score</th>\n",
              "      <th>A4_Score</th>\n",
              "      <th>A5_Score</th>\n",
              "      <th>A6_Score</th>\n",
              "      <th>A7_Score</th>\n",
              "      <th>A8_Score</th>\n",
              "      <th>A9_Score</th>\n",
              "      <th>A10_Score</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>jundice</th>\n",
              "      <th>austim</th>\n",
              "      <th>contry_of_res</th>\n",
              "      <th>used_app_before</th>\n",
              "      <th>result</th>\n",
              "      <th>age_desc</th>\n",
              "      <th>relation</th>\n",
              "      <th>Class/ASD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>m</td>\n",
              "      <td>Others</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>Jordan</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>4-11 years</td>\n",
              "      <td>Parent</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>m</td>\n",
              "      <td>Middle Eastern</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>Jordan</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>4-11 years</td>\n",
              "      <td>Parent</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>m</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>Jordan</td>\n",
              "      <td>yes</td>\n",
              "      <td>5</td>\n",
              "      <td>4-11 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>f</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>Jordan</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>4-11 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>m</td>\n",
              "      <td>Others</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>United States</td>\n",
              "      <td>no</td>\n",
              "      <td>10</td>\n",
              "      <td>4-11 years</td>\n",
              "      <td>Parent</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  A1_Score  A2_Score  A3_Score  ...  result    age_desc  relation  Class/ASD\n",
              "0   1         1         1         0  ...       5  4-11 years    Parent         NO\n",
              "1   2         1         1         0  ...       5  4-11 years    Parent         NO\n",
              "2   3         1         1         0  ...       5  4-11 years       NaN         NO\n",
              "3   4         0         1         0  ...       4  4-11 years       NaN         NO\n",
              "4   5         1         1         1  ...      10  4-11 years    Parent        YES\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aYdcNBycMpv",
        "colab_type": "text"
      },
      "source": [
        "### Data Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkrIDPrXc4D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/lechemrc/Datasets-to-ref/master/Autism%20Screening%20for%20Children/csv_result-Autism-Child-Data.csv', na_values='?')\n",
        "\n",
        "def data_wrangle(df):\n",
        "  ''' cleaning the data with one function'''\n",
        "\n",
        "  # null values\n",
        "  df = df.fillna(value='unspecified')\n",
        "\n",
        "  # Dropping columns with single value\n",
        "  df = df.drop('age_desc', axis=1)\n",
        "\n",
        "  # Dropping id column to prevent obfuscation of data\n",
        "  df = df.drop('id', axis=1)\n",
        "\n",
        "  # Cleaning column names\n",
        "  df = df.rename(columns={'jundice':'born_jaundice', \n",
        "                          'austim':'family_pdd', \n",
        "                          'contry_of_res':'country', \n",
        "                          'used_app_before':'prior_screening'})\n",
        "  \n",
        "  # Changing the country column values to 'other' if there are less\n",
        "  # than 5 instances in the df\n",
        "  frequencies = df['country'].value_counts()\n",
        "  condition = frequencies <= 5\n",
        "  mask = frequencies[condition].index\n",
        "  mask_dict = dict.fromkeys(mask, 'other')\n",
        "\n",
        "  df['country'] = df['country'].replace(mask_dict)\n",
        "\n",
        "  # renaming values for clarity\n",
        "  df['relation'] = df['relation'].replace(\n",
        "      {'self':'Self', \n",
        "       'Health care professional':'Healthcare Professional', \n",
        "       'unspecified':'Unspecified'})\n",
        "  \n",
        "  df['ethnicity'] = df['ethnicity'].replace({'Pasifika':'Pacifica', \n",
        "                                           'Others':'unspecified'})\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pY1UnGXnA6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = data_wrangle(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSTHtmKa-Y4x",
        "colab_type": "text"
      },
      "source": [
        "### Regression and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx3xDab_YaWk",
        "colab_type": "code",
        "outputId": "31bca476-39ef-4be1-92e6-bd8b2ef2ce63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['Class/ASD'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NO     151\n",
              "YES    141\n",
              "Name: Class/ASD, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1znEzO0ZEr0",
        "colab_type": "code",
        "outputId": "e066bca9-8a03-440b-b666-503cccc78751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score',\n",
              "       'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age', 'gender',\n",
              "       'ethnicity', 'born_jaundice', 'family_pdd', 'country',\n",
              "       'prior_screening', 'result', 'relation', 'Class/ASD'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2WKwqSuZMkM",
        "colab_type": "code",
        "outputId": "d3a01adf-7107-4a23-a204-8ed79de000dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Result was giving the model 100% accuracy, \n",
        "# meaning there was major data leakage from it\n",
        "df['result'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8     44\n",
              "7     44\n",
              "5     41\n",
              "6     40\n",
              "4     33\n",
              "9     32\n",
              "10    21\n",
              "3     21\n",
              "2      9\n",
              "1      6\n",
              "0      1\n",
              "Name: result, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2o32hCa-gAK",
        "colab_type": "code",
        "outputId": "cf7d2fcd-f05e-49d5-f5f2-408eeef633ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Setting target and features\n",
        "target = 'Class/ASD'\n",
        "\n",
        "# Dropping 'result' and 'age' as they seem to be confounding and not helpful\n",
        "features = df.columns.drop([target, 'result', 'age', 'family_pdd'])\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Train / Test split\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42)\n",
        "\n",
        "# Train / Val split \n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=0.25, \n",
        "    stratify=y_trainval, random_state=42)\n",
        "\n",
        "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((174, 16), (174,), (59, 16), (59,), (59, 16), (59,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qi7z_Ezlp-D",
        "colab_type": "code",
        "outputId": "3a28fd35-eb61-4531-af39-5c9182677193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score',\n",
              "       'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'gender', 'ethnicity',\n",
              "       'born_jaundice', 'country', 'prior_screening', 'relation'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Pmq-ap9GH-",
        "colab_type": "text"
      },
      "source": [
        "#### Majority Class Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LWOZz76-Vt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.float_format = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRu7VrJpR2M_",
        "outputId": "05b55c26-9383-4bb2-c49b-b1c6bb9d527c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NO     0.517241\n",
              "YES    0.482759\n",
              "Name: Class/ASD, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ScnJsYSDeEu8",
        "outputId": "ff0dd3f3-acb9-40ef-8f73-dbe146b17b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Accuracy score using the majority class\n",
        "majority_class = y_train.mode()[0]\n",
        "y_pred = np.full_like(y_val, fill_value=majority_class)\n",
        "accuracy_score(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5084745762711864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcSHHRFwaSE8",
        "colab_type": "text"
      },
      "source": [
        "#### XGBoost with ordinal encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHk6H5HRZwMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# xgboost = make_pipeline(\n",
        "#     ce.OrdinalEncoder(),\n",
        "#     SimpleImputer(strategy='median')\n",
        "# )\n",
        "\n",
        "# X_train_processed = xgboost.fit_transform(X_train)\n",
        "# X_val_processed = xgboost.transform(X_val)\n",
        "\n",
        "# eval_set = [(X_train_processed, y_train), \n",
        "#             (X_val_processed, y_val)]\n",
        "\n",
        "# model = XGBClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "# model.fit(X_train_processed, y_train, eval_set=eval_set, eval_metric='auc', \n",
        "#           early_stopping_rounds=10)\n",
        "\n",
        "# y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cOGarbMtapph"
      },
      "source": [
        "#### Random Forest Classifier with ordinal encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G5q1hxXOappk",
        "colab": {}
      },
      "source": [
        "# random_forest_ord = make_pipeline(\n",
        "#     ce.OrdinalEncoder(),\n",
        "#     SimpleImputer(strategy='median'),\n",
        "#     RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
        "# )\n",
        "\n",
        "# random_forest_ord.fit(X_train, y_train)\n",
        "# y_pred = random_forest_ord.predict(X_test)\n",
        "# print('Validation Accuracy:', random_forest_ord.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqTBJTfRayyA",
        "colab_type": "text"
      },
      "source": [
        "The Random Forest Classifier with One Hot Encoder was the better model. XGBoost says it had a nearly 100% accuracy, but I'm very skeptical of that and figiure there's some overfitting happening. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbDz3HHgaVL1",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forest Classifier with One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfW2emmoEsXd",
        "colab_type": "code",
        "outputId": "a5e598b3-cb39-468d-b20c-ec2621f6ba02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "random_forest = make_pipeline(\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "print('Validation Accuracy:', random_forest.score(X_val, y_val), \n",
        "      '\\nTest Accuracy:', random_forest.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8305084745762712 \n",
            "Test Accuracy: 0.9322033898305084\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}