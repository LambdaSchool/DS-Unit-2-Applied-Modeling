{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 4*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your work.\n",
    "\n",
    "- [ ] Continue to iterate on your project: data cleaning, exploratory visualization, feature engineering, modeling.\n",
    "- [ ] Make at least 1 partial dependence plot to explain your model.\n",
    "- [ ] Make at least 1 Shapley force plot to explain an individual prediction.\n",
    "- [ ] **Share at least 1 visualization (of any type) on Slack!**\n",
    "\n",
    "If you aren't ready to make these plots with your own dataset, you can practice these objectives with any dataset you've worked with previously. Example solutions are available for Partial Dependence Plots with the Tanzania Waterpumps dataset, and Shapley force plots with the Titanic dataset. (These datasets are available in the data directory of this repository.)\n",
    "\n",
    "Please be aware that **multi-class classification** will result in multiple Partial Dependence Plots (one for each class), and multiple sets of Shapley Values (one for each class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "#### Partial Dependence Plots\n",
    "- [ ] Make multiple PDPs with 1 feature in isolation.\n",
    "- [ ] Make multiple PDPs with 2 features in interaction. \n",
    "- [ ] Use Plotly to make a 3D PDP.\n",
    "- [ ] Make PDPs with categorical feature(s). Use Ordinal Encoder, outside of a pipeline, to encode your data first. If there is a natural ordering, then take the time to encode it that way, instead of random integers. Then use the encoded data with pdpbox. Get readable category names on your plot, instead of integer category codes.\n",
    "\n",
    "#### Shap Values\n",
    "- [ ] Make Shapley force plots to explain at least 4 individual predictions.\n",
    "    - If your project is Binary Classification, you can do a True Positive, True Negative, False Positive, False Negative.\n",
    "    - If your project is Regression, you can do a high prediction with low error, a low prediction with low error, a high prediction with high error, and a low prediction with high error.\n",
    "- [ ] Use Shapley values to display verbal explanations of individual predictions.\n",
    "- [ ] Use the SHAP library for other visualization types.\n",
    "\n",
    "The [SHAP repo](https://github.com/slundberg/shap) has examples for many visualization types, including:\n",
    "\n",
    "- Force Plot, individual predictions\n",
    "- Force Plot, multiple predictions\n",
    "- Dependence Plot\n",
    "- Summary Plot\n",
    "- Summary Plot, Bar\n",
    "- Interaction Values\n",
    "- Decision Plots\n",
    "\n",
    "We just did the first type during the lesson. The [Kaggle microcourse](https://www.kaggle.com/dansbecker/advanced-uses-of-shap-values) shows two more. Experiment and see what you can learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "#### Partial Dependence Plots\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability — Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
    "- [Christoph Molnar: Interpretable Machine Learning — Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html) + [animated explanation](https://twitter.com/ChristophMolnar/status/1066398522608635904)\n",
    "- [pdpbox repo](https://github.com/SauceCat/PDPbox) & [docs](https://pdpbox.readthedocs.io/en/latest/)\n",
    "- [Plotly: 3D PDP example](https://plot.ly/scikit-learn/plot-partial-dependence/#partial-dependence-of-house-value-on-median-age-and-average-occupancy)\n",
    "\n",
    "#### Shapley Values\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability — SHAP Values](https://www.kaggle.com/learn/machine-learning-explainability)\n",
    "- [Christoph Molnar: Interpretable Machine Learning — Shapley Values](https://christophm.github.io/interpretable-ml-book/shapley.html)\n",
    "- [SHAP repo](https://github.com/slundberg/shap) & [docs](https://shap.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "#### Feed in as much data as I reasonably can\n",
    "Based off of the last assignment I could probably get away with 600,000-800,000 observations total.  So maybe a 600,000 train, and a 200,000 test split.  Sequential is okay for now, since random and stratified read ins didn't significantly improve things.\n",
    "\n",
    "#### PCA testing\n",
    "I want to get an idea of how much PCA can reduce my dimensionality, and maybe improve my models. This is strictly for my own knowledge.  I suspect that keeping key feature importances may be more useful than reducing dimensionality.  But we'll see.\n",
    "\n",
    "#### Plots\n",
    "1 shaply and 1 partial dependence plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers I've been using\n",
    "def get_Xy(df):\n",
    "    target = 'Response'\n",
    "    return(df.drop(columns = ['Id', target]), df[target])\n",
    "\n",
    "def get_df(itr, size):\n",
    "    '''\n",
    "    itr - a pandas chunk iterator. Advise passing with a chunksize that is a multiple of 10\n",
    "    size - The final size of data frame you want\n",
    "    return a data frame of the passed in size\n",
    "    '''\n",
    "    times = int(size / itr.chunksize)\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(times):\n",
    "        chunks.append(itr.get_chunk())\n",
    "        \n",
    "    return pd.concat(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to stick with numeric dataset for right now.\n",
    "#also hard coding these variables from other notebooks.  Might be nice to do some comparisons\n",
    "baseline = .00385\n",
    "best_perm_xgb = .75\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "folder = '../../DS-Unit-2-Build/bosch-production-line-performance/'\n",
    "\n",
    "num_iter = pd.read_csv(folder + 'train_numeric.csv', iterator = True, chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 970), (200000, 970))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is about the max that pandas can read in without puking later on in our notebook\n",
    "train = get_df(num_iter, size = 500000)\n",
    "val = get_df(num_iter, size = 200000)\n",
    "\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 968), (200000, 968), (500000,), (200000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets go ahead and split these up.\n",
    "X_train, y_train = get_Xy(train)\n",
    "X_val, y_val = get_Xy(val)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "We have to do this a little bit earlier than I planed due to some transformation issues with my PCA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure if this works with the classifier model.  I get the impression it doesn't.  But \n",
    "#lets go ahead and give it a try\n",
    "\n",
    "#I pulled these features from the last assignment, the had high importance.  Would like to\n",
    "#see all of them.\n",
    "features = ['L3_S38_F3960', 'L1_S24_F1846', 'L3_S38_F3956']\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "gb = make_pipeline(\n",
    "    SimpleImputer(strategy = 'median'),\n",
    "    XGBClassifier(objective = 'reg:squarederror', n_jobs = -1)\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runnin into issues because of nans in the validation set so manually imputing\n",
    "\n",
    "X_val = pd.DataFrame(gb.named_steps['simpleimputer'].transform(X_val), columns = X_val.columns)\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    isolated = pdp_isolate(\n",
    "        model = gb,\n",
    "        dataset = X_val,\n",
    "        model_features = X_val.columns,\n",
    "        feature = features[i]\n",
    "    )\n",
    "    \n",
    "    pdp_plot(isolated, feature_name = features[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm doing this really barebones.  Note to future self, look at my lesson notebook for\n",
    "#better notes.\n",
    "\n",
    "row = X_val.iloc[0]\n",
    "\n",
    "gb.predict([row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay thats a legit prediction.  Most things will be 0\n",
    "import shap\n",
    "\n",
    "#since I'm not using a decision tree, I need to use the generic  Kernel Explainer\n",
    "#I just kinda hacked this with documentation.  So if this doesn't make sense to\n",
    "#future me.  Well rtfm\n",
    "explainer = shap.KernelExplainer(gb.named_steps['xgbclassifier'].predict,\n",
    "                                 data = shap.sample(X_train, 10))\n",
    "shap_values = explainer.shap_values(row)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value = explainer.expected_value,\n",
    "    shap_values = shap_values,\n",
    "    features = row\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "My PCA analysis had to be moved to a new notebook.  After adding the plots above, it kept\n",
    "crashing my PCA work.  See my notebook LS_DS_234_assignment_PCA.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
