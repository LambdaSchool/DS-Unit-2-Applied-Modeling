{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2ha9OWxf0jw"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 2*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hTictxWYih7"
   },
   "source": [
    "# Permutation & Boosting\n",
    "\n",
    "- Get **permutation importances** for model interpretation and feature selection\n",
    "- Use xgboost for **gradient boosting**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoxNYFBXYih9"
   },
   "source": [
    "### Default Feature Importances are fast, but Permutation Importances may be more accurate\n",
    "\n",
    "- Permutation Importances\n",
    "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
    "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "- (Default) Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
    "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
    "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
    "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
    "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
    "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy.\n",
    "\n",
    "#### Python libraries for Gradient Boosting\n",
    "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
    "  - Anaconda: already installed\n",
    "  - Google Colab: already installed\n",
    "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
    "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
    "  - Windows: `conda install -c anaconda py-xgboost`\n",
    "  - Google Colab: already installed\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
    "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
    "  - Google Colab: already installed\n",
    "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
    "  - Anaconda: `conda install -c conda-forge catboost`\n",
    "  - Google Colab: `pip install catboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMejJg0w8v76"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
    "\n",
    "Libraries:\n",
    "\n",
    "- category_encoders\n",
    "- [**eli5**](https://eli5.readthedocs.io/en/latest/)\n",
    "- matplotlib\n",
    "- numpy\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- [**xgboost**](https://xgboost.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFQMky3CYih-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "    !pip install eli5\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-TExplb_Slf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
    "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
    "\n",
    "\n",
    "# Split train into train & val\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "                              stratify=train['status_group'], random_state=42)\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
    "    \n",
    "    # Prevent SettingWithCopyWarning\n",
    "    X = X.copy()\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    # Also create a \"missing indicator\" column, because the fact that\n",
    "    # values are missing may be a predictive signal.\n",
    "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
    "                       'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col+'_MISSING'] = X[col].isnull()\n",
    "            \n",
    "    # Drop duplicate columns\n",
    "    duplicates = ['quantity_group', 'payment_type']\n",
    "    X = X.drop(columns=duplicates)\n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "    unusable_variance = ['recorded_by', 'id']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']\n",
    "    X['years_MISSING'] = X['years'].isnull()\n",
    "    \n",
    "    # return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhg8PQKt_jzP"
   },
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector\n",
    "target = 'status_group'\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=target)\n",
    "y_val = val[target]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8lB4z5l_eml"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.81506734006734\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=2000, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HOayKBOYiit"
   },
   "source": [
    "# 3 types of feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4bRhsxENYiiu"
   },
   "source": [
    "## 1. (Default) Feature Importances\n",
    "\n",
    "Fastest, good for first estimates, but be aware:\n",
    "\n",
    "\n",
    "\n",
    ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
    "\n",
    "\n",
    " \n",
    " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNVm6f7mYiiu"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances\n",
    "rf = pipeline.named_steps['randomforestclassifier']\n",
    "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 20\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8HzLcCBYiiv"
   },
   "source": [
    "## 2. Drop-Column Importance\n",
    "\n",
    "The best in theory, but too slow in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQAOlERnYiiw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy without longitude: 0.8097643097643098\n",
      "Validation Accuracy with longitude: 0.8135521885521886\n",
      "Drop-Column Importance for longitude: 0.0037878787878787845\n"
     ]
    }
   ],
   "source": [
    "column  = 'longitude'\n",
    "\n",
    "# Fit without column\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train.drop(columns=column), y_train)\n",
    "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
    "print(f'Validation Accuracy without {column}: {score_without}')\n",
    "\n",
    "# Fit with column\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "score_with = pipeline.score(X_val, y_val)\n",
    "print(f'Validation Accuracy with {column}: {score_with}')\n",
    "\n",
    "# Compare the error with & without column\n",
    "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Vu39wGkYiix"
   },
   "source": [
    "## 3. Permutation Importance\n",
    "\n",
    "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
    "\n",
    "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
    "\n",
    "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
    ">\n",
    "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
    ">\n",
    ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
    ">\n",
    ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYCiEx7zYiiy"
   },
   "source": [
    "### Do-It-Yourself way, for intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TksOf_n2Yiiy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290     insufficient\n",
       "47666    insufficient\n",
       "2538           enough\n",
       "53117          enough\n",
       "51817          enough\n",
       "Name: quantity, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEFORE: Sequence of the feature to be permuted\n",
    "feature = 'quantity'\n",
    "X_val[feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enough          6619\n",
       "insufficient    2976\n",
       "dry             1325\n",
       "seasonal         806\n",
       "unknown          154\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEFORE: Distribution of the feature to be permuted\n",
    "X_val[feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERMUTE!\n",
    "X_val_permuted = X_val.copy()\n",
    "X_val_permuted[feature] = np.random.permutation(X_val[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290              dry\n",
       "47666    insufficient\n",
       "2538           enough\n",
       "53117    insufficient\n",
       "51817    insufficient\n",
       "Name: quantity, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER: Sequence has changed\n",
    "X_val_permuted[feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enough          6619\n",
       "insufficient    2976\n",
       "dry             1325\n",
       "seasonal         806\n",
       "unknown          154\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER: Distribution hasn't changed!\n",
    "X_val_permuted[feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy with quantity: 0.8135521885521886\n",
      "Validation Accuracy with quantity permuted: 0.7121212121212122\n",
      "Permutation Importance: 0.10143097643097643\n"
     ]
    }
   ],
   "source": [
    "# Get the permutation importance\n",
    "# Notice that we don't need to refit the pipeline here!\n",
    "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
    "print(f'Validation Accuracy with {feature}: {score_with}')\n",
    "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
    "print(f'Permutation Importance: {score_with - score_permuted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy with wpt_name: 0.8135521885521886\n",
      "Validation Accuracy with wpt_name permuted: 0.813973063973064\n",
      "Permutation Importance: -0.00042087542087543284\n"
     ]
    }
   ],
   "source": [
    "feature = 'wpt_name'\n",
    "X_val_permuted = X_val.copy()\n",
    "X_val_permuted[feature] = np.random.permutation(X_val[feature])\n",
    "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
    "\n",
    "print(f'Validation Accuracy with {feature}: {score_with}')\n",
    "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
    "print(f'Permutation Importance: {score_with - score_permuted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LYk19SNYii7"
   },
   "source": [
    "### With eli5 library\n",
    "\n",
    "For more documentation on using this library, see:\n",
    "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
    "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
    "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
    "\n",
    "eli5 doesn't work with pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpSemTkFFP8i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_transformed = transformers.fit_transform(X_train)\n",
    "X_val_transformed = transformers.transform(X_val)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(cv='prefit',\n",
       "                      estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=None,\n",
       "                                                       max_features='auto',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=-1,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_state=42,\n",
       "                                                       verbose=0,\n",
       "                                                       warm_start=False),\n",
       "                      n_iter=3, random_state=42, refit=True,\n",
       "                      scoring='accuracy')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "permuter = PermutationImportance(\n",
    "    model,\n",
    "    scoring='accuracy',\n",
    "    n_iter=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X_val_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quantity                     0.100589\n",
       "amount_tsh                   0.010999\n",
       "extraction_type_class        0.009961\n",
       "waterpoint_type              0.009933\n",
       "longitude                    0.009259\n",
       "waterpoint_type_group        0.007323\n",
       "latitude                     0.006902\n",
       "population                   0.006173\n",
       "years                        0.003255\n",
       "public_meeting               0.003227\n",
       "construction_year            0.003114\n",
       "payment                      0.003030\n",
       "subvillage                   0.003002\n",
       "district_code                0.002160\n",
       "extraction_type_group        0.001964\n",
       "day_recorded                 0.001852\n",
       "gps_height                   0.001627\n",
       "source                       0.001375\n",
       "wpt_name                     0.001038\n",
       "ward                         0.000954\n",
       "region_code                  0.000954\n",
       "extraction_type              0.000898\n",
       "longitude_MISSING            0.000842\n",
       "permit                       0.000842\n",
       "funder                       0.000814\n",
       "lga                          0.000758\n",
       "region                       0.000730\n",
       "month_recorded               0.000589\n",
       "years_MISSING                0.000561\n",
       "scheme_name                  0.000533\n",
       "management                   0.000505\n",
       "water_quality                0.000505\n",
       "year_recorded                0.000421\n",
       "num_private                  0.000337\n",
       "population_MISSING           0.000337\n",
       "scheme_management            0.000309\n",
       "source_class                 0.000281\n",
       "construction_year_MISSING    0.000224\n",
       "latitude_MISSING             0.000140\n",
       "gps_height_MISSING           0.000028\n",
       "source_type                 -0.000140\n",
       "installer                   -0.000140\n",
       "management_group            -0.000393\n",
       "quality_group               -0.000505\n",
       "basin                       -0.001515\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X_val.columns.tolist()\n",
    "pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1006\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                quantity\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.75%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0110\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                amount_tsh\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0100\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                extraction_type_class\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0099\n",
       "                \n",
       "                    &plusmn; 0.0015\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                waterpoint_type\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0093\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                longitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0073\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                waterpoint_type_group\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.93%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0069\n",
       "                \n",
       "                    &plusmn; 0.0024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                latitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                population\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0033\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                years\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.20%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                public_meeting\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0031\n",
       "                \n",
       "                    &plusmn; 0.0030\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                construction_year\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                payment\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                subvillage\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                district_code\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                extraction_type_group\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                day_recorded\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.88%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                gps_height\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                source\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                wpt_name\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ward\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                region_code\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                extraction_type\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                longitude_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                permit\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                funder\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0010\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lga\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                region\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0006\n",
       "                \n",
       "                    &plusmn; 0.0018\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                month_recorded\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0006\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                years_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0020\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                scheme_name\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0019\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                management\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                water_quality\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.57%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                year_recorded\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                num_private\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0004\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                population_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                scheme_management\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                source_class\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0002\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                construction_year_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0001\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                latitude_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0008\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                gps_height_MISSING\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0001\n",
       "                \n",
       "                    &plusmn; 0.0003\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                source_type\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0001\n",
       "                \n",
       "                    &plusmn; 0.0021\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                installer\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0004\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                management_group\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0005\n",
       "                \n",
       "                    &plusmn; 0.0014\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                quality_group\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 98.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0015\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                basin\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(\n",
    "    permuter,\n",
    "    top=None, #show permutation importances for top n features, none=all\n",
    "    feature_names=feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q07yW9k-Yii8"
   },
   "source": [
    "### We can use importances for feature selection\n",
    "\n",
    "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZrPFyEMYii9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing features: (47520, 45)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before removing features:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40,), (45,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum_importance = 0\n",
    "mask = (permuter.feature_importances_ >= minimum_importance)\n",
    "X_train.columns[mask].shape, X_train.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amount_tsh', 'funder', 'gps_height', 'longitude', 'latitude',\n",
       "       'wpt_name', 'num_private', 'subvillage', 'region', 'region_code',\n",
       "       'district_code', 'lga', 'ward', 'population', 'public_meeting',\n",
       "       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n",
       "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
       "       'management', 'payment', 'water_quality', 'quantity', 'source',\n",
       "       'source_class', 'waterpoint_type', 'waterpoint_type_group',\n",
       "       'longitude_MISSING', 'latitude_MISSING', 'construction_year_MISSING',\n",
       "       'gps_height_MISSING', 'population_MISSING', 'year_recorded',\n",
       "       'month_recorded', 'day_recorded', 'years', 'years_MISSING'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X_train.columns[mask]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8117003367003367\n"
     ]
    }
   ],
   "source": [
    "X_val = X_val[features]\n",
    "X_train = X_train[features]\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fl67bCR7WY6j"
   },
   "source": [
    "## Use xgboost for gradient boosting\n",
    "\n",
    "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsnJRKjfWYph"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'subvillage',\n",
       "                                      'region', 'lga', 'ward', 'public_meeting',\n",
       "                                      'scheme_management', 'scheme_name',\n",
       "                                      'permit', 'extraction_type',\n",
       "                                      'extraction_type_group',\n",
       "                                      'extraction_type_class', 'management',\n",
       "                                      'payment', 'water_quality', 'quantity',\n",
       "                                      'source', 'source_class',\n",
       "                                      'waterpoint_type',\n",
       "                                      'waterpoin...\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=1000, n_jobs=-1, nthread=None,\n",
       "                               objective='multi:softprob', random_stat=42,\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, seed=None, silent=None,\n",
       "                               subsample=1, verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    XGBClassifier(n_estimators=1000, random_stat=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.786952861952862\n",
      "Validation Accuracy 0.786952861952862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = pipeline.predict(X_val)\n",
    "print('Validation Accuracy', accuracy_score(y_val, y_pred))\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ubb7Ot6OZcK1"
   },
   "source": [
    "### Understand the difference between boosting & bagging\n",
    "\n",
    "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
    "\n",
    "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
    "\n",
    ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
    ">\n",
    ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
    ">\n",
    ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
    ">\n",
    ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
    ">\n",
    ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCjVSlD_XJr2"
   },
   "source": [
    "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
    "\n",
    "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
    "\n",
    "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
    "\n",
    "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
    "\n",
    "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
    "\n",
    "#### XGBoost parameters\n",
    "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
    "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNX3IKftXBFS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 40), (11880, 40), (47520, 40), (11880, 40))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "\n",
    "X_train.shape, X_val.shape, X_train_encoded.shape, X_val_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.250884\tvalidation_1-merror:0.261953\n",
      "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-merror:0.252294\tvalidation_1-merror:0.264057\n",
      "[2]\tvalidation_0-merror:0.251747\tvalidation_1-merror:0.264731\n",
      "[3]\tvalidation_0-merror:0.249895\tvalidation_1-merror:0.262037\n",
      "[4]\tvalidation_0-merror:0.248864\tvalidation_1-merror:0.26069\n",
      "[5]\tvalidation_0-merror:0.24678\tvalidation_1-merror:0.257239\n",
      "[6]\tvalidation_0-merror:0.243687\tvalidation_1-merror:0.255051\n",
      "[7]\tvalidation_0-merror:0.240404\tvalidation_1-merror:0.250421\n",
      "[8]\tvalidation_0-merror:0.2379\tvalidation_1-merror:0.248316\n",
      "[9]\tvalidation_0-merror:0.235816\tvalidation_1-merror:0.247054\n",
      "[10]\tvalidation_0-merror:0.234975\tvalidation_1-merror:0.24596\n",
      "[11]\tvalidation_0-merror:0.23388\tvalidation_1-merror:0.245118\n",
      "[12]\tvalidation_0-merror:0.233228\tvalidation_1-merror:0.245286\n",
      "[13]\tvalidation_0-merror:0.231776\tvalidation_1-merror:0.244529\n",
      "[14]\tvalidation_0-merror:0.232008\tvalidation_1-merror:0.244529\n",
      "[15]\tvalidation_0-merror:0.230535\tvalidation_1-merror:0.243855\n",
      "[16]\tvalidation_0-merror:0.229104\tvalidation_1-merror:0.241835\n",
      "[17]\tvalidation_0-merror:0.228325\tvalidation_1-merror:0.241919\n",
      "[18]\tvalidation_0-merror:0.227125\tvalidation_1-merror:0.239899\n",
      "[19]\tvalidation_0-merror:0.226515\tvalidation_1-merror:0.238973\n",
      "[20]\tvalidation_0-merror:0.225526\tvalidation_1-merror:0.238973\n",
      "[21]\tvalidation_0-merror:0.224495\tvalidation_1-merror:0.237626\n",
      "[22]\tvalidation_0-merror:0.22298\tvalidation_1-merror:0.23569\n",
      "[23]\tvalidation_0-merror:0.221843\tvalidation_1-merror:0.235522\n",
      "[24]\tvalidation_0-merror:0.221044\tvalidation_1-merror:0.235774\n",
      "[25]\tvalidation_0-merror:0.220244\tvalidation_1-merror:0.235269\n",
      "[26]\tvalidation_0-merror:0.218939\tvalidation_1-merror:0.234428\n",
      "[27]\tvalidation_0-merror:0.217151\tvalidation_1-merror:0.232492\n",
      "[28]\tvalidation_0-merror:0.215109\tvalidation_1-merror:0.230892\n",
      "[29]\tvalidation_0-merror:0.213636\tvalidation_1-merror:0.229882\n",
      "[30]\tvalidation_0-merror:0.212563\tvalidation_1-merror:0.228283\n",
      "[31]\tvalidation_0-merror:0.211132\tvalidation_1-merror:0.227357\n",
      "[32]\tvalidation_0-merror:0.209996\tvalidation_1-merror:0.227104\n",
      "[33]\tvalidation_0-merror:0.209049\tvalidation_1-merror:0.226683\n",
      "[34]\tvalidation_0-merror:0.207765\tvalidation_1-merror:0.226515\n",
      "[35]\tvalidation_0-merror:0.206734\tvalidation_1-merror:0.226347\n",
      "[36]\tvalidation_0-merror:0.205724\tvalidation_1-merror:0.225589\n",
      "[37]\tvalidation_0-merror:0.204882\tvalidation_1-merror:0.225168\n",
      "[38]\tvalidation_0-merror:0.203998\tvalidation_1-merror:0.224158\n",
      "[39]\tvalidation_0-merror:0.20221\tvalidation_1-merror:0.222475\n",
      "[40]\tvalidation_0-merror:0.200968\tvalidation_1-merror:0.221633\n",
      "[41]\tvalidation_0-merror:0.199474\tvalidation_1-merror:0.220539\n",
      "[42]\tvalidation_0-merror:0.198695\tvalidation_1-merror:0.220707\n",
      "[43]\tvalidation_0-merror:0.197769\tvalidation_1-merror:0.220286\n",
      "[44]\tvalidation_0-merror:0.196275\tvalidation_1-merror:0.219613\n",
      "[45]\tvalidation_0-merror:0.195707\tvalidation_1-merror:0.219108\n",
      "[46]\tvalidation_0-merror:0.194739\tvalidation_1-merror:0.218266\n",
      "[47]\tvalidation_0-merror:0.194192\tvalidation_1-merror:0.217172\n",
      "[48]\tvalidation_0-merror:0.193287\tvalidation_1-merror:0.217172\n",
      "[49]\tvalidation_0-merror:0.192466\tvalidation_1-merror:0.216667\n",
      "[50]\tvalidation_0-merror:0.19194\tvalidation_1-merror:0.216835\n",
      "[51]\tvalidation_0-merror:0.191225\tvalidation_1-merror:0.216077\n",
      "[52]\tvalidation_0-merror:0.190278\tvalidation_1-merror:0.215152\n",
      "[53]\tvalidation_0-merror:0.18971\tvalidation_1-merror:0.21431\n",
      "[54]\tvalidation_0-merror:0.189205\tvalidation_1-merror:0.214478\n",
      "[55]\tvalidation_0-merror:0.188279\tvalidation_1-merror:0.212879\n",
      "[56]\tvalidation_0-merror:0.187184\tvalidation_1-merror:0.212795\n",
      "[57]\tvalidation_0-merror:0.186385\tvalidation_1-merror:0.211953\n",
      "[58]\tvalidation_0-merror:0.185501\tvalidation_1-merror:0.211448\n",
      "[59]\tvalidation_0-merror:0.18487\tvalidation_1-merror:0.211448\n",
      "[60]\tvalidation_0-merror:0.184364\tvalidation_1-merror:0.211364\n",
      "[61]\tvalidation_0-merror:0.183586\tvalidation_1-merror:0.210859\n",
      "[62]\tvalidation_0-merror:0.183123\tvalidation_1-merror:0.21069\n",
      "[63]\tvalidation_0-merror:0.182302\tvalidation_1-merror:0.210354\n",
      "[64]\tvalidation_0-merror:0.182029\tvalidation_1-merror:0.210522\n",
      "[65]\tvalidation_0-merror:0.181839\tvalidation_1-merror:0.209512\n",
      "[66]\tvalidation_0-merror:0.181145\tvalidation_1-merror:0.209259\n",
      "[67]\tvalidation_0-merror:0.180745\tvalidation_1-merror:0.209259\n",
      "[68]\tvalidation_0-merror:0.180156\tvalidation_1-merror:0.208923\n",
      "[69]\tvalidation_0-merror:0.179735\tvalidation_1-merror:0.208923\n",
      "[70]\tvalidation_0-merror:0.179398\tvalidation_1-merror:0.208754\n",
      "[71]\tvalidation_0-merror:0.178767\tvalidation_1-merror:0.208923\n",
      "[72]\tvalidation_0-merror:0.17822\tvalidation_1-merror:0.208923\n",
      "[73]\tvalidation_0-merror:0.177946\tvalidation_1-merror:0.209091\n",
      "[74]\tvalidation_0-merror:0.176684\tvalidation_1-merror:0.208502\n",
      "[75]\tvalidation_0-merror:0.176157\tvalidation_1-merror:0.207997\n",
      "[76]\tvalidation_0-merror:0.175231\tvalidation_1-merror:0.207576\n",
      "[77]\tvalidation_0-merror:0.174958\tvalidation_1-merror:0.208165\n",
      "[78]\tvalidation_0-merror:0.174579\tvalidation_1-merror:0.206313\n",
      "[79]\tvalidation_0-merror:0.17399\tvalidation_1-merror:0.206145\n",
      "[80]\tvalidation_0-merror:0.173695\tvalidation_1-merror:0.205556\n",
      "[81]\tvalidation_0-merror:0.17338\tvalidation_1-merror:0.205135\n",
      "[82]\tvalidation_0-merror:0.173211\tvalidation_1-merror:0.205219\n",
      "[83]\tvalidation_0-merror:0.172727\tvalidation_1-merror:0.204798\n",
      "[84]\tvalidation_0-merror:0.172306\tvalidation_1-merror:0.204798\n",
      "[85]\tvalidation_0-merror:0.171928\tvalidation_1-merror:0.204714\n",
      "[86]\tvalidation_0-merror:0.171907\tvalidation_1-merror:0.204545\n",
      "[87]\tvalidation_0-merror:0.17138\tvalidation_1-merror:0.204209\n",
      "[88]\tvalidation_0-merror:0.170581\tvalidation_1-merror:0.204545\n",
      "[89]\tvalidation_0-merror:0.17037\tvalidation_1-merror:0.204293\n",
      "[90]\tvalidation_0-merror:0.169634\tvalidation_1-merror:0.204461\n",
      "[91]\tvalidation_0-merror:0.169423\tvalidation_1-merror:0.204545\n",
      "[92]\tvalidation_0-merror:0.169213\tvalidation_1-merror:0.204377\n",
      "[93]\tvalidation_0-merror:0.168624\tvalidation_1-merror:0.204545\n",
      "[94]\tvalidation_0-merror:0.168119\tvalidation_1-merror:0.204377\n",
      "[95]\tvalidation_0-merror:0.167908\tvalidation_1-merror:0.204377\n",
      "[96]\tvalidation_0-merror:0.167551\tvalidation_1-merror:0.204545\n",
      "[97]\tvalidation_0-merror:0.167424\tvalidation_1-merror:0.204461\n",
      "[98]\tvalidation_0-merror:0.167109\tvalidation_1-merror:0.204377\n",
      "[99]\tvalidation_0-merror:0.166561\tvalidation_1-merror:0.204293\n",
      "[100]\tvalidation_0-merror:0.166246\tvalidation_1-merror:0.203788\n",
      "[101]\tvalidation_0-merror:0.166077\tvalidation_1-merror:0.203367\n",
      "[102]\tvalidation_0-merror:0.16553\tvalidation_1-merror:0.203704\n",
      "[103]\tvalidation_0-merror:0.165236\tvalidation_1-merror:0.20362\n",
      "[104]\tvalidation_0-merror:0.164857\tvalidation_1-merror:0.20362\n",
      "[105]\tvalidation_0-merror:0.164583\tvalidation_1-merror:0.203704\n",
      "[106]\tvalidation_0-merror:0.164394\tvalidation_1-merror:0.203114\n",
      "[107]\tvalidation_0-merror:0.164141\tvalidation_1-merror:0.203199\n",
      "[108]\tvalidation_0-merror:0.163784\tvalidation_1-merror:0.203451\n",
      "[109]\tvalidation_0-merror:0.163237\tvalidation_1-merror:0.203367\n",
      "[110]\tvalidation_0-merror:0.163047\tvalidation_1-merror:0.203283\n",
      "[111]\tvalidation_0-merror:0.162584\tvalidation_1-merror:0.202778\n",
      "[112]\tvalidation_0-merror:0.162353\tvalidation_1-merror:0.202694\n",
      "[113]\tvalidation_0-merror:0.162163\tvalidation_1-merror:0.203114\n",
      "[114]\tvalidation_0-merror:0.161848\tvalidation_1-merror:0.202778\n",
      "[115]\tvalidation_0-merror:0.161616\tvalidation_1-merror:0.202609\n",
      "[116]\tvalidation_0-merror:0.161258\tvalidation_1-merror:0.202525\n",
      "[117]\tvalidation_0-merror:0.161027\tvalidation_1-merror:0.20303\n",
      "[118]\tvalidation_0-merror:0.160354\tvalidation_1-merror:0.203283\n",
      "[119]\tvalidation_0-merror:0.159891\tvalidation_1-merror:0.202946\n",
      "[120]\tvalidation_0-merror:0.159638\tvalidation_1-merror:0.202946\n",
      "[121]\tvalidation_0-merror:0.159322\tvalidation_1-merror:0.202778\n",
      "[122]\tvalidation_0-merror:0.159049\tvalidation_1-merror:0.202946\n",
      "[123]\tvalidation_0-merror:0.158228\tvalidation_1-merror:0.20202\n",
      "[124]\tvalidation_0-merror:0.158228\tvalidation_1-merror:0.201852\n",
      "[125]\tvalidation_0-merror:0.157639\tvalidation_1-merror:0.20202\n",
      "[126]\tvalidation_0-merror:0.157302\tvalidation_1-merror:0.20202\n",
      "[127]\tvalidation_0-merror:0.156692\tvalidation_1-merror:0.201431\n",
      "[128]\tvalidation_0-merror:0.156629\tvalidation_1-merror:0.201178\n",
      "[129]\tvalidation_0-merror:0.156313\tvalidation_1-merror:0.201347\n",
      "[130]\tvalidation_0-merror:0.156124\tvalidation_1-merror:0.200926\n",
      "[131]\tvalidation_0-merror:0.155997\tvalidation_1-merror:0.201263\n",
      "[132]\tvalidation_0-merror:0.155829\tvalidation_1-merror:0.201094\n",
      "[133]\tvalidation_0-merror:0.155513\tvalidation_1-merror:0.200589\n",
      "[134]\tvalidation_0-merror:0.154651\tvalidation_1-merror:0.200673\n",
      "[135]\tvalidation_0-merror:0.154461\tvalidation_1-merror:0.200673\n",
      "[136]\tvalidation_0-merror:0.154209\tvalidation_1-merror:0.200589\n",
      "[137]\tvalidation_0-merror:0.153746\tvalidation_1-merror:0.200337\n",
      "[138]\tvalidation_0-merror:0.153367\tvalidation_1-merror:0.2\n",
      "[139]\tvalidation_0-merror:0.152883\tvalidation_1-merror:0.199832\n",
      "[140]\tvalidation_0-merror:0.152462\tvalidation_1-merror:0.2\n",
      "[141]\tvalidation_0-merror:0.152189\tvalidation_1-merror:0.200168\n",
      "[142]\tvalidation_0-merror:0.151915\tvalidation_1-merror:0.200337\n",
      "[143]\tvalidation_0-merror:0.15162\tvalidation_1-merror:0.200168\n",
      "[144]\tvalidation_0-merror:0.151494\tvalidation_1-merror:0.199916\n",
      "[145]\tvalidation_0-merror:0.151115\tvalidation_1-merror:0.2\n",
      "[146]\tvalidation_0-merror:0.150758\tvalidation_1-merror:0.199663\n",
      "[147]\tvalidation_0-merror:0.15061\tvalidation_1-merror:0.199411\n",
      "[148]\tvalidation_0-merror:0.149874\tvalidation_1-merror:0.199579\n",
      "[149]\tvalidation_0-merror:0.149369\tvalidation_1-merror:0.199327\n",
      "[150]\tvalidation_0-merror:0.149158\tvalidation_1-merror:0.199158\n",
      "[151]\tvalidation_0-merror:0.148843\tvalidation_1-merror:0.199663\n",
      "[152]\tvalidation_0-merror:0.148506\tvalidation_1-merror:0.199832\n",
      "[153]\tvalidation_0-merror:0.14838\tvalidation_1-merror:0.2\n",
      "[154]\tvalidation_0-merror:0.148001\tvalidation_1-merror:0.199242\n",
      "[155]\tvalidation_0-merror:0.14779\tvalidation_1-merror:0.199327\n",
      "[156]\tvalidation_0-merror:0.147517\tvalidation_1-merror:0.199579\n",
      "[157]\tvalidation_0-merror:0.147559\tvalidation_1-merror:0.199747\n",
      "[158]\tvalidation_0-merror:0.147054\tvalidation_1-merror:0.199663\n",
      "[159]\tvalidation_0-merror:0.146949\tvalidation_1-merror:0.199832\n",
      "[160]\tvalidation_0-merror:0.146591\tvalidation_1-merror:0.199411\n",
      "[161]\tvalidation_0-merror:0.146444\tvalidation_1-merror:0.199579\n",
      "[162]\tvalidation_0-merror:0.146233\tvalidation_1-merror:0.199411\n",
      "[163]\tvalidation_0-merror:0.146065\tvalidation_1-merror:0.198906\n",
      "[164]\tvalidation_0-merror:0.145644\tvalidation_1-merror:0.198569\n",
      "[165]\tvalidation_0-merror:0.145118\tvalidation_1-merror:0.198148\n",
      "[166]\tvalidation_0-merror:0.144592\tvalidation_1-merror:0.198401\n",
      "[167]\tvalidation_0-merror:0.144129\tvalidation_1-merror:0.198316\n",
      "[168]\tvalidation_0-merror:0.143813\tvalidation_1-merror:0.198232\n",
      "[169]\tvalidation_0-merror:0.14354\tvalidation_1-merror:0.197896\n",
      "[170]\tvalidation_0-merror:0.143119\tvalidation_1-merror:0.197727\n",
      "[171]\tvalidation_0-merror:0.142761\tvalidation_1-merror:0.19798\n",
      "[172]\tvalidation_0-merror:0.142635\tvalidation_1-merror:0.198232\n",
      "[173]\tvalidation_0-merror:0.142277\tvalidation_1-merror:0.198401\n",
      "[174]\tvalidation_0-merror:0.142045\tvalidation_1-merror:0.198148\n",
      "[175]\tvalidation_0-merror:0.141582\tvalidation_1-merror:0.198148\n",
      "[176]\tvalidation_0-merror:0.141246\tvalidation_1-merror:0.198064\n",
      "[177]\tvalidation_0-merror:0.140783\tvalidation_1-merror:0.198401\n",
      "[178]\tvalidation_0-merror:0.14053\tvalidation_1-merror:0.198148\n",
      "[179]\tvalidation_0-merror:0.140109\tvalidation_1-merror:0.198064\n",
      "[180]\tvalidation_0-merror:0.139752\tvalidation_1-merror:0.198064\n",
      "[181]\tvalidation_0-merror:0.139773\tvalidation_1-merror:0.197811\n",
      "[182]\tvalidation_0-merror:0.139436\tvalidation_1-merror:0.197559\n",
      "[183]\tvalidation_0-merror:0.139247\tvalidation_1-merror:0.197475\n",
      "[184]\tvalidation_0-merror:0.138889\tvalidation_1-merror:0.197306\n",
      "[185]\tvalidation_0-merror:0.138636\tvalidation_1-merror:0.197222\n",
      "[186]\tvalidation_0-merror:0.138173\tvalidation_1-merror:0.196886\n",
      "[187]\tvalidation_0-merror:0.137921\tvalidation_1-merror:0.196886\n",
      "[188]\tvalidation_0-merror:0.137858\tvalidation_1-merror:0.19697\n",
      "[189]\tvalidation_0-merror:0.137521\tvalidation_1-merror:0.197054\n",
      "[190]\tvalidation_0-merror:0.137395\tvalidation_1-merror:0.19697\n",
      "[191]\tvalidation_0-merror:0.137205\tvalidation_1-merror:0.197138\n",
      "[192]\tvalidation_0-merror:0.136953\tvalidation_1-merror:0.197054\n",
      "[193]\tvalidation_0-merror:0.136532\tvalidation_1-merror:0.19697\n",
      "[194]\tvalidation_0-merror:0.136574\tvalidation_1-merror:0.197138\n",
      "[195]\tvalidation_0-merror:0.136322\tvalidation_1-merror:0.197138\n",
      "[196]\tvalidation_0-merror:0.136153\tvalidation_1-merror:0.19697\n",
      "[197]\tvalidation_0-merror:0.135795\tvalidation_1-merror:0.196717\n",
      "[198]\tvalidation_0-merror:0.135396\tvalidation_1-merror:0.196465\n",
      "[199]\tvalidation_0-merror:0.13529\tvalidation_1-merror:0.196801\n",
      "[200]\tvalidation_0-merror:0.13508\tvalidation_1-merror:0.196801\n",
      "[201]\tvalidation_0-merror:0.13487\tvalidation_1-merror:0.195875\n",
      "[202]\tvalidation_0-merror:0.134301\tvalidation_1-merror:0.195623\n",
      "[203]\tvalidation_0-merror:0.134133\tvalidation_1-merror:0.195791\n",
      "[204]\tvalidation_0-merror:0.133965\tvalidation_1-merror:0.195875\n",
      "[205]\tvalidation_0-merror:0.133691\tvalidation_1-merror:0.19596\n",
      "[206]\tvalidation_0-merror:0.133333\tvalidation_1-merror:0.195875\n",
      "[207]\tvalidation_0-merror:0.132849\tvalidation_1-merror:0.196296\n",
      "[208]\tvalidation_0-merror:0.132723\tvalidation_1-merror:0.196128\n",
      "[209]\tvalidation_0-merror:0.132555\tvalidation_1-merror:0.195875\n",
      "[210]\tvalidation_0-merror:0.132323\tvalidation_1-merror:0.195875\n",
      "[211]\tvalidation_0-merror:0.132176\tvalidation_1-merror:0.195875\n",
      "[212]\tvalidation_0-merror:0.13205\tvalidation_1-merror:0.195791\n",
      "[213]\tvalidation_0-merror:0.131797\tvalidation_1-merror:0.19596\n",
      "[214]\tvalidation_0-merror:0.131503\tvalidation_1-merror:0.196212\n",
      "[215]\tvalidation_0-merror:0.131418\tvalidation_1-merror:0.19596\n",
      "[216]\tvalidation_0-merror:0.131082\tvalidation_1-merror:0.195707\n",
      "[217]\tvalidation_0-merror:0.130598\tvalidation_1-merror:0.195455\n",
      "[218]\tvalidation_0-merror:0.130282\tvalidation_1-merror:0.19537\n",
      "[219]\tvalidation_0-merror:0.130261\tvalidation_1-merror:0.195455\n",
      "[220]\tvalidation_0-merror:0.129798\tvalidation_1-merror:0.196128\n",
      "[221]\tvalidation_0-merror:0.129672\tvalidation_1-merror:0.196296\n",
      "[222]\tvalidation_0-merror:0.129545\tvalidation_1-merror:0.196128\n",
      "[223]\tvalidation_0-merror:0.129188\tvalidation_1-merror:0.196212\n",
      "[224]\tvalidation_0-merror:0.128809\tvalidation_1-merror:0.19596\n",
      "[225]\tvalidation_0-merror:0.128598\tvalidation_1-merror:0.195623\n",
      "[226]\tvalidation_0-merror:0.128598\tvalidation_1-merror:0.19596\n",
      "[227]\tvalidation_0-merror:0.128346\tvalidation_1-merror:0.195539\n",
      "[228]\tvalidation_0-merror:0.12782\tvalidation_1-merror:0.195539\n",
      "[229]\tvalidation_0-merror:0.12742\tvalidation_1-merror:0.195286\n",
      "[230]\tvalidation_0-merror:0.127273\tvalidation_1-merror:0.195286\n",
      "[231]\tvalidation_0-merror:0.127104\tvalidation_1-merror:0.194865\n",
      "[232]\tvalidation_0-merror:0.126747\tvalidation_1-merror:0.195118\n",
      "[233]\tvalidation_0-merror:0.126515\tvalidation_1-merror:0.194949\n",
      "[234]\tvalidation_0-merror:0.125884\tvalidation_1-merror:0.195202\n",
      "[235]\tvalidation_0-merror:0.125274\tvalidation_1-merror:0.195455\n",
      "[236]\tvalidation_0-merror:0.125253\tvalidation_1-merror:0.195539\n",
      "[237]\tvalidation_0-merror:0.124979\tvalidation_1-merror:0.195118\n",
      "[238]\tvalidation_0-merror:0.1246\tvalidation_1-merror:0.195202\n",
      "[239]\tvalidation_0-merror:0.124474\tvalidation_1-merror:0.19537\n",
      "[240]\tvalidation_0-merror:0.124116\tvalidation_1-merror:0.195118\n",
      "[241]\tvalidation_0-merror:0.123927\tvalidation_1-merror:0.195202\n",
      "[242]\tvalidation_0-merror:0.123569\tvalidation_1-merror:0.195455\n",
      "[243]\tvalidation_0-merror:0.123274\tvalidation_1-merror:0.195286\n",
      "[244]\tvalidation_0-merror:0.123106\tvalidation_1-merror:0.195118\n",
      "[245]\tvalidation_0-merror:0.122875\tvalidation_1-merror:0.195286\n",
      "[246]\tvalidation_0-merror:0.122559\tvalidation_1-merror:0.195202\n",
      "[247]\tvalidation_0-merror:0.122201\tvalidation_1-merror:0.195455\n",
      "[248]\tvalidation_0-merror:0.121949\tvalidation_1-merror:0.195539\n",
      "[249]\tvalidation_0-merror:0.121886\tvalidation_1-merror:0.195455\n",
      "[250]\tvalidation_0-merror:0.121549\tvalidation_1-merror:0.195539\n",
      "[251]\tvalidation_0-merror:0.121149\tvalidation_1-merror:0.194865\n",
      "[252]\tvalidation_0-merror:0.121002\tvalidation_1-merror:0.194697\n",
      "[253]\tvalidation_0-merror:0.120749\tvalidation_1-merror:0.194781\n",
      "[254]\tvalidation_0-merror:0.120518\tvalidation_1-merror:0.194697\n",
      "[255]\tvalidation_0-merror:0.120118\tvalidation_1-merror:0.194865\n",
      "[256]\tvalidation_0-merror:0.119844\tvalidation_1-merror:0.194781\n",
      "[257]\tvalidation_0-merror:0.119802\tvalidation_1-merror:0.194865\n",
      "[258]\tvalidation_0-merror:0.119423\tvalidation_1-merror:0.194781\n",
      "[259]\tvalidation_0-merror:0.119297\tvalidation_1-merror:0.194865\n",
      "[260]\tvalidation_0-merror:0.119108\tvalidation_1-merror:0.195202\n",
      "[261]\tvalidation_0-merror:0.118708\tvalidation_1-merror:0.194949\n",
      "[262]\tvalidation_0-merror:0.118519\tvalidation_1-merror:0.194276\n",
      "[263]\tvalidation_0-merror:0.118434\tvalidation_1-merror:0.194529\n",
      "[264]\tvalidation_0-merror:0.117971\tvalidation_1-merror:0.194192\n",
      "[265]\tvalidation_0-merror:0.117551\tvalidation_1-merror:0.194529\n",
      "[266]\tvalidation_0-merror:0.117424\tvalidation_1-merror:0.194697\n",
      "[267]\tvalidation_0-merror:0.117151\tvalidation_1-merror:0.194865\n",
      "[268]\tvalidation_0-merror:0.116793\tvalidation_1-merror:0.194529\n",
      "[269]\tvalidation_0-merror:0.116625\tvalidation_1-merror:0.194276\n",
      "[270]\tvalidation_0-merror:0.116309\tvalidation_1-merror:0.194276\n",
      "[271]\tvalidation_0-merror:0.11612\tvalidation_1-merror:0.19436\n",
      "[272]\tvalidation_0-merror:0.115825\tvalidation_1-merror:0.193855\n",
      "[273]\tvalidation_0-merror:0.115741\tvalidation_1-merror:0.193855\n",
      "[274]\tvalidation_0-merror:0.115067\tvalidation_1-merror:0.193939\n",
      "[275]\tvalidation_0-merror:0.114625\tvalidation_1-merror:0.193771\n",
      "[276]\tvalidation_0-merror:0.114457\tvalidation_1-merror:0.194108\n",
      "[277]\tvalidation_0-merror:0.114226\tvalidation_1-merror:0.194276\n",
      "[278]\tvalidation_0-merror:0.113973\tvalidation_1-merror:0.194024\n",
      "[279]\tvalidation_0-merror:0.113763\tvalidation_1-merror:0.193434\n",
      "[280]\tvalidation_0-merror:0.11351\tvalidation_1-merror:0.193687\n",
      "[281]\tvalidation_0-merror:0.113363\tvalidation_1-merror:0.193687\n",
      "[282]\tvalidation_0-merror:0.113152\tvalidation_1-merror:0.193855\n",
      "[283]\tvalidation_0-merror:0.112837\tvalidation_1-merror:0.194276\n",
      "[284]\tvalidation_0-merror:0.112374\tvalidation_1-merror:0.194276\n",
      "[285]\tvalidation_0-merror:0.112247\tvalidation_1-merror:0.19436\n",
      "[286]\tvalidation_0-merror:0.112079\tvalidation_1-merror:0.194192\n",
      "[287]\tvalidation_0-merror:0.111679\tvalidation_1-merror:0.194024\n",
      "[288]\tvalidation_0-merror:0.111448\tvalidation_1-merror:0.194276\n",
      "[289]\tvalidation_0-merror:0.111364\tvalidation_1-merror:0.193434\n",
      "[290]\tvalidation_0-merror:0.111069\tvalidation_1-merror:0.19335\n",
      "[291]\tvalidation_0-merror:0.111069\tvalidation_1-merror:0.192929\n",
      "[292]\tvalidation_0-merror:0.110817\tvalidation_1-merror:0.193098\n",
      "[293]\tvalidation_0-merror:0.110543\tvalidation_1-merror:0.193013\n",
      "[294]\tvalidation_0-merror:0.11048\tvalidation_1-merror:0.193182\n",
      "[295]\tvalidation_0-merror:0.110438\tvalidation_1-merror:0.193434\n",
      "[296]\tvalidation_0-merror:0.110143\tvalidation_1-merror:0.193182\n",
      "[297]\tvalidation_0-merror:0.109743\tvalidation_1-merror:0.193182\n",
      "[298]\tvalidation_0-merror:0.109449\tvalidation_1-merror:0.193266\n",
      "[299]\tvalidation_0-merror:0.108986\tvalidation_1-merror:0.193013\n",
      "[300]\tvalidation_0-merror:0.108586\tvalidation_1-merror:0.193098\n",
      "[301]\tvalidation_0-merror:0.108333\tvalidation_1-merror:0.193098\n",
      "[302]\tvalidation_0-merror:0.10806\tvalidation_1-merror:0.193098\n",
      "[303]\tvalidation_0-merror:0.107807\tvalidation_1-merror:0.193182\n",
      "[304]\tvalidation_0-merror:0.107723\tvalidation_1-merror:0.193519\n",
      "[305]\tvalidation_0-merror:0.107449\tvalidation_1-merror:0.193434\n",
      "[306]\tvalidation_0-merror:0.107134\tvalidation_1-merror:0.193266\n",
      "[307]\tvalidation_0-merror:0.106923\tvalidation_1-merror:0.193434\n",
      "[308]\tvalidation_0-merror:0.106566\tvalidation_1-merror:0.193266\n",
      "[309]\tvalidation_0-merror:0.106334\tvalidation_1-merror:0.193434\n",
      "[310]\tvalidation_0-merror:0.106166\tvalidation_1-merror:0.193603\n",
      "[311]\tvalidation_0-merror:0.105892\tvalidation_1-merror:0.193434\n",
      "[312]\tvalidation_0-merror:0.105766\tvalidation_1-merror:0.193519\n",
      "[313]\tvalidation_0-merror:0.105682\tvalidation_1-merror:0.193603\n",
      "[314]\tvalidation_0-merror:0.105556\tvalidation_1-merror:0.193434\n",
      "[315]\tvalidation_0-merror:0.105324\tvalidation_1-merror:0.193434\n",
      "[316]\tvalidation_0-merror:0.105198\tvalidation_1-merror:0.193687\n",
      "[317]\tvalidation_0-merror:0.104966\tvalidation_1-merror:0.193939\n",
      "[318]\tvalidation_0-merror:0.104798\tvalidation_1-merror:0.193771\n",
      "[319]\tvalidation_0-merror:0.104419\tvalidation_1-merror:0.193519\n",
      "[320]\tvalidation_0-merror:0.104356\tvalidation_1-merror:0.193687\n",
      "[321]\tvalidation_0-merror:0.104104\tvalidation_1-merror:0.193603\n",
      "[322]\tvalidation_0-merror:0.103535\tvalidation_1-merror:0.193434\n",
      "[323]\tvalidation_0-merror:0.103409\tvalidation_1-merror:0.193434\n",
      "[324]\tvalidation_0-merror:0.10322\tvalidation_1-merror:0.193603\n",
      "[325]\tvalidation_0-merror:0.103136\tvalidation_1-merror:0.193519\n",
      "[326]\tvalidation_0-merror:0.102715\tvalidation_1-merror:0.193519\n",
      "[327]\tvalidation_0-merror:0.102357\tvalidation_1-merror:0.193771\n",
      "[328]\tvalidation_0-merror:0.102125\tvalidation_1-merror:0.193603\n",
      "[329]\tvalidation_0-merror:0.101768\tvalidation_1-merror:0.193855\n",
      "[330]\tvalidation_0-merror:0.101599\tvalidation_1-merror:0.193939\n",
      "[331]\tvalidation_0-merror:0.101368\tvalidation_1-merror:0.193603\n",
      "[332]\tvalidation_0-merror:0.101263\tvalidation_1-merror:0.193855\n",
      "[333]\tvalidation_0-merror:0.10101\tvalidation_1-merror:0.19335\n",
      "[334]\tvalidation_0-merror:0.100715\tvalidation_1-merror:0.19335\n",
      "[335]\tvalidation_0-merror:0.100758\tvalidation_1-merror:0.193519\n",
      "[336]\tvalidation_0-merror:0.100505\tvalidation_1-merror:0.193603\n",
      "[337]\tvalidation_0-merror:0.100295\tvalidation_1-merror:0.19335\n",
      "[338]\tvalidation_0-merror:0.100231\tvalidation_1-merror:0.193434\n",
      "[339]\tvalidation_0-merror:0.099979\tvalidation_1-merror:0.193771\n",
      "[340]\tvalidation_0-merror:0.099705\tvalidation_1-merror:0.193771\n",
      "[341]\tvalidation_0-merror:0.099579\tvalidation_1-merror:0.193855\n",
      "Stopping. Best iteration:\n",
      "[291]\tvalidation_0-merror:0.111069\tvalidation_1-merror:0.192929\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train_encoded, y_train), (X_val_encoded, y_val)]\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=1000, # This mean <=1000 trees, depends on early stopping\n",
    "    max_depth=7,       # Try deeper trees because of high cardinality categoricals\n",
    "    learning_rate=0.1, # Try higher learning rate\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train_encoded, y_train, eval_set=eval_set, eval_metric='merror', early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_Booster',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_estimator_type',\n",
       " '_features_count',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_le',\n",
       " 'apply',\n",
       " 'base_score',\n",
       " 'best_iteration',\n",
       " 'best_ntree_limit',\n",
       " 'best_score',\n",
       " 'booster',\n",
       " 'classes_',\n",
       " 'coef_',\n",
       " 'colsample_bylevel',\n",
       " 'colsample_bynode',\n",
       " 'colsample_bytree',\n",
       " 'evals_result',\n",
       " 'evals_result_',\n",
       " 'feature_importances_',\n",
       " 'fit',\n",
       " 'gamma',\n",
       " 'get_booster',\n",
       " 'get_num_boosting_rounds',\n",
       " 'get_params',\n",
       " 'get_xgb_params',\n",
       " 'importance_type',\n",
       " 'intercept_',\n",
       " 'kwargs',\n",
       " 'learning_rate',\n",
       " 'load_model',\n",
       " 'max_delta_step',\n",
       " 'max_depth',\n",
       " 'min_child_weight',\n",
       " 'missing',\n",
       " 'n_classes_',\n",
       " 'n_estimators',\n",
       " 'n_jobs',\n",
       " 'nthread',\n",
       " 'objective',\n",
       " 'predict',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'reg_alpha',\n",
       " 'reg_lambda',\n",
       " 'save_model',\n",
       " 'scale_pos_weight',\n",
       " 'score',\n",
       " 'seed',\n",
       " 'set_params',\n",
       " 'silent',\n",
       " 'subsample',\n",
       " 'verbosity']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'n_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-00a1ce909a3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'n_classes'"
     ]
    }
   ],
   "source": [
    "model.n_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_0': {'merror': [0.250884,\n",
       "   0.252294,\n",
       "   0.251747,\n",
       "   0.249895,\n",
       "   0.248864,\n",
       "   0.24678,\n",
       "   0.243687,\n",
       "   0.240404,\n",
       "   0.2379,\n",
       "   0.235816,\n",
       "   0.234975,\n",
       "   0.23388,\n",
       "   0.233228,\n",
       "   0.231776,\n",
       "   0.232008,\n",
       "   0.230535,\n",
       "   0.229104,\n",
       "   0.228325,\n",
       "   0.227125,\n",
       "   0.226515,\n",
       "   0.225526,\n",
       "   0.224495,\n",
       "   0.22298,\n",
       "   0.221843,\n",
       "   0.221044,\n",
       "   0.220244,\n",
       "   0.218939,\n",
       "   0.217151,\n",
       "   0.215109,\n",
       "   0.213636,\n",
       "   0.212563,\n",
       "   0.211132,\n",
       "   0.209996,\n",
       "   0.209049,\n",
       "   0.207765,\n",
       "   0.206734,\n",
       "   0.205724,\n",
       "   0.204882,\n",
       "   0.203998,\n",
       "   0.20221,\n",
       "   0.200968,\n",
       "   0.199474,\n",
       "   0.198695,\n",
       "   0.197769,\n",
       "   0.196275,\n",
       "   0.195707,\n",
       "   0.194739,\n",
       "   0.194192,\n",
       "   0.193287,\n",
       "   0.192466,\n",
       "   0.19194,\n",
       "   0.191225,\n",
       "   0.190278,\n",
       "   0.18971,\n",
       "   0.189205,\n",
       "   0.188279,\n",
       "   0.187184,\n",
       "   0.186385,\n",
       "   0.185501,\n",
       "   0.18487,\n",
       "   0.184364,\n",
       "   0.183586,\n",
       "   0.183123,\n",
       "   0.182302,\n",
       "   0.182029,\n",
       "   0.181839,\n",
       "   0.181145,\n",
       "   0.180745,\n",
       "   0.180156,\n",
       "   0.179735,\n",
       "   0.179398,\n",
       "   0.178767,\n",
       "   0.17822,\n",
       "   0.177946,\n",
       "   0.176684,\n",
       "   0.176157,\n",
       "   0.175231,\n",
       "   0.174958,\n",
       "   0.174579,\n",
       "   0.17399,\n",
       "   0.173695,\n",
       "   0.17338,\n",
       "   0.173211,\n",
       "   0.172727,\n",
       "   0.172306,\n",
       "   0.171928,\n",
       "   0.171907,\n",
       "   0.17138,\n",
       "   0.170581,\n",
       "   0.17037,\n",
       "   0.169634,\n",
       "   0.169423,\n",
       "   0.169213,\n",
       "   0.168624,\n",
       "   0.168119,\n",
       "   0.167908,\n",
       "   0.167551,\n",
       "   0.167424,\n",
       "   0.167109,\n",
       "   0.166561,\n",
       "   0.166246,\n",
       "   0.166077,\n",
       "   0.16553,\n",
       "   0.165236,\n",
       "   0.164857,\n",
       "   0.164583,\n",
       "   0.164394,\n",
       "   0.164141,\n",
       "   0.163784,\n",
       "   0.163237,\n",
       "   0.163047,\n",
       "   0.162584,\n",
       "   0.162353,\n",
       "   0.162163,\n",
       "   0.161848,\n",
       "   0.161616,\n",
       "   0.161258,\n",
       "   0.161027,\n",
       "   0.160354,\n",
       "   0.159891,\n",
       "   0.159638,\n",
       "   0.159322,\n",
       "   0.159049,\n",
       "   0.158228,\n",
       "   0.158228,\n",
       "   0.157639,\n",
       "   0.157302,\n",
       "   0.156692,\n",
       "   0.156629,\n",
       "   0.156313,\n",
       "   0.156124,\n",
       "   0.155997,\n",
       "   0.155829,\n",
       "   0.155513,\n",
       "   0.154651,\n",
       "   0.154461,\n",
       "   0.154209,\n",
       "   0.153746,\n",
       "   0.153367,\n",
       "   0.152883,\n",
       "   0.152462,\n",
       "   0.152189,\n",
       "   0.151915,\n",
       "   0.15162,\n",
       "   0.151494,\n",
       "   0.151115,\n",
       "   0.150758,\n",
       "   0.15061,\n",
       "   0.149874,\n",
       "   0.149369,\n",
       "   0.149158,\n",
       "   0.148843,\n",
       "   0.148506,\n",
       "   0.14838,\n",
       "   0.148001,\n",
       "   0.14779,\n",
       "   0.147517,\n",
       "   0.147559,\n",
       "   0.147054,\n",
       "   0.146949,\n",
       "   0.146591,\n",
       "   0.146444,\n",
       "   0.146233,\n",
       "   0.146065,\n",
       "   0.145644,\n",
       "   0.145118,\n",
       "   0.144592,\n",
       "   0.144129,\n",
       "   0.143813,\n",
       "   0.14354,\n",
       "   0.143119,\n",
       "   0.142761,\n",
       "   0.142635,\n",
       "   0.142277,\n",
       "   0.142045,\n",
       "   0.141582,\n",
       "   0.141246,\n",
       "   0.140783,\n",
       "   0.14053,\n",
       "   0.140109,\n",
       "   0.139752,\n",
       "   0.139773,\n",
       "   0.139436,\n",
       "   0.139247,\n",
       "   0.138889,\n",
       "   0.138636,\n",
       "   0.138173,\n",
       "   0.137921,\n",
       "   0.137858,\n",
       "   0.137521,\n",
       "   0.137395,\n",
       "   0.137205,\n",
       "   0.136953,\n",
       "   0.136532,\n",
       "   0.136574,\n",
       "   0.136322,\n",
       "   0.136153,\n",
       "   0.135795,\n",
       "   0.135396,\n",
       "   0.13529,\n",
       "   0.13508,\n",
       "   0.13487,\n",
       "   0.134301,\n",
       "   0.134133,\n",
       "   0.133965,\n",
       "   0.133691,\n",
       "   0.133333,\n",
       "   0.132849,\n",
       "   0.132723,\n",
       "   0.132555,\n",
       "   0.132323,\n",
       "   0.132176,\n",
       "   0.13205,\n",
       "   0.131797,\n",
       "   0.131503,\n",
       "   0.131418,\n",
       "   0.131082,\n",
       "   0.130598,\n",
       "   0.130282,\n",
       "   0.130261,\n",
       "   0.129798,\n",
       "   0.129672,\n",
       "   0.129545,\n",
       "   0.129188,\n",
       "   0.128809,\n",
       "   0.128598,\n",
       "   0.128598,\n",
       "   0.128346,\n",
       "   0.12782,\n",
       "   0.12742,\n",
       "   0.127273,\n",
       "   0.127104,\n",
       "   0.126747,\n",
       "   0.126515,\n",
       "   0.125884,\n",
       "   0.125274,\n",
       "   0.125253,\n",
       "   0.124979,\n",
       "   0.1246,\n",
       "   0.124474,\n",
       "   0.124116,\n",
       "   0.123927,\n",
       "   0.123569,\n",
       "   0.123274,\n",
       "   0.123106,\n",
       "   0.122875,\n",
       "   0.122559,\n",
       "   0.122201,\n",
       "   0.121949,\n",
       "   0.121886,\n",
       "   0.121549,\n",
       "   0.121149,\n",
       "   0.121002,\n",
       "   0.120749,\n",
       "   0.120518,\n",
       "   0.120118,\n",
       "   0.119844,\n",
       "   0.119802,\n",
       "   0.119423,\n",
       "   0.119297,\n",
       "   0.119108,\n",
       "   0.118708,\n",
       "   0.118519,\n",
       "   0.118434,\n",
       "   0.117971,\n",
       "   0.117551,\n",
       "   0.117424,\n",
       "   0.117151,\n",
       "   0.116793,\n",
       "   0.116625,\n",
       "   0.116309,\n",
       "   0.11612,\n",
       "   0.115825,\n",
       "   0.115741,\n",
       "   0.115067,\n",
       "   0.114625,\n",
       "   0.114457,\n",
       "   0.114226,\n",
       "   0.113973,\n",
       "   0.113763,\n",
       "   0.11351,\n",
       "   0.113363,\n",
       "   0.113152,\n",
       "   0.112837,\n",
       "   0.112374,\n",
       "   0.112247,\n",
       "   0.112079,\n",
       "   0.111679,\n",
       "   0.111448,\n",
       "   0.111364,\n",
       "   0.111069,\n",
       "   0.111069,\n",
       "   0.110817,\n",
       "   0.110543,\n",
       "   0.11048,\n",
       "   0.110438,\n",
       "   0.110143,\n",
       "   0.109743,\n",
       "   0.109449,\n",
       "   0.108986,\n",
       "   0.108586,\n",
       "   0.108333,\n",
       "   0.10806,\n",
       "   0.107807,\n",
       "   0.107723,\n",
       "   0.107449,\n",
       "   0.107134,\n",
       "   0.106923,\n",
       "   0.106566,\n",
       "   0.106334,\n",
       "   0.106166,\n",
       "   0.105892,\n",
       "   0.105766,\n",
       "   0.105682,\n",
       "   0.105556,\n",
       "   0.105324,\n",
       "   0.105198,\n",
       "   0.104966,\n",
       "   0.104798,\n",
       "   0.104419,\n",
       "   0.104356,\n",
       "   0.104104,\n",
       "   0.103535,\n",
       "   0.103409,\n",
       "   0.10322,\n",
       "   0.103136,\n",
       "   0.102715,\n",
       "   0.102357,\n",
       "   0.102125,\n",
       "   0.101768,\n",
       "   0.101599,\n",
       "   0.101368,\n",
       "   0.101263,\n",
       "   0.10101,\n",
       "   0.100715,\n",
       "   0.100758,\n",
       "   0.100505,\n",
       "   0.100295,\n",
       "   0.100231,\n",
       "   0.099979,\n",
       "   0.099705]},\n",
       " 'validation_1': {'merror': [0.261953,\n",
       "   0.264057,\n",
       "   0.264731,\n",
       "   0.262037,\n",
       "   0.26069,\n",
       "   0.257239,\n",
       "   0.255051,\n",
       "   0.250421,\n",
       "   0.248316,\n",
       "   0.247054,\n",
       "   0.24596,\n",
       "   0.245118,\n",
       "   0.245286,\n",
       "   0.244529,\n",
       "   0.244529,\n",
       "   0.243855,\n",
       "   0.241835,\n",
       "   0.241919,\n",
       "   0.239899,\n",
       "   0.238973,\n",
       "   0.238973,\n",
       "   0.237626,\n",
       "   0.23569,\n",
       "   0.235522,\n",
       "   0.235774,\n",
       "   0.235269,\n",
       "   0.234428,\n",
       "   0.232492,\n",
       "   0.230892,\n",
       "   0.229882,\n",
       "   0.228283,\n",
       "   0.227357,\n",
       "   0.227104,\n",
       "   0.226683,\n",
       "   0.226515,\n",
       "   0.226347,\n",
       "   0.225589,\n",
       "   0.225168,\n",
       "   0.224158,\n",
       "   0.222475,\n",
       "   0.221633,\n",
       "   0.220539,\n",
       "   0.220707,\n",
       "   0.220286,\n",
       "   0.219613,\n",
       "   0.219108,\n",
       "   0.218266,\n",
       "   0.217172,\n",
       "   0.217172,\n",
       "   0.216667,\n",
       "   0.216835,\n",
       "   0.216077,\n",
       "   0.215152,\n",
       "   0.21431,\n",
       "   0.214478,\n",
       "   0.212879,\n",
       "   0.212795,\n",
       "   0.211953,\n",
       "   0.211448,\n",
       "   0.211448,\n",
       "   0.211364,\n",
       "   0.210859,\n",
       "   0.21069,\n",
       "   0.210354,\n",
       "   0.210522,\n",
       "   0.209512,\n",
       "   0.209259,\n",
       "   0.209259,\n",
       "   0.208923,\n",
       "   0.208923,\n",
       "   0.208754,\n",
       "   0.208923,\n",
       "   0.208923,\n",
       "   0.209091,\n",
       "   0.208502,\n",
       "   0.207997,\n",
       "   0.207576,\n",
       "   0.208165,\n",
       "   0.206313,\n",
       "   0.206145,\n",
       "   0.205556,\n",
       "   0.205135,\n",
       "   0.205219,\n",
       "   0.204798,\n",
       "   0.204798,\n",
       "   0.204714,\n",
       "   0.204545,\n",
       "   0.204209,\n",
       "   0.204545,\n",
       "   0.204293,\n",
       "   0.204461,\n",
       "   0.204545,\n",
       "   0.204377,\n",
       "   0.204545,\n",
       "   0.204377,\n",
       "   0.204377,\n",
       "   0.204545,\n",
       "   0.204461,\n",
       "   0.204377,\n",
       "   0.204293,\n",
       "   0.203788,\n",
       "   0.203367,\n",
       "   0.203704,\n",
       "   0.20362,\n",
       "   0.20362,\n",
       "   0.203704,\n",
       "   0.203114,\n",
       "   0.203199,\n",
       "   0.203451,\n",
       "   0.203367,\n",
       "   0.203283,\n",
       "   0.202778,\n",
       "   0.202694,\n",
       "   0.203114,\n",
       "   0.202778,\n",
       "   0.202609,\n",
       "   0.202525,\n",
       "   0.20303,\n",
       "   0.203283,\n",
       "   0.202946,\n",
       "   0.202946,\n",
       "   0.202778,\n",
       "   0.202946,\n",
       "   0.20202,\n",
       "   0.201852,\n",
       "   0.20202,\n",
       "   0.20202,\n",
       "   0.201431,\n",
       "   0.201178,\n",
       "   0.201347,\n",
       "   0.200926,\n",
       "   0.201263,\n",
       "   0.201094,\n",
       "   0.200589,\n",
       "   0.200673,\n",
       "   0.200673,\n",
       "   0.200589,\n",
       "   0.200337,\n",
       "   0.2,\n",
       "   0.199832,\n",
       "   0.2,\n",
       "   0.200168,\n",
       "   0.200337,\n",
       "   0.200168,\n",
       "   0.199916,\n",
       "   0.2,\n",
       "   0.199663,\n",
       "   0.199411,\n",
       "   0.199579,\n",
       "   0.199327,\n",
       "   0.199158,\n",
       "   0.199663,\n",
       "   0.199832,\n",
       "   0.2,\n",
       "   0.199242,\n",
       "   0.199327,\n",
       "   0.199579,\n",
       "   0.199747,\n",
       "   0.199663,\n",
       "   0.199832,\n",
       "   0.199411,\n",
       "   0.199579,\n",
       "   0.199411,\n",
       "   0.198906,\n",
       "   0.198569,\n",
       "   0.198148,\n",
       "   0.198401,\n",
       "   0.198316,\n",
       "   0.198232,\n",
       "   0.197896,\n",
       "   0.197727,\n",
       "   0.19798,\n",
       "   0.198232,\n",
       "   0.198401,\n",
       "   0.198148,\n",
       "   0.198148,\n",
       "   0.198064,\n",
       "   0.198401,\n",
       "   0.198148,\n",
       "   0.198064,\n",
       "   0.198064,\n",
       "   0.197811,\n",
       "   0.197559,\n",
       "   0.197475,\n",
       "   0.197306,\n",
       "   0.197222,\n",
       "   0.196886,\n",
       "   0.196886,\n",
       "   0.19697,\n",
       "   0.197054,\n",
       "   0.19697,\n",
       "   0.197138,\n",
       "   0.197054,\n",
       "   0.19697,\n",
       "   0.197138,\n",
       "   0.197138,\n",
       "   0.19697,\n",
       "   0.196717,\n",
       "   0.196465,\n",
       "   0.196801,\n",
       "   0.196801,\n",
       "   0.195875,\n",
       "   0.195623,\n",
       "   0.195791,\n",
       "   0.195875,\n",
       "   0.19596,\n",
       "   0.195875,\n",
       "   0.196296,\n",
       "   0.196128,\n",
       "   0.195875,\n",
       "   0.195875,\n",
       "   0.195875,\n",
       "   0.195791,\n",
       "   0.19596,\n",
       "   0.196212,\n",
       "   0.19596,\n",
       "   0.195707,\n",
       "   0.195455,\n",
       "   0.19537,\n",
       "   0.195455,\n",
       "   0.196128,\n",
       "   0.196296,\n",
       "   0.196128,\n",
       "   0.196212,\n",
       "   0.19596,\n",
       "   0.195623,\n",
       "   0.19596,\n",
       "   0.195539,\n",
       "   0.195539,\n",
       "   0.195286,\n",
       "   0.195286,\n",
       "   0.194865,\n",
       "   0.195118,\n",
       "   0.194949,\n",
       "   0.195202,\n",
       "   0.195455,\n",
       "   0.195539,\n",
       "   0.195118,\n",
       "   0.195202,\n",
       "   0.19537,\n",
       "   0.195118,\n",
       "   0.195202,\n",
       "   0.195455,\n",
       "   0.195286,\n",
       "   0.195118,\n",
       "   0.195286,\n",
       "   0.195202,\n",
       "   0.195455,\n",
       "   0.195539,\n",
       "   0.195455,\n",
       "   0.195539,\n",
       "   0.194865,\n",
       "   0.194697,\n",
       "   0.194781,\n",
       "   0.194697,\n",
       "   0.194865,\n",
       "   0.194781,\n",
       "   0.194865,\n",
       "   0.194781,\n",
       "   0.194865,\n",
       "   0.195202,\n",
       "   0.194949,\n",
       "   0.194276,\n",
       "   0.194529,\n",
       "   0.194192,\n",
       "   0.194529,\n",
       "   0.194697,\n",
       "   0.194865,\n",
       "   0.194529,\n",
       "   0.194276,\n",
       "   0.194276,\n",
       "   0.19436,\n",
       "   0.193855,\n",
       "   0.193855,\n",
       "   0.193939,\n",
       "   0.193771,\n",
       "   0.194108,\n",
       "   0.194276,\n",
       "   0.194024,\n",
       "   0.193434,\n",
       "   0.193687,\n",
       "   0.193687,\n",
       "   0.193855,\n",
       "   0.194276,\n",
       "   0.194276,\n",
       "   0.19436,\n",
       "   0.194192,\n",
       "   0.194024,\n",
       "   0.194276,\n",
       "   0.193434,\n",
       "   0.19335,\n",
       "   0.192929,\n",
       "   0.193098,\n",
       "   0.193013,\n",
       "   0.193182,\n",
       "   0.193434,\n",
       "   0.193182,\n",
       "   0.193182,\n",
       "   0.193266,\n",
       "   0.193013,\n",
       "   0.193098,\n",
       "   0.193098,\n",
       "   0.193098,\n",
       "   0.193182,\n",
       "   0.193519,\n",
       "   0.193434,\n",
       "   0.193266,\n",
       "   0.193434,\n",
       "   0.193266,\n",
       "   0.193434,\n",
       "   0.193603,\n",
       "   0.193434,\n",
       "   0.193519,\n",
       "   0.193603,\n",
       "   0.193434,\n",
       "   0.193434,\n",
       "   0.193687,\n",
       "   0.193939,\n",
       "   0.193771,\n",
       "   0.193519,\n",
       "   0.193687,\n",
       "   0.193603,\n",
       "   0.193434,\n",
       "   0.193434,\n",
       "   0.193603,\n",
       "   0.193519,\n",
       "   0.193519,\n",
       "   0.193771,\n",
       "   0.193603,\n",
       "   0.193855,\n",
       "   0.193939,\n",
       "   0.193603,\n",
       "   0.193855,\n",
       "   0.19335,\n",
       "   0.19335,\n",
       "   0.193519,\n",
       "   0.193603,\n",
       "   0.19335,\n",
       "   0.193434,\n",
       "   0.193771,\n",
       "   0.193771]}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.evals_result()\n",
    "train_error = results['validation_0']['merror']\n",
    "val_error = results['validation_1']['merror']\n",
    "epoch = list(range(1, len(train_error)+1))\n",
    "plt.plot(epoch, train_error, label='Train')\n",
    "plt.plot(epoch, val_error, label='Validation')\n",
    "plt.ylabel('Classification Error')\n",
    "plt.xlabel('Model Complexity (n_estimators)')\n",
    "# plt.ylim(0.18, .22)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZF7-ml6BhRRf"
   },
   "source": [
    "## Try adjusting these hyperparameters\n",
    "\n",
    "#### Random Forest\n",
    "- class_weight (for imbalanced classes)\n",
    "- max_depth (usually high, can try decreasing)\n",
    "- n_estimators (too low underfits, too high wastes time)\n",
    "- min_samples_leaf (increase if overfitting)\n",
    "- max_features (decrease for more diverse trees)\n",
    "\n",
    "#### Xgboost\n",
    "- scale_pos_weight (for imbalanced classes)\n",
    "- max_depth (usually low, can try increasing)\n",
    "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
    "- learning_rate (too low underfits, too high overfits)\n",
    "\n",
    "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS7_lesson_applied_modeling_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
