{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_applied_modeling_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lechemrc/DS-Unit-2-Applied-Modeling/blob/master/module2/assignment_applied_modeling_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Applied Modeling, Module 2\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your work.\n",
        "\n",
        "- [ ] Plot the distribution of your target. \n",
        "    - Classification problem: Are your classes imbalanced? Then, don't use just accuracy.\n",
        "    - Regression problem: Is your target skewed? If so, let's discuss in Slack.\n",
        "- [ ] Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- [ ] Fit a model. Does it beat your baseline?\n",
        "- [ ] Try xgboost.\n",
        "- [ ] Get your model's permutation importances.\n",
        "\n",
        "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "\n",
        "## Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Permutation Importances\n",
        "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
        "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "\n",
        "#### (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "#### Gradient Boosting\n",
        "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
        "  - _**[A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)**_\n",
        "  - [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8\n",
        "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)\n",
        "  - _**[Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw) (2.5 minute video)**_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL8mwm0rUaQo",
        "colab_type": "text"
      },
      "source": [
        "### Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLQ8sFRMUSef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b02oUw9UFXY",
        "colab_type": "text"
      },
      "source": [
        "### Important Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnMUTmIuUfkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# libraries and math functions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas_profiling\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# imports for pipeline and regression\n",
        "import category_encoders as ce\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# plotting\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrfx0ECB9Fo9",
        "colab_type": "code",
        "outputId": "9e98d1e6-c41b-44fc-ff7d-3ce792539ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/lechemrc/Datasets-to-ref/master/Endangered%20Species%20and%20Environment%20sets/merged.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 163)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>1990_emissions</th>\n",
              "      <th>1991_emissions</th>\n",
              "      <th>1992_emissions</th>\n",
              "      <th>1993_emissions</th>\n",
              "      <th>1994_emissions</th>\n",
              "      <th>1995_emissions</th>\n",
              "      <th>1996_emissions</th>\n",
              "      <th>1997_emissions</th>\n",
              "      <th>1998_emissions</th>\n",
              "      <th>1999_emissions</th>\n",
              "      <th>2000_emissions</th>\n",
              "      <th>2001_emissions</th>\n",
              "      <th>2002_emissions</th>\n",
              "      <th>2003_emissions</th>\n",
              "      <th>2004_emissions</th>\n",
              "      <th>2005_emissions</th>\n",
              "      <th>2006_emissions</th>\n",
              "      <th>2007_emissions</th>\n",
              "      <th>2008_emissions</th>\n",
              "      <th>2009_emissions</th>\n",
              "      <th>2010_emissions</th>\n",
              "      <th>2011_emissions</th>\n",
              "      <th>2012_emissions</th>\n",
              "      <th>2013_emissions</th>\n",
              "      <th>2014_emissions</th>\n",
              "      <th>2015_emissions</th>\n",
              "      <th>2016_emissions</th>\n",
              "      <th>2017_emissions</th>\n",
              "      <th>1990_stringency</th>\n",
              "      <th>1991_stringency</th>\n",
              "      <th>1992_stringency</th>\n",
              "      <th>1993_stringency</th>\n",
              "      <th>1994_stringency</th>\n",
              "      <th>1995_stringency</th>\n",
              "      <th>1996_stringency</th>\n",
              "      <th>1997_stringency</th>\n",
              "      <th>1998_stringency</th>\n",
              "      <th>1999_stringency</th>\n",
              "      <th>2000_stringency</th>\n",
              "      <th>...</th>\n",
              "      <th>1995_lead</th>\n",
              "      <th>2000_lead</th>\n",
              "      <th>2005_lead</th>\n",
              "      <th>2006_lead</th>\n",
              "      <th>2007_lead</th>\n",
              "      <th>2008_lead</th>\n",
              "      <th>2009_lead</th>\n",
              "      <th>2010_lead</th>\n",
              "      <th>2011_lead</th>\n",
              "      <th>2012_lead</th>\n",
              "      <th>2013_lead</th>\n",
              "      <th>2014_lead</th>\n",
              "      <th>2015_lead</th>\n",
              "      <th>2016_lead</th>\n",
              "      <th>2017_lead</th>\n",
              "      <th>Mammals_percent_species</th>\n",
              "      <th>Birds_percent_species</th>\n",
              "      <th>Reptiles_percent_species</th>\n",
              "      <th>Amphibians_percent_species</th>\n",
              "      <th>Fish_percent_species</th>\n",
              "      <th>Marine Fish_percent_species</th>\n",
              "      <th>Freshwater Fish_percent_species</th>\n",
              "      <th>Vascular plants_percent_species</th>\n",
              "      <th>Mosses_percent_species</th>\n",
              "      <th>Lichens_percent_species</th>\n",
              "      <th>Invertebrates_percent_species</th>\n",
              "      <th>2005_population</th>\n",
              "      <th>2006_population</th>\n",
              "      <th>2007_population</th>\n",
              "      <th>2008_population</th>\n",
              "      <th>2009_population</th>\n",
              "      <th>2010_population</th>\n",
              "      <th>2011_population</th>\n",
              "      <th>2012_population</th>\n",
              "      <th>2013_population</th>\n",
              "      <th>2014_population</th>\n",
              "      <th>2015_population</th>\n",
              "      <th>2016_population</th>\n",
              "      <th>2017_population</th>\n",
              "      <th>2018_population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Australia</td>\n",
              "      <td>420315</td>\n",
              "      <td>421381</td>\n",
              "      <td>425702</td>\n",
              "      <td>426232</td>\n",
              "      <td>426305</td>\n",
              "      <td>434913</td>\n",
              "      <td>442506</td>\n",
              "      <td>454629</td>\n",
              "      <td>468406</td>\n",
              "      <td>474027</td>\n",
              "      <td>485019</td>\n",
              "      <td>492462</td>\n",
              "      <td>496319</td>\n",
              "      <td>498119</td>\n",
              "      <td>515931</td>\n",
              "      <td>521801</td>\n",
              "      <td>526437</td>\n",
              "      <td>533138</td>\n",
              "      <td>537032</td>\n",
              "      <td>540913</td>\n",
              "      <td>537275</td>\n",
              "      <td>538281</td>\n",
              "      <td>540616</td>\n",
              "      <td>530434</td>\n",
              "      <td>524957</td>\n",
              "      <td>535174</td>\n",
              "      <td>546772</td>\n",
              "      <td>554127</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.98</td>\n",
              "      <td>...</td>\n",
              "      <td>2291</td>\n",
              "      <td>2220</td>\n",
              "      <td>2083</td>\n",
              "      <td>2078</td>\n",
              "      <td>2124</td>\n",
              "      <td>2132</td>\n",
              "      <td>2087</td>\n",
              "      <td>2043</td>\n",
              "      <td>2047</td>\n",
              "      <td>2000</td>\n",
              "      <td>1985</td>\n",
              "      <td>2031</td>\n",
              "      <td>2078</td>\n",
              "      <td>2134</td>\n",
              "      <td>2203</td>\n",
              "      <td>27</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>20176844</td>\n",
              "      <td>20450966</td>\n",
              "      <td>20827622</td>\n",
              "      <td>21249199</td>\n",
              "      <td>21691653</td>\n",
              "      <td>22031750</td>\n",
              "      <td>22340024</td>\n",
              "      <td>22733465</td>\n",
              "      <td>23128129</td>\n",
              "      <td>23475686</td>\n",
              "      <td>23815995</td>\n",
              "      <td>24190907</td>\n",
              "      <td>24601860</td>\n",
              "      <td>24992860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Austria</td>\n",
              "      <td>78670</td>\n",
              "      <td>82349</td>\n",
              "      <td>75750</td>\n",
              "      <td>75932</td>\n",
              "      <td>76207</td>\n",
              "      <td>79584</td>\n",
              "      <td>82875</td>\n",
              "      <td>82405</td>\n",
              "      <td>81702</td>\n",
              "      <td>80105</td>\n",
              "      <td>80415</td>\n",
              "      <td>84324</td>\n",
              "      <td>86111</td>\n",
              "      <td>91788</td>\n",
              "      <td>91383</td>\n",
              "      <td>92567</td>\n",
              "      <td>90117</td>\n",
              "      <td>87473</td>\n",
              "      <td>86816</td>\n",
              "      <td>80329</td>\n",
              "      <td>84753</td>\n",
              "      <td>82460</td>\n",
              "      <td>79811</td>\n",
              "      <td>80353</td>\n",
              "      <td>76680</td>\n",
              "      <td>78897</td>\n",
              "      <td>79596</td>\n",
              "      <td>82261</td>\n",
              "      <td>1.17</td>\n",
              "      <td>1.42</td>\n",
              "      <td>1.42</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.48</td>\n",
              "      <td>1.94</td>\n",
              "      <td>1.94</td>\n",
              "      <td>1.85</td>\n",
              "      <td>1.94</td>\n",
              "      <td>1.85</td>\n",
              "      <td>2.02</td>\n",
              "      <td>...</td>\n",
              "      <td>688</td>\n",
              "      <td>684</td>\n",
              "      <td>608</td>\n",
              "      <td>588</td>\n",
              "      <td>591</td>\n",
              "      <td>584</td>\n",
              "      <td>592</td>\n",
              "      <td>589</td>\n",
              "      <td>594</td>\n",
              "      <td>595</td>\n",
              "      <td>589</td>\n",
              "      <td>589</td>\n",
              "      <td>596</td>\n",
              "      <td>590</td>\n",
              "      <td>590</td>\n",
              "      <td>27</td>\n",
              "      <td>27</td>\n",
              "      <td>64</td>\n",
              "      <td>60</td>\n",
              "      <td>46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>46.0</td>\n",
              "      <td>33</td>\n",
              "      <td>23</td>\n",
              "      <td>21.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8225278</td>\n",
              "      <td>8267948</td>\n",
              "      <td>8295189</td>\n",
              "      <td>8321541</td>\n",
              "      <td>8341483</td>\n",
              "      <td>8361069</td>\n",
              "      <td>8388534</td>\n",
              "      <td>8426311</td>\n",
              "      <td>8477230</td>\n",
              "      <td>8543932</td>\n",
              "      <td>8629519</td>\n",
              "      <td>8739806</td>\n",
              "      <td>8795073</td>\n",
              "      <td>8837707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Belgium</td>\n",
              "      <td>146587</td>\n",
              "      <td>149324</td>\n",
              "      <td>148920</td>\n",
              "      <td>147890</td>\n",
              "      <td>152523</td>\n",
              "      <td>154665</td>\n",
              "      <td>158303</td>\n",
              "      <td>149782</td>\n",
              "      <td>154957</td>\n",
              "      <td>148645</td>\n",
              "      <td>149730</td>\n",
              "      <td>148132</td>\n",
              "      <td>147567</td>\n",
              "      <td>147932</td>\n",
              "      <td>149231</td>\n",
              "      <td>145284</td>\n",
              "      <td>142660</td>\n",
              "      <td>138961</td>\n",
              "      <td>138828</td>\n",
              "      <td>126263</td>\n",
              "      <td>132922</td>\n",
              "      <td>122198</td>\n",
              "      <td>119373</td>\n",
              "      <td>119304</td>\n",
              "      <td>113506</td>\n",
              "      <td>117122</td>\n",
              "      <td>115783</td>\n",
              "      <td>114540</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.85</td>\n",
              "      <td>...</td>\n",
              "      <td>2142</td>\n",
              "      <td>2131</td>\n",
              "      <td>1925</td>\n",
              "      <td>1841</td>\n",
              "      <td>1841</td>\n",
              "      <td>1840</td>\n",
              "      <td>1810</td>\n",
              "      <td>1766</td>\n",
              "      <td>1770</td>\n",
              "      <td>1783</td>\n",
              "      <td>1769</td>\n",
              "      <td>1702</td>\n",
              "      <td>1734</td>\n",
              "      <td>1712</td>\n",
              "      <td>1722</td>\n",
              "      <td>21</td>\n",
              "      <td>28</td>\n",
              "      <td>40</td>\n",
              "      <td>32</td>\n",
              "      <td>20</td>\n",
              "      <td>14.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>59.0</td>\n",
              "      <td>11</td>\n",
              "      <td>10478617</td>\n",
              "      <td>10547956</td>\n",
              "      <td>10625701</td>\n",
              "      <td>10709976</td>\n",
              "      <td>10796498</td>\n",
              "      <td>10895589</td>\n",
              "      <td>10993616</td>\n",
              "      <td>11067748</td>\n",
              "      <td>11125033</td>\n",
              "      <td>11179778</td>\n",
              "      <td>11238474</td>\n",
              "      <td>11295003</td>\n",
              "      <td>11349081</td>\n",
              "      <td>11403740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Canada</td>\n",
              "      <td>602184</td>\n",
              "      <td>593402</td>\n",
              "      <td>610441</td>\n",
              "      <td>612264</td>\n",
              "      <td>633675</td>\n",
              "      <td>651011</td>\n",
              "      <td>672053</td>\n",
              "      <td>686988</td>\n",
              "      <td>694531</td>\n",
              "      <td>707376</td>\n",
              "      <td>730588</td>\n",
              "      <td>719733</td>\n",
              "      <td>724349</td>\n",
              "      <td>741003</td>\n",
              "      <td>742972</td>\n",
              "      <td>730349</td>\n",
              "      <td>721445</td>\n",
              "      <td>743767</td>\n",
              "      <td>723225</td>\n",
              "      <td>681699</td>\n",
              "      <td>692619</td>\n",
              "      <td>703379</td>\n",
              "      <td>711023</td>\n",
              "      <td>722063</td>\n",
              "      <td>723091</td>\n",
              "      <td>721992</td>\n",
              "      <td>707727</td>\n",
              "      <td>715749</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.90</td>\n",
              "      <td>...</td>\n",
              "      <td>1414</td>\n",
              "      <td>1360</td>\n",
              "      <td>1260</td>\n",
              "      <td>1227</td>\n",
              "      <td>1231</td>\n",
              "      <td>1226</td>\n",
              "      <td>1201</td>\n",
              "      <td>1176</td>\n",
              "      <td>1161</td>\n",
              "      <td>1179</td>\n",
              "      <td>1168</td>\n",
              "      <td>1202</td>\n",
              "      <td>1237</td>\n",
              "      <td>1251</td>\n",
              "      <td>1272</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>58</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>32243753</td>\n",
              "      <td>32571174</td>\n",
              "      <td>32889025</td>\n",
              "      <td>33247118</td>\n",
              "      <td>33628895</td>\n",
              "      <td>34004889</td>\n",
              "      <td>34339328</td>\n",
              "      <td>34714222</td>\n",
              "      <td>35082954</td>\n",
              "      <td>35437435</td>\n",
              "      <td>35702908</td>\n",
              "      <td>36109487</td>\n",
              "      <td>36540268</td>\n",
              "      <td>37058856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chile</td>\n",
              "      <td>52016</td>\n",
              "      <td>50681</td>\n",
              "      <td>52579</td>\n",
              "      <td>55432</td>\n",
              "      <td>58349</td>\n",
              "      <td>61452</td>\n",
              "      <td>67715</td>\n",
              "      <td>75203</td>\n",
              "      <td>76151</td>\n",
              "      <td>79279</td>\n",
              "      <td>76587</td>\n",
              "      <td>74732</td>\n",
              "      <td>76179</td>\n",
              "      <td>76956</td>\n",
              "      <td>82609</td>\n",
              "      <td>84334</td>\n",
              "      <td>85555</td>\n",
              "      <td>93656</td>\n",
              "      <td>94262</td>\n",
              "      <td>90887</td>\n",
              "      <td>91862</td>\n",
              "      <td>99861</td>\n",
              "      <td>104492</td>\n",
              "      <td>104304</td>\n",
              "      <td>101474</td>\n",
              "      <td>108243</td>\n",
              "      <td>111678</td>\n",
              "      <td>715749</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.90</td>\n",
              "      <td>...</td>\n",
              "      <td>237</td>\n",
              "      <td>248</td>\n",
              "      <td>271</td>\n",
              "      <td>270</td>\n",
              "      <td>274</td>\n",
              "      <td>269</td>\n",
              "      <td>284</td>\n",
              "      <td>293</td>\n",
              "      <td>290</td>\n",
              "      <td>294</td>\n",
              "      <td>300</td>\n",
              "      <td>301</td>\n",
              "      <td>308</td>\n",
              "      <td>315</td>\n",
              "      <td>327</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>40</td>\n",
              "      <td>68</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1</td>\n",
              "      <td>16183489</td>\n",
              "      <td>16347890</td>\n",
              "      <td>16517933</td>\n",
              "      <td>16697754</td>\n",
              "      <td>16881078</td>\n",
              "      <td>17063927</td>\n",
              "      <td>17254159</td>\n",
              "      <td>17443491</td>\n",
              "      <td>17611902</td>\n",
              "      <td>17787617</td>\n",
              "      <td>17971423</td>\n",
              "      <td>18167147</td>\n",
              "      <td>18419192</td>\n",
              "      <td>18751405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 163 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     country  1990_emissions  ...  2017_population  2018_population\n",
              "0  Australia          420315  ...         24601860         24992860\n",
              "1    Austria           78670  ...          8795073          8837707\n",
              "2    Belgium          146587  ...         11349081         11403740\n",
              "3     Canada          602184  ...         36540268         37058856\n",
              "4      Chile           52016  ...         18419192         18751405\n",
              "\n",
              "[5 rows x 163 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncmoQCPP5GaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric = df.select_dtypes(include= \"number\").columns\n",
        "categorical = df.select_dtypes(exclude = \"number\").columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZGfOkqE75do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_steps = [('c_imputer', SimpleImputer(strategy=\"most_frequent\"))]\n",
        "c_pipeline = Pipeline(c_steps)\n",
        "\n",
        "n_steps = [('n_imputer', SimpleImputer())]\n",
        "n_pipeline = Pipeline(n_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9IGCbm06rWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[numeric] = n_pipeline.fit_transform(df[numeric])\n",
        "df[categorical] = c_pipeline.fit_transform(df[categorical])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fy_cgAc_h6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_preprocess(df):\n",
        "  \n",
        "  numeric = df.select_dtypes(include= \"number\").columns\n",
        "  categorical = df.select_dtypes(exclude = \"number\").columns\n",
        "  \n",
        "  c_steps = [('c_imputer', SimpleImputer(strategy=\"most_frequent\"))]\n",
        "  c_pipeline = Pipeline(c_steps)\n",
        "  \n",
        "  n_steps = [('n_imputer', SimpleImputer())]\n",
        "  n_pipeline = Pipeline(n_steps)\n",
        "  \n",
        "  df[numeric] = n_pipeline.fit_transform(df[numeric])\n",
        "  df[categorical] = c_pipeline.fit_transform(df[categorical])\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2o32hCa-gAK",
        "colab_type": "code",
        "outputId": "79fcbca2-d9a7-486d-8cab-41afb62b1722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def train_validate_test_split(df, train_percent=.5, validate_percent=.25, seed=42):\n",
        "    np.random.seed(42)\n",
        "    perm = np.random.permutation(df.index)\n",
        "    m = len(df.index)\n",
        "    train_end = int(train_percent * m)\n",
        "    validate_end = int(validate_percent * m) + train_end\n",
        "    train = df.iloc[perm[:train_end]]\n",
        "    validate = df.iloc[perm[train_end:validate_end]]\n",
        "    test = df.iloc[perm[validate_end:]]\n",
        "    return train, validate, test\n",
        "\n",
        "train, val, test = train_validate_test_split(df)\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24, 163), (12, 163), (12, 163))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBtWrJejREfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'total_threatened'\n",
        "features = df.columns.drop(target)\n",
        "\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = train.drop(columns=target)\n",
        "y_val = train[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnJRKjfWYph",
        "colab_type": "code",
        "outputId": "6e0129e7-9346-4b31-a345-0ca430ebaa56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgboost = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "xgboost.fit(X_train, y_train)\n",
        "print('Validation Accuracy', xgboost.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.9166666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}