{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LS_DS_233.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U2ha9OWxf0jw"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Permutation & Boosting\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wMejJg0w8v76"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
        "\n",
        "Libraries:\n",
        "\n",
        "- category_encoders\n",
        "- [**eli5**](https://eli5.readthedocs.io/en/latest/)\n",
        "- matplotlib\n",
        "- numpy\n",
        "- pandas\n",
        "- scikit-learn\n",
        "- [**xgboost**](https://xgboost.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install eli5\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfMua-SmQXo7",
        "colab_type": "text"
      },
      "source": [
        "We'll go back to Tanzania Waterpumps for this lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z-TExplb_Slf",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rhg8PQKt_jzP",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8lB4z5l_eml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "300442e0-3ec1-4e01-e274-47f0bfc780e4"
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_qeHJciQXpb",
        "colab_type": "text"
      },
      "source": [
        "# Get permutation importances for model interpretation and feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-eT46uEQXpd",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjCDrv4yQXph",
        "colab_type": "text"
      },
      "source": [
        "Default Feature Importances are fast, but Permutation Importances may be more accurate.\n",
        "\n",
        "These links go deeper with explanations and examples:\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "There are three types of feature importances:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "### 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "289ca001-e303-40a8-b8d4-0b6e9bae5d33"
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArYAAAJOCAYAAABCwkSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRvmFtOoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "### 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "bd4b8e4c-fe91-4e84-f261-7714c8227f67"
      },
      "source": [
        "column  = 'quantity'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without quantity: 0.7771043771043771\n",
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Drop-Column Importance for quantity: 0.03644781144781151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "### 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TksOf_n2Yiiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f7ddd3eb-6e17-4f3f-9900-3daee67aed4a"
      },
      "source": [
        "import random\n",
        "column = 'quantity'\n",
        "\n",
        "# fit and get score on val without permutation of column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(f\"Score without permutating: {pipeline.score(X_val, y_val)}\")\n",
        "\n",
        "# get score on val with permutation of column\n",
        "permutated_data = X_val.copy()\n",
        "permutated_data[column] = random.shuffle(permutated_data[column].values)\n",
        "print(f\"Score with permutating {column}: {pipeline.score(permutated_data, y_val)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score without permutating: 0.8135521885521886\n",
            "Score with permutating quantity: 0.7512626262626263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpSemTkFFP8i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "6b71af56-ff2c-4683-c22c-6908e65af1d4"
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wADX2uEue0jH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "d5c1b096-6d72-41df-ac0d-55f6bbdf4019"
      },
      "source": [
        "import eli5 \n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "''' \n",
        "takes a:\n",
        "- model\n",
        "- scoring metric \n",
        "- n_iter (how many times it will shuffle each column)\n",
        "'''\n",
        "permuter = PermutationImportance(\n",
        "    model,\n",
        "    scoring='accuracy',\n",
        "    n_iter=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PermutationImportance(cv='prefit',\n",
              "                      estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                       ccp_alpha=0.0,\n",
              "                                                       class_weight=None,\n",
              "                                                       criterion='gini',\n",
              "                                                       max_depth=None,\n",
              "                                                       max_features='auto',\n",
              "                                                       max_leaf_nodes=None,\n",
              "                                                       max_samples=None,\n",
              "                                                       min_impurity_decrease=0.0,\n",
              "                                                       min_impurity_split=None,\n",
              "                                                       min_samples_leaf=1,\n",
              "                                                       min_samples_split=2,\n",
              "                                                       min_weight_fraction_leaf=0.0,\n",
              "                                                       n_estimators=100,\n",
              "                                                       n_jobs=-1,\n",
              "                                                       oob_score=False,\n",
              "                                                       random_state=42,\n",
              "                                                       verbose=0,\n",
              "                                                       warm_start=False),\n",
              "                      n_iter=5, random_state=42, refit=True,\n",
              "                      scoring='accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yTia7EBfzI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "00d99bf2-f5ea-43b2-c60d-2151ad2f3c9a"
      },
      "source": [
        "permuter.feature_importances_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.07575758e-02,  1.12794613e-03,  1.76767677e-03, -5.05050505e-05,\n",
              "        8.83838384e-03,  6.24579125e-03,  9.42760943e-04,  3.36700337e-04,\n",
              "       -1.43097643e-03,  3.03030303e-03,  9.25925926e-04,  8.92255892e-04,\n",
              "        2.23905724e-03,  7.23905724e-04,  5.38720539e-04,  6.41414141e-03,\n",
              "        2.96296296e-03,  6.56565657e-04,  8.08080808e-04,  7.74410774e-04,\n",
              "        2.60942761e-03,  5.38720539e-04,  1.78451178e-03,  1.01683502e-02,\n",
              "        4.54545455e-04, -4.88215488e-04,  3.06397306e-03,  5.38720539e-04,\n",
              "       -5.72390572e-04,  1.01632997e-01,  1.54882155e-03, -1.68350168e-05,\n",
              "        3.36700337e-04,  1.03535354e-02,  6.75084175e-03,  8.75420875e-04,\n",
              "        1.34680135e-04,  5.05050505e-05,  5.05050505e-05,  2.02020202e-04,\n",
              "        2.69360269e-04,  1.12794613e-03,  1.49831650e-03,  2.97979798e-03,\n",
              "        4.71380471e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBdBmstwgPUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "97911575-7a69-492b-b8c1-d44b7d2b7888"
      },
      "source": [
        "feature_names = X_val.columns.tolist()\n",
        "pd.Series(permuter.feature_importances_, feature_names).sort_values()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "basin                       -0.001431\n",
              "quality_group               -0.000572\n",
              "management_group            -0.000488\n",
              "installer                   -0.000051\n",
              "source_type                 -0.000017\n",
              "construction_year_MISSING    0.000051\n",
              "gps_height_MISSING           0.000051\n",
              "latitude_MISSING             0.000135\n",
              "population_MISSING           0.000202\n",
              "year_recorded                0.000269\n",
              "source_class                 0.000337\n",
              "num_private                  0.000337\n",
              "management                   0.000455\n",
              "years_MISSING                0.000471\n",
              "extraction_type              0.000539\n",
              "water_quality                0.000539\n",
              "ward                         0.000539\n",
              "scheme_management            0.000657\n",
              "lga                          0.000724\n",
              "permit                       0.000774\n",
              "scheme_name                  0.000808\n",
              "longitude_MISSING            0.000875\n",
              "region_code                  0.000892\n",
              "region                       0.000926\n",
              "wpt_name                     0.000943\n",
              "month_recorded               0.001128\n",
              "funder                       0.001128\n",
              "day_recorded                 0.001498\n",
              "source                       0.001549\n",
              "gps_height                   0.001768\n",
              "extraction_type_group        0.001785\n",
              "district_code                0.002239\n",
              "construction_year            0.002609\n",
              "public_meeting               0.002963\n",
              "years                        0.002980\n",
              "subvillage                   0.003030\n",
              "payment                      0.003064\n",
              "latitude                     0.006246\n",
              "population                   0.006414\n",
              "waterpoint_type_group        0.006751\n",
              "longitude                    0.008838\n",
              "extraction_type_class        0.010168\n",
              "waterpoint_type              0.010354\n",
              "amount_tsh                   0.010758\n",
              "quantity                     0.101633\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y20GuiyuglWD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "475f01f6-5557-4259-d817-cdcc48357c4a"
      },
      "source": [
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None, # includes all features\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1016\n",
              "                \n",
              "                    &plusmn; 0.0029\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.85%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0108\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0104\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.01%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0102\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0088\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0068\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.11%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0064\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0062\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0031\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.29%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.31%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.46%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0026\n",
              "                \n",
              "                    &plusmn; 0.0029\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.62%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0022\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.82%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.83%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.93%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0017\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.24%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.34%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0017\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.53%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.55%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0021\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.69%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.74%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0001\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.52%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0005\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.47%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0006\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.99%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0014\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZrPFyEMYii9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34ddd457-5c57-4272-92b3-28b774aa5196"
      },
      "source": [
        "# prior shape\n",
        "X_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkQKLl4tiaGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "features =  X_train.columns[mask]\n",
        "X_train = X_train[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfsIwDkZinrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06862b98-59e8-48b2-b66c-ae89b328b4d5"
      },
      "source": [
        "# resulting shape\n",
        "X_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NC4MR92iv8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = X_val[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fl67bCR7WY6j"
      },
      "source": [
        "# Use xgboost for gradient boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU_TXrs0QXtI",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY9_KMv2QXtK",
        "colab_type": "text"
      },
      "source": [
        "In the Random Forest lesson, you learned this advice:\n",
        "\n",
        "#### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmhw8q93QXtn",
        "colab_type": "text"
      },
      "source": [
        "Like Random Forest, Gradient Boosting uses ensembles of trees. But the details of the ensembling technique are different:\n",
        "\n",
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "Here's an excerpt from [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown.\n",
        "\n",
        "This high-level overview is all you need to know for now. If you want to go deeper, we recommend you watch the StatQuest videos on gradient boosting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mnIolnwQXtp",
        "colab_type": "text"
      },
      "source": [
        "Let's write some code. We have lots of options for which libraries to use:\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_2q4tA-QXt5",
        "colab_type": "text"
      },
      "source": [
        "In this lesson, you'll use a new library, xgboost — But it has an API that's almost the same as scikit-learn, so it won't be a hard adjustment!\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wsnJRKjfWYph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f1302713-327e-4a24-ca01-1093d73ab9dc"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'subvillage',\n",
              "                                      'region', 'lga', 'ward', 'public_meeting',\n",
              "                                      'scheme_management', 'scheme_name',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'payment', 'water_quality', 'quantity',\n",
              "                                      'source', 'source_class',\n",
              "                                      'waterpoint_type',\n",
              "                                      'waterpoin...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNNATXK_mLhf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "effeee97-63df-4b12-8b4d-d8cfe6148492"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print(f\"Validation score: {accuracy_score(y_pred, y_val)}\")\n",
        "# GOT WORSE! need to tune hyperparameters\n",
        "# XGBoost is known for being very \"sensitive\" to hyperparameters"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation score: 0.7457070707070707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eCjVSlD_XJr2"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNX3IKftXBFS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e80ab9d-c528-4132-ffa9-c2454fff77ae"
      },
      "source": [
        "# fit_transfom on train, transform on val\n",
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000,  # <= 1000 trees, depends on early stopping\n",
        "    max_depth=7,        # try deeper trees because of high cardinality categoricals\n",
        "    learning_rate=0.5,  # try higher learning rate\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "eval_set = [(X_train_encoded, y_train), \n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "model.fit(X_train_encoded, y_train, \n",
        "          eval_set=eval_set,\n",
        "          eval_metric='merror', \n",
        "          early_stopping_rounds=50) # Stop if the score hasn't improved in 50 rounds"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.250884\tvalidation_1-merror:0.261953\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.234722\tvalidation_1-merror:0.245791\n",
            "[2]\tvalidation_0-merror:0.229903\tvalidation_1-merror:0.242424\n",
            "[3]\tvalidation_0-merror:0.225358\tvalidation_1-merror:0.2383\n",
            "[4]\tvalidation_0-merror:0.216372\tvalidation_1-merror:0.233249\n",
            "[5]\tvalidation_0-merror:0.209343\tvalidation_1-merror:0.229714\n",
            "[6]\tvalidation_0-merror:0.204714\tvalidation_1-merror:0.22601\n",
            "[7]\tvalidation_0-merror:0.198927\tvalidation_1-merror:0.221549\n",
            "[8]\tvalidation_0-merror:0.194613\tvalidation_1-merror:0.22037\n",
            "[9]\tvalidation_0-merror:0.191793\tvalidation_1-merror:0.220286\n",
            "[10]\tvalidation_0-merror:0.189078\tvalidation_1-merror:0.218603\n",
            "[11]\tvalidation_0-merror:0.18609\tvalidation_1-merror:0.217256\n",
            "[12]\tvalidation_0-merror:0.182618\tvalidation_1-merror:0.216919\n",
            "[13]\tvalidation_0-merror:0.180051\tvalidation_1-merror:0.215825\n",
            "[14]\tvalidation_0-merror:0.177083\tvalidation_1-merror:0.213973\n",
            "[15]\tvalidation_0-merror:0.174474\tvalidation_1-merror:0.214394\n",
            "[16]\tvalidation_0-merror:0.173338\tvalidation_1-merror:0.213721\n",
            "[17]\tvalidation_0-merror:0.171612\tvalidation_1-merror:0.214141\n",
            "[18]\tvalidation_0-merror:0.168981\tvalidation_1-merror:0.211616\n",
            "[19]\tvalidation_0-merror:0.166604\tvalidation_1-merror:0.211279\n",
            "[20]\tvalidation_0-merror:0.165846\tvalidation_1-merror:0.210606\n",
            "[21]\tvalidation_0-merror:0.164878\tvalidation_1-merror:0.209343\n",
            "[22]\tvalidation_0-merror:0.1629\tvalidation_1-merror:0.209175\n",
            "[23]\tvalidation_0-merror:0.159301\tvalidation_1-merror:0.207492\n",
            "[24]\tvalidation_0-merror:0.15705\tvalidation_1-merror:0.208754\n",
            "[25]\tvalidation_0-merror:0.154167\tvalidation_1-merror:0.206818\n",
            "[26]\tvalidation_0-merror:0.15202\tvalidation_1-merror:0.207744\n",
            "[27]\tvalidation_0-merror:0.1508\tvalidation_1-merror:0.207492\n",
            "[28]\tvalidation_0-merror:0.149095\tvalidation_1-merror:0.206818\n",
            "[29]\tvalidation_0-merror:0.148043\tvalidation_1-merror:0.206734\n",
            "[30]\tvalidation_0-merror:0.146528\tvalidation_1-merror:0.206902\n",
            "[31]\tvalidation_0-merror:0.145055\tvalidation_1-merror:0.206734\n",
            "[32]\tvalidation_0-merror:0.143182\tvalidation_1-merror:0.206397\n",
            "[33]\tvalidation_0-merror:0.141519\tvalidation_1-merror:0.20505\n",
            "[34]\tvalidation_0-merror:0.140341\tvalidation_1-merror:0.204545\n",
            "[35]\tvalidation_0-merror:0.138152\tvalidation_1-merror:0.204882\n",
            "[36]\tvalidation_0-merror:0.135417\tvalidation_1-merror:0.204461\n",
            "[37]\tvalidation_0-merror:0.134343\tvalidation_1-merror:0.203872\n",
            "[38]\tvalidation_0-merror:0.133081\tvalidation_1-merror:0.202862\n",
            "[39]\tvalidation_0-merror:0.132134\tvalidation_1-merror:0.202946\n",
            "[40]\tvalidation_0-merror:0.129966\tvalidation_1-merror:0.202862\n",
            "[41]\tvalidation_0-merror:0.128346\tvalidation_1-merror:0.202104\n",
            "[42]\tvalidation_0-merror:0.126999\tvalidation_1-merror:0.201347\n",
            "[43]\tvalidation_0-merror:0.126221\tvalidation_1-merror:0.201515\n",
            "[44]\tvalidation_0-merror:0.124011\tvalidation_1-merror:0.201178\n",
            "[45]\tvalidation_0-merror:0.122475\tvalidation_1-merror:0.200084\n",
            "[46]\tvalidation_0-merror:0.121338\tvalidation_1-merror:0.200253\n",
            "[47]\tvalidation_0-merror:0.120055\tvalidation_1-merror:0.200673\n",
            "[48]\tvalidation_0-merror:0.119087\tvalidation_1-merror:0.200758\n",
            "[49]\tvalidation_0-merror:0.117172\tvalidation_1-merror:0.201599\n",
            "[50]\tvalidation_0-merror:0.115804\tvalidation_1-merror:0.200842\n",
            "[51]\tvalidation_0-merror:0.114436\tvalidation_1-merror:0.201347\n",
            "[52]\tvalidation_0-merror:0.1129\tvalidation_1-merror:0.201431\n",
            "[53]\tvalidation_0-merror:0.111385\tvalidation_1-merror:0.201684\n",
            "[54]\tvalidation_0-merror:0.110017\tvalidation_1-merror:0.2\n",
            "[55]\tvalidation_0-merror:0.109343\tvalidation_1-merror:0.201178\n",
            "[56]\tvalidation_0-merror:0.108565\tvalidation_1-merror:0.200842\n",
            "[57]\tvalidation_0-merror:0.107407\tvalidation_1-merror:0.200673\n",
            "[58]\tvalidation_0-merror:0.106776\tvalidation_1-merror:0.200421\n",
            "[59]\tvalidation_0-merror:0.105871\tvalidation_1-merror:0.199663\n",
            "[60]\tvalidation_0-merror:0.105072\tvalidation_1-merror:0.200505\n",
            "[61]\tvalidation_0-merror:0.103683\tvalidation_1-merror:0.200673\n",
            "[62]\tvalidation_0-merror:0.102694\tvalidation_1-merror:0.200926\n",
            "[63]\tvalidation_0-merror:0.101052\tvalidation_1-merror:0.198653\n",
            "[64]\tvalidation_0-merror:0.100421\tvalidation_1-merror:0.200253\n",
            "[65]\tvalidation_0-merror:0.099432\tvalidation_1-merror:0.199747\n",
            "[66]\tvalidation_0-merror:0.096928\tvalidation_1-merror:0.200168\n",
            "[67]\tvalidation_0-merror:0.095981\tvalidation_1-merror:0.200589\n",
            "[68]\tvalidation_0-merror:0.094676\tvalidation_1-merror:0.200168\n",
            "[69]\tvalidation_0-merror:0.093813\tvalidation_1-merror:0.199495\n",
            "[70]\tvalidation_0-merror:0.092908\tvalidation_1-merror:0.19899\n",
            "[71]\tvalidation_0-merror:0.092466\tvalidation_1-merror:0.199579\n",
            "[72]\tvalidation_0-merror:0.09112\tvalidation_1-merror:0.198653\n",
            "[73]\tvalidation_0-merror:0.090088\tvalidation_1-merror:0.198822\n",
            "[74]\tvalidation_0-merror:0.08891\tvalidation_1-merror:0.197896\n",
            "[75]\tvalidation_0-merror:0.086848\tvalidation_1-merror:0.198822\n",
            "[76]\tvalidation_0-merror:0.08588\tvalidation_1-merror:0.199495\n",
            "[77]\tvalidation_0-merror:0.084806\tvalidation_1-merror:0.199579\n",
            "[78]\tvalidation_0-merror:0.083733\tvalidation_1-merror:0.199747\n",
            "[79]\tvalidation_0-merror:0.08287\tvalidation_1-merror:0.199663\n",
            "[80]\tvalidation_0-merror:0.081629\tvalidation_1-merror:0.200084\n",
            "[81]\tvalidation_0-merror:0.081313\tvalidation_1-merror:0.200253\n",
            "[82]\tvalidation_0-merror:0.080724\tvalidation_1-merror:0.199832\n",
            "[83]\tvalidation_0-merror:0.079461\tvalidation_1-merror:0.199832\n",
            "[84]\tvalidation_0-merror:0.078514\tvalidation_1-merror:0.200589\n",
            "[85]\tvalidation_0-merror:0.078051\tvalidation_1-merror:0.201094\n",
            "[86]\tvalidation_0-merror:0.077252\tvalidation_1-merror:0.200758\n",
            "[87]\tvalidation_0-merror:0.076389\tvalidation_1-merror:0.200758\n",
            "[88]\tvalidation_0-merror:0.075547\tvalidation_1-merror:0.200673\n",
            "[89]\tvalidation_0-merror:0.074979\tvalidation_1-merror:0.200758\n",
            "[90]\tvalidation_0-merror:0.073674\tvalidation_1-merror:0.200589\n",
            "[91]\tvalidation_0-merror:0.07319\tvalidation_1-merror:0.200842\n",
            "[92]\tvalidation_0-merror:0.073022\tvalidation_1-merror:0.200673\n",
            "[93]\tvalidation_0-merror:0.072601\tvalidation_1-merror:0.200337\n",
            "[94]\tvalidation_0-merror:0.072285\tvalidation_1-merror:0.200084\n",
            "[95]\tvalidation_0-merror:0.07178\tvalidation_1-merror:0.200084\n",
            "[96]\tvalidation_0-merror:0.071296\tvalidation_1-merror:0.2\n",
            "[97]\tvalidation_0-merror:0.070307\tvalidation_1-merror:0.199747\n",
            "[98]\tvalidation_0-merror:0.069444\tvalidation_1-merror:0.200505\n",
            "[99]\tvalidation_0-merror:0.068582\tvalidation_1-merror:0.200421\n",
            "[100]\tvalidation_0-merror:0.067487\tvalidation_1-merror:0.199579\n",
            "[101]\tvalidation_0-merror:0.067024\tvalidation_1-merror:0.199832\n",
            "[102]\tvalidation_0-merror:0.066288\tvalidation_1-merror:0.199411\n",
            "[103]\tvalidation_0-merror:0.065383\tvalidation_1-merror:0.200505\n",
            "[104]\tvalidation_0-merror:0.064457\tvalidation_1-merror:0.200505\n",
            "[105]\tvalidation_0-merror:0.063342\tvalidation_1-merror:0.200589\n",
            "[106]\tvalidation_0-merror:0.062626\tvalidation_1-merror:0.200505\n",
            "[107]\tvalidation_0-merror:0.062163\tvalidation_1-merror:0.201094\n",
            "[108]\tvalidation_0-merror:0.061827\tvalidation_1-merror:0.200421\n",
            "[109]\tvalidation_0-merror:0.060964\tvalidation_1-merror:0.199916\n",
            "[110]\tvalidation_0-merror:0.060438\tvalidation_1-merror:0.200926\n",
            "[111]\tvalidation_0-merror:0.059659\tvalidation_1-merror:0.200758\n",
            "[112]\tvalidation_0-merror:0.059175\tvalidation_1-merror:0.200842\n",
            "[113]\tvalidation_0-merror:0.058439\tvalidation_1-merror:0.200505\n",
            "[114]\tvalidation_0-merror:0.057449\tvalidation_1-merror:0.200589\n",
            "[115]\tvalidation_0-merror:0.057134\tvalidation_1-merror:0.201094\n",
            "[116]\tvalidation_0-merror:0.05665\tvalidation_1-merror:0.200926\n",
            "[117]\tvalidation_0-merror:0.056124\tvalidation_1-merror:0.199916\n",
            "[118]\tvalidation_0-merror:0.055556\tvalidation_1-merror:0.200505\n",
            "[119]\tvalidation_0-merror:0.054693\tvalidation_1-merror:0.200673\n",
            "[120]\tvalidation_0-merror:0.054061\tvalidation_1-merror:0.201347\n",
            "[121]\tvalidation_0-merror:0.05322\tvalidation_1-merror:0.20101\n",
            "[122]\tvalidation_0-merror:0.05282\tvalidation_1-merror:0.200842\n",
            "[123]\tvalidation_0-merror:0.052315\tvalidation_1-merror:0.201431\n",
            "[124]\tvalidation_0-merror:0.051515\tvalidation_1-merror:0.200505\n",
            "Stopping. Best iteration:\n",
            "[74]\tvalidation_0-merror:0.08891\tvalidation_1-merror:0.197896\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.5, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZF7-ml6BhRRf"
      },
      "source": [
        "### Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwTjaWBnQXus",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint. Complete these tasks for your project, and document your work.\n",
        "\n",
        "- Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- Fit a model. Does it beat your baseline?\n",
        "- Try xgboost.\n",
        "- Get your model's permutation importances.\n",
        "\n",
        "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "But, if you aren't ready to try xgboost and permutation importances with your dataset today, you can practice with another dataset instead. You may choose any dataset you've worked with previously."
      ]
    }
  ]
}