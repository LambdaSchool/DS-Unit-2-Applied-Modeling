{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_233_assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 3*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Permutation & Boosting\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your work.\n",
        "\n",
        "- [ ] If you haven't completed assignment #1, please do so first.\n",
        "- [ ] Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- [ ] Fit a model. Does it beat your baseline? \n",
        "- [ ] Try xgboost.\n",
        "- [ ] Get your model's permutation importances.\n",
        "\n",
        "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "But, if you aren't ready to try xgboost and permutation importances with your dataset today, that's okay. You can practice with another dataset instead. You may choose any dataset you've worked with previously.\n",
        "\n",
        "The data subdirectory includes the Titanic dataset for classification and the NYC apartments dataset for regression. You may want to choose one of these datasets, because example solutions will be available for each.\n",
        "\n",
        "\n",
        "## Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Permutation Importances\n",
        "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
        "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "\n",
        "#### (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "#### Gradient Boosting\n",
        "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
        "  - _**[A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)**_\n",
        "  - [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8\n",
        "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)\n",
        "  - _**[Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw) (2.5 minute video)**_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lchrsdzt-8vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install category_encoders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFTPBLvK-2zc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84dbff40-b2db-4ee6-aea6-28cbab644c10"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "train, test = train_test_split(titanic, test_size=.2)\n",
        "\n",
        "features = ['age', 'class', 'deck', 'embarked', 'fare', 'sex']\n",
        "target = 'survived'\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_test = test[features]\n",
        "y_test = test[target]\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((712, 6), (179, 6), (712,), (179,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-BCaGBH-52A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2dabecdb-7937-43d7-82a7-c05b70e9b025"
      },
      "source": [
        "X_train.isnull().sum()\n",
        "# we're dealing with some null values"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         149\n",
              "class         0\n",
              "deck        556\n",
              "embarked      1\n",
              "fare          0\n",
              "sex           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFej-QBGBdG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61952b87-7d3c-4178-901b-7b324e391757"
      },
      "source": [
        "# what is our baseline\n",
        "max(1-y_train.mean(), y_train.mean())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6306179775280899"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw5KBq-i_N2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import category_encoders as ce\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26FMDwgDAAzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create base pipeline\n",
        "pipeline = Pipeline([\n",
        "                     ('encoder', ce.OrdinalEncoder()),\n",
        "                     ('model', XGBClassifier())\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCxsAO_JAWZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a6fdb63f-eaca-4198-b093-99e6454632a5"
      },
      "source": [
        "# fit base pipeline \n",
        "train_size = .8\n",
        "cutoff = int(train_size*X_train.shape[0])\n",
        "small_X_train = X_train[:cutoff]\n",
        "X_val = X_train[cutoff:]\n",
        "small_y_train = y_train[:cutoff]\n",
        "y_val = y_train[cutoff:]\n",
        "\n",
        "pipeline.fit(small_X_train, small_y_train)\n",
        "pipeline.score(X_val, y_val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7972027972027972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNWMV2UpCnuQ",
        "colab_type": "text"
      },
      "source": [
        "## Baseline model beat the baseline by about 16%!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6-oPheBC1VN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4687b4f9-ed33-42a2-bc4c-fd371fa239b5"
      },
      "source": [
        "# now lets tune some hyperparameters! \n",
        "params = {\n",
        "    'model__n_estimators': [50, 70, 90],\n",
        "    'model__max_depth': [3, 5]\n",
        "}\n",
        "\n",
        "search = GridSearchCV(pipeline, params, n_jobs=-1)\n",
        "search.fit(X_train, y_train)\n",
        "print(f\"Best params: \\n{search.best_params_}\")\n",
        "print(f\"Best score: \\n{search.best_score_}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params: \n",
            "{'model__max_depth': 3, 'model__n_estimators': 90}\n",
            "Best score: \n",
            "0.8215699793164581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FzrDMfBEb8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline([\n",
        "                     ('encoder', ce.OrdinalEncoder()),\n",
        "                     ('model', XGBClassifier(n_estimators=90,\n",
        "                                             max_depth=3))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXtSTwp6EpcX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64cbf327-c1a8-4778-ca15-f346a3bc5296"
      },
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "pipeline.score(X_test, y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8324022346368715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy12UvfbE3TT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "6bc912e4-992a-4055-aea5-55fb05e9c120"
      },
      "source": [
        "# get model and encoded data seperate for permutation importance eval\n",
        "model = XGBClassifier(n_estimators=90, max_depth=3)\n",
        "transformer = Pipeline([\n",
        "                        ('encoder', ce.OrdinalEncoder()),\n",
        "                        ('imputer', SimpleImputer())\n",
        "])\n",
        "\n",
        "X_train_transformed = transformer.fit_transform(X_train)\n",
        "X_test_transformed = transformer.transform(X_test)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=90, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHYj8fyfFmja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "0db6e7ff-3f0b-4984-c79f-d9a7ee16360a"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\r\u001b[K     |███                             | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.10.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.17.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.14.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4UylSk9_9il",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "09159a59-5373-4edd-dfef-7f8487035f7d"
      },
      "source": [
        "import eli5 \n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model,\n",
        "    scoring=\"accuracy\",\n",
        "    n_iter=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_test_transformed, y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PermutationImportance(cv='prefit',\n",
              "                      estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                              colsample_bylevel=1,\n",
              "                                              colsample_bynode=1,\n",
              "                                              colsample_bytree=1, gamma=0,\n",
              "                                              learning_rate=0.1,\n",
              "                                              max_delta_step=0, max_depth=3,\n",
              "                                              min_child_weight=1, missing=None,\n",
              "                                              n_estimators=90, n_jobs=1,\n",
              "                                              nthread=None,\n",
              "                                              objective='binary:logistic',\n",
              "                                              random_state=0, reg_alpha=0,\n",
              "                                              reg_lambda=1, scale_pos_weight=1,\n",
              "                                              seed=None, silent=None,\n",
              "                                              subsample=1, verbosity=1),\n",
              "                      n_iter=10, random_state=42, refit=True,\n",
              "                      scoring='accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJVdWCoRFyoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d9f07039-11b4-4569-e944-023b505a9922"
      },
      "source": [
        "feature_names = X_train.columns.tolist()\n",
        "pd.Series(permuter.feature_importances_, feature_names).sort_values()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "embarked    0.013408\n",
              "deck        0.029050\n",
              "fare        0.075419\n",
              "age         0.077095\n",
              "class       0.130168\n",
              "sex         0.237989\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X7qjUSRG1gs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "f844a3e4-6e4f-4349-90e7-2a0e06e64c5c"
      },
      "source": [
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None, # includes all features\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.2380\n",
              "                \n",
              "                    &plusmn; 0.0413\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                sex\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 86.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1302\n",
              "                \n",
              "                    &plusmn; 0.0346\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0771\n",
              "                \n",
              "                    &plusmn; 0.0370\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                age\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.05%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0754\n",
              "                \n",
              "                    &plusmn; 0.0475\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                fare\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0291\n",
              "                \n",
              "                    &plusmn; 0.0164\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                deck\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0134\n",
              "                \n",
              "                    &plusmn; 0.0167\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                embarked\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M_UwXYhG7iY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I may be cautious about embarked given the standard error is larger than \n",
        "# the permutation importance value"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}